{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828e847a-04c5-42c2-80e9-e0756d208822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d3e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b7bcf",
   "metadata": {},
   "source": [
    "### A) Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7b9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d0fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Mojo is a programming language in the Python family that is currently under development.[2][3][4] It is available both in browsers via Jupyter notebooks,[4][5] and locally on Linux and macOS.[6][7] Mojo aims to combine the usability of higher level programming languages, specifically Python, with the performance of lower level programming languages like C++, Rust, and Zig.[8] The Mojo compiler is currently closed source with an open source standard library, although Modular, the company behind Mojo, has stated their intent to eventually open source the Mojo programming language itself as it matures.[9]\n",
    "\n",
    "Mojo builds upon the MLIR compiler framework instead of directly on the lower level LLVM compiler framework that many languages like Julia, Swift, clang and Rust do.[10][11] MLIR is a newer compiler framework that allows Mojo to take advantage of higher level compiler passes not available in LLVM alone and allows Mojo to compile down and target more than just CPUs, including producing code that can run on GPUs, TPUs, ASICs and other accelerators. It can also often more effectively use certain types of CPU optimizations directly, like SIMD without direct intervention by the developer like in many other languages.[12][13] According to Jeremy Howard of fast.ai, Mojo can be seen as \"syntax sugar for MLIR\" and for that reason Mojo is well optimized for applications like AI.[14]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "156a181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='You are an expert copywriter with expertize in summarizing documents'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the follwing text:\\n TEXT:{text}')\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4136aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c68396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output = llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5304dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mojo is a new programming language in the Python family that aims to combine the usability of higher level languages like Python with the performance of lower level languages such as C++, Rust, and Zig. It is available on browsers through Jupyter notebooks and locally on Linux and macOS. The Mojo compiler is currently closed source but has an open source standard library. Mojo utilizes the MLIR compiler framework, allowing it to take advantage of higher level compiler passes and target various processors including GPUs, TPUs, and ASICs. Mojo is optimized for applications like AI and is considered \"syntax sugar for MLIR\" by experts.\n"
     ]
    }
   ],
   "source": [
    "print(summary_output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b9da7",
   "metadata": {},
   "source": [
    "### Summarizing using Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532c3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39974ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "Write a concise and short summary of the following text:\n",
    "TEXT: `{text}`\n",
    "Translate the summary to {language}.\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text', 'language'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376d45f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(prompt.format(text=text, language='Odia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ab2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "summary = chain.invoke({'text':text, 'language':'Odia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccf9403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Mojo ଏକ Python ପରିବାରରେ ଉତ୍ପାଦନ କରାଯାଇଛି ପ୍ରୋଗ୍ରାମିଂ ଭାଷା ଯେହେତୁ ଉନ୍ନତ ସ୍ତରର ପ୍ରୋଗ୍ରାମିଂ ଭାଷାଗୁଡ଼ିକ ଯେମିତି Python, ଏହିକୁ C++, Rust, ଓ Zig ପ୍ରକାରର ନିମ୍ନ ସ୍ତରର ପ୍ରୋଗ୍ରାମିଂ ଭାଷାଗୁଡ଼ିକ ଯେମିତି ଉପଯୋଗକରିବା ଲକ୍ଷ୍ୟ ରଖୁଛି।` ଏହି ଉପଲବ୍ଧ ଅଛି ବ୍ରାଉଜରରେ Jupyter ନୋଟବୁକ୍ ମାଧ୍ୟମରେ, ଏବଂ ଲୋକାଲି ଲିନୁକ୍ସ ଓ macOS ଉପର ମୋଜୋ ଉପଲବ୍ଧ ଅଛି। ମୋଜୋ ଏହିକୁ ଉଚ୍ଚ ସ୍ତରର ପ୍ରୋଗ୍ରାମିଂ ଭାଷାଗୁଡ଼ିକର ଉପଯୋଗକରିବା ଯେତେ Python ଏବଂ କିଛି ଅନ୍ଯାନ୍ୟ ପ୍ରୋଗ୍ରାମିଂ ଭାଷାଗୁଡ଼ିକର ପ୍ରଦର୍ଶନକୁ ଯେତେ C++, Rust, ଓ Zig ଯେତେ।` ମୋଜୋ କମ୍ପାଇଲର ଏହି ବର୍ତ୍ତମାନ ବନ୍ଦର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ୍ତରର ସ', 'language': 'Odia'}\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0a69e",
   "metadata": {},
   "source": [
    "### Summarizing using StuffDocumentChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1410b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9575c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents/sj.txt', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "788ceba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40da5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "Write a concise and short summary of the following text.\n",
    "TEXT: `{text}`\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f219812",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f102c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise and short summary of the following text.\n",
      "TEXT: `I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories.\n",
      "\n",
      "The first story is about connecting the dots.\n",
      "\n",
      "I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?\n",
      "\n",
      "It started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy; do you want him?” They said: “Of course.” My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.\n",
      "\n",
      "And 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents’ savings were being spent on my college tuition. After six months, I couldn’t see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn’t interest me, and begin dropping in on the ones that looked interesting.\n",
      "\n",
      "It wasn’t all romantic. I didn’t have a dorm room, so I slept on the floor in friends’ rooms, I returned Coke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let me give you one example:\n",
      "\n",
      "Reed College at that time offered perhaps the best calligraphy instruction in the country. Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed. Because I had dropped out and didn’t have to take the normal classes, I decided to take a calligraphy class to learn how to do this. I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great. It was beautiful, historical, artistically subtle in a way that science can’t capture, and I found it fascinating.\n",
      "\n",
      "None of this had even a hope of any practical application in my life. But 10 years later, when we were designing the first Macintosh computer, it all came back to me. And we designed it all into the Mac. It was the first computer with beautiful typography. If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts. And since Windows just copied the Mac, it’s likely that no personal computer would have them. If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do. Of course it was impossible to connect the dots looking forward when I was in college. But it was very, very clear looking backward 10 years later.\n",
      "\n",
      "Again, you can’t connect the dots looking forward; you can only connect them looking backward. So you have to trust that the dots will somehow connect in your future. You have to trust in something — your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.\n",
      "\n",
      "My second story is about love and loss.\n",
      "\n",
      "I was lucky — I found what I loved to do early in life. Woz and I started Apple in my parents’ garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees. We had just released our finest creation — the Macintosh — a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.\n",
      "\n",
      "I really didn’t know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down — that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me — I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.\n",
      "\n",
      "I didn’t see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.\n",
      "\n",
      "During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the world’s first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple’s current renaissance. And Laurene and I have a wonderful family together.\n",
      "\n",
      "I’m pretty sure none of this would have happened if I hadn’t been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don’t lose faith. I’m convinced that the only thing that kept me going was that I loved what I did. You’ve got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle. As with all matters of the heart, you’ll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don’t settle.\n",
      "\n",
      "My third story is about death.\n",
      "\n",
      "When I was 17, I read a quote that went something like: “If you live each day as if it was your last, someday you’ll most certainly be right.” It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: “If today were the last day of my life, would I want to do what I am about to do today?” And whenever the answer has been “No” for too many days in a row, I know I need to change something.\n",
      "\n",
      "Remembering that I’ll be dead soon is the most important tool I’ve ever encountered to help me make the big choices in life. Because almost everything — all external expectations, all pride, all fear of embarrassment or failure — these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart.\n",
      "\n",
      "About a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas. I didn’t even know what a pancreas was. The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months. My doctor advised me to go home and get my affairs in order, which is doctor’s code for prepare to die. It means to try to tell your kids everything you thought you’d have the next 10 years to tell them in just a few months. It means to make sure everything is buttoned up so that it will be as easy as possible for your family. It means to say your goodbyes.\n",
      "\n",
      "I lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor. I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and I’m fine now.\n",
      "\n",
      "This was the closest I’ve been to facing death, and I hope it’s the closest I get for a few more decades. Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:\n",
      "\n",
      "No one wants to die. Even people who want to go to heaven don’t want to die to get there. And yet death is the destination we all share. No one has ever escaped it. And that is as it should be, because Death is very likely the single best invention of Life. It is Life’s change agent. It clears out the old to make way for the new. Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away. Sorry to be so dramatic, but it is quite true.\n",
      "\n",
      "Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.\n",
      "\n",
      "When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.\n",
      "\n",
      "Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: “Stay Hungry. Stay Foolish.” It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.\n",
      "\n",
      "Stay Hungry. Stay Foolish.\n",
      "\n",
      "Thank you all very much.\n",
      "`\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input_documents': [Document(page_content='I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories.\\n\\nThe first story is about connecting the dots.\\n\\nI dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?\\n\\nIt started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy; do you want him?” They said: “Of course.” My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.\\n\\nAnd 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents’ savings were being spent on my college tuition. After six months, I couldn’t see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn’t interest me, and begin dropping in on the ones that looked interesting.\\n\\nIt wasn’t all romantic. I didn’t have a dorm room, so I slept on the floor in friends’ rooms, I returned Coke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let me give you one example:\\n\\nReed College at that time offered perhaps the best calligraphy instruction in the country. Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed. Because I had dropped out and didn’t have to take the normal classes, I decided to take a calligraphy class to learn how to do this. I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great. It was beautiful, historical, artistically subtle in a way that science can’t capture, and I found it fascinating.\\n\\nNone of this had even a hope of any practical application in my life. But 10 years later, when we were designing the first Macintosh computer, it all came back to me. And we designed it all into the Mac. It was the first computer with beautiful typography. If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts. And since Windows just copied the Mac, it’s likely that no personal computer would have them. If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do. Of course it was impossible to connect the dots looking forward when I was in college. But it was very, very clear looking backward 10 years later.\\n\\nAgain, you can’t connect the dots looking forward; you can only connect them looking backward. So you have to trust that the dots will somehow connect in your future. You have to trust in something — your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.\\n\\nMy second story is about love and loss.\\n\\nI was lucky — I found what I loved to do early in life. Woz and I started Apple in my parents’ garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees. We had just released our finest creation — the Macintosh — a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.\\n\\nI really didn’t know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down — that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me — I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.\\n\\nI didn’t see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.\\n\\nDuring the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the world’s first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple’s current renaissance. And Laurene and I have a wonderful family together.\\n\\nI’m pretty sure none of this would have happened if I hadn’t been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don’t lose faith. I’m convinced that the only thing that kept me going was that I loved what I did. You’ve got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle. As with all matters of the heart, you’ll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don’t settle.\\n\\nMy third story is about death.\\n\\nWhen I was 17, I read a quote that went something like: “If you live each day as if it was your last, someday you’ll most certainly be right.” It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: “If today were the last day of my life, would I want to do what I am about to do today?” And whenever the answer has been “No” for too many days in a row, I know I need to change something.\\n\\nRemembering that I’ll be dead soon is the most important tool I’ve ever encountered to help me make the big choices in life. Because almost everything — all external expectations, all pride, all fear of embarrassment or failure — these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart.\\n\\nAbout a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas. I didn’t even know what a pancreas was. The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months. My doctor advised me to go home and get my affairs in order, which is doctor’s code for prepare to die. It means to try to tell your kids everything you thought you’d have the next 10 years to tell them in just a few months. It means to make sure everything is buttoned up so that it will be as easy as possible for your family. It means to say your goodbyes.\\n\\nI lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor. I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and I’m fine now.\\n\\nThis was the closest I’ve been to facing death, and I hope it’s the closest I get for a few more decades. Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:\\n\\nNo one wants to die. Even people who want to go to heaven don’t want to die to get there. And yet death is the destination we all share. No one has ever escaped it. And that is as it should be, because Death is very likely the single best invention of Life. It is Life’s change agent. It clears out the old to make way for the new. Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away. Sorry to be so dramatic, but it is quite true.\\n\\nYour time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.\\n\\nWhen I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.\\n\\nStewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: “Stay Hungry. Stay Foolish.” It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.\\n\\nStay Hungry. Stay Foolish.\\n\\nThank you all very much.\\n')], 'output_text': 'The speaker shares three stories from his life during a commencement speech. The first story is about dropping out of college, the second is about being fired from the company he co-founded, and the third is about facing a cancer diagnosis. He emphasizes the importance of following one\\'s heart, staying true to oneself, and making the most of life as it is limited. The speech concludes with the message \"Stay Hungry. Stay Foolish.\"'}\n"
     ]
    }
   ],
   "source": [
    "output_summary = chain.invoke(docs)\n",
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769ca0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker shares three stories from his life during a commencement speech. The first story is about dropping out of college, the second is about being fired from the company he co-founded, and the third is about facing a cancer diagnosis. He emphasizes the importance of following one's heart, staying true to oneself, and making the most of life as it is limited. The speech concludes with the message \"Stay Hungry. Stay Foolish.\"\n"
     ]
    }
   ],
   "source": [
    "print(output_summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c3389",
   "metadata": {},
   "source": [
    "### Summarizing Large Documents Using map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fe39465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89c135dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents/sj.txt', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fed74066",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f38b69c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2653"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d581d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=50)\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb4fc23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caad67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae450c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_summary = chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8db94a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs shares three stories from his life in his commencement speech, highlighting the importance of following one's passion, not settling for less, and living each day as if it were your last. He emphasizes the significance of staying hungry and foolish, embracing new opportunities, and following one's intuition. Jobs also references The Whole Earth Catalog's message of staying curious and open-minded.\n"
     ]
    }
   ],
   "source": [
    "print(output_summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfa9d637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt for summarizing each part\n",
    "chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8597e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt for combining the summaries\n",
    "chain.combine_document_chain.llm_chain.prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67059a9f",
   "metadata": {},
   "source": [
    "### Map Reduce with Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e19f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = '''\n",
    "Write a short and concise summary of the following:\n",
    "text: `{text}`\n",
    "CONCISE SUMMARY:\n",
    "'''\n",
    "\n",
    "\n",
    "map_prompt_template = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=map_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e97a9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt = '''\n",
    "Write a concise summary of the following text that covers the key points.\n",
    "Add a title to the summary.\n",
    "Start your summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWED by BULLET POINTS \n",
    "if possible AND end the summary with CONCLUSION PHRASE.\n",
    "Text: `{text}`\n",
    "'''\n",
    "\n",
    "combine_prompt_template = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=combine_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "791679b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=combine_prompt_template,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55c41422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a short and concise summary of the following:\n",
      "text: `I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I’ve ever gotten to a college graduation. Today I want to tell you three stories from my life. That’s it. No big deal. Just three stories.\n",
      "\n",
      "The first story is about connecting the dots.\n",
      "\n",
      "I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?\n",
      "\n",
      "It started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: “We have an unexpected baby boy; do you want him?” They said: “Of course.” My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.\n",
      "\n",
      "And 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents’ savings were being spent on my college tuition. After six months, I couldn’t see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn’t interest me, and begin dropping in on the ones that looked interesting.\n",
      "\n",
      "It wasn’t all romantic. I didn’t have a dorm room, so I slept on the floor in friends’ rooms, I returned Coke bottles for the 5¢ deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let me give you one example:\n",
      "\n",
      "Reed College at that time offered perhaps the best calligraphy instruction in the country. Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed. Because I had dropped out and didn’t have to take the normal classes, I decided to take a calligraphy class to learn how to do this. I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great. It was beautiful, historical, artistically subtle in a way that science can’t capture, and I found it fascinating.\n",
      "\n",
      "None of this had even a hope of any practical application in my life. But 10 years later, when we were designing the first Macintosh computer, it all came back to me. And we designed it all into the Mac. It was the first computer with beautiful typography. If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts. And since Windows just copied the Mac, it’s likely that no personal computer would have them. If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do. Of course it was impossible to connect the dots looking forward when I was in college. But it was very, very clear looking backward 10 years later.\n",
      "\n",
      "Again, you can’t connect the dots looking forward; you can only connect them looking backward. So you have to trust that the dots will somehow connect in your future. You have to trust in something — your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.\n",
      "\n",
      "My second story is about love and loss.\n",
      "\n",
      "I was lucky — I found what I loved to do early in life. Woz and I started Apple in my parents’ garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees. We had just released our finest creation — the Macintosh — a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.\n",
      "\n",
      "I really didn’t know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down — that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me — I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.\n",
      "\n",
      "I didn’t see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.\n",
      "\n",
      "During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the world’s first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple’s current renaissance. And Laurene and I have a wonderful family together.\n",
      "\n",
      "I’m pretty sure none of this would have happened if I hadn’t been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don’t lose faith. I’m convinced that the only thing that kept me going was that I loved what I did. You’ve got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle. As with all matters of the heart, you’ll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don’t settle.\n",
      "\n",
      "My third story is about death.\n",
      "\n",
      "When I was 17, I read a quote that went something like: “If you live each day as if it was your last, someday you’ll most certainly be right.” It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: “If today were the last day of my life, would I want to do what I am about to do today?” And whenever the answer has been “No” for too many days in a row, I know I need to change something.\n",
      "\n",
      "Remembering that I’ll be dead soon is the most important tool I’ve ever encountered to help me make the big choices in life. Because almost everything — all external expectations, all pride, all fear of embarrassment or failure — these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart.\n",
      "\n",
      "About a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas. I didn’t even know what a pancreas was. The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months. My doctor advised me to go home and get my affairs in order, which is doctor’s code for prepare to die. It means to try to tell your kids everything you thought you’d have the next 10 years to tell them in just a few months. It means to make sure everything is buttoned up so that it will be as easy as possible for your family. It means to say your goodbyes.\n",
      "\n",
      "I lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor. I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and I’m fine now.\n",
      "\n",
      "This was the closest I’ve been to facing death, and I hope it’s the closest I get for a few more decades. Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:`\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a short and concise summary of the following:\n",
      "text: `No one wants to die. Even people who want to go to heaven don’t want to die to get there. And yet death is the destination we all share. No one has ever escaped it. And that is as it should be, because Death is very likely the single best invention of Life. It is Life’s change agent. It clears out the old to make way for the new. Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away. Sorry to be so dramatic, but it is quite true.\n",
      "\n",
      "Your time is limited, so don’t waste it living someone else’s life. Don’t be trapped by dogma — which is living with the results of other people’s thinking. Don’t let the noise of others’ opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.\n",
      "\n",
      "When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.\n",
      "\n",
      "Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: “Stay Hungry. Stay Foolish.” It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.\n",
      "\n",
      "Stay Hungry. Stay Foolish.\n",
      "\n",
      "Thank you all very much.`\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text that covers the key points.\n",
      "Add a title to the summary.\n",
      "Start your summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWED by BULLET POINTS \n",
      "if possible AND end the summary with CONCLUSION PHRASE.\n",
      "Text: `The speaker shares three stories from his life during a commencement speech. The first story is about dropping out of college, following his curiosity, and how it led to the design of the Macintosh computer. The second story is about being fired from Apple, starting over, and finding success with NeXT and Pixar. The third story is about facing death after being diagnosed with cancer, and how it changed his perspective on life. The overall message is to trust in following your passion, not settling, and living each day as if it were your last.\n",
      "\n",
      "The text emphasizes the inevitability of death and the importance of living authentically and following one's own intuition. It also references the impact of The Whole Earth Catalog and encourages readers to \"Stay Hungry. Stay Foolish.\" as they embark on new beginnings.`\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = summary_chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfd43b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Trusting Your Passion: Lessons from a Commencement Speech\n",
      "\n",
      "INTRODUCTION:\n",
      "The speaker in the text shares three impactful stories from his life during a commencement speech, highlighting the importance of following one's passion and living authentically.\n",
      "\n",
      "KEY POINTS:\n",
      "- Story 1: Dropping out of college, following curiosity, leading to the design of the Macintosh computer\n",
      "- Story 2: Being fired from Apple, finding success with NeXT and Pixar after starting over\n",
      "- Story 3: Facing death after cancer diagnosis, changing perspective on life\n",
      "\n",
      "CONCLUSION:\n",
      "The text emphasizes the importance of trusting in following one's passion, not settling, and living each day as if it were your last.\n"
     ]
    }
   ],
   "source": [
    "print(output['output_text'])"
   ]
  },
  {
   "attachments": {
    "Screenshot%202024-06-29%20at%203.36.13%E2%80%AFPM.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "50dbf641",
   "metadata": {},
   "source": [
    "### Summarizing using refine chain\n",
    "\n",
    "![Screenshot%202024-06-29%20at%203.36.13%E2%80%AFPM.png](attachment:Screenshot%202024-06-29%20at%203.36.13%E2%80%AFPM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebccbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43a6c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/typing_extensions-4.7.1.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b18347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rakesh.panigrahy/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredPDFLoader('documents/flash_attention.pdf')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e4862b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2205.14135v2 [cs.LG] 23 Jun 2022\\n\\narXiv\\n\\nFLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness\\n\\nTri Dao’, Daniel Y. Fu’, Stefano Ermon\\', Atri Rudra?, and Christopher Ré*\\n\\n‘Department of Computer Science, Stanford University *Department of Computer Science and Engineering, University at Buffalo, SUNY\\n\\n{trid,danfu}@cs.stanford.edu, ermon@stanford.edu, atri@buffalo.edu, chrismre@cs.stanford.edu\\n\\nJune 24, 2022\\n\\nAbstract\\n\\nTransformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. We argue that a missing principle is making attention algorithms JO- aware—accounting for reads and writes between levels of GPU memory. We propose FLASHATTENTION, an IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes between GPU high bandwidth memory (HBM) and GPU on-chip SRAM. We analyze the IO complexity of FLASHATTENTION, showing that it requires fewer HBM accesses than standard attention, and is optimal for a range of SRAM sizes. We also extend FLASHATTENTION to block-sparse attention, yielding an approximate attention algorithm that is faster than any existing approximate attention method. FLASHATTENTION trains Transformers faster than existing baselines: 15% end-to-end wall-clock speedup on BERT-large (seq. length 512) compared to the MLPerf 1.1 training speed record, 3x speedup on GPT-2 (seq. length 1K), and 2.4x speedup on long-range arena (seq. length 1K-4K). FLASHATTENTION and block-sparse FLASHATTENTION enable longer context in Transformers, yielding higher quality models (0.7 better perplexity on GPT-2 and 6.4 points of lift on long-document classification) and entirely new capabilities: the first Transformers to achieve better-than-chance performance on the Path-X challenge (seq. length 16K, 61.4% accuracy) and Path-256 (seq. length 64K, 63.1% accuracy).\\n\\n1 Introduction\\n\\nTransformer models [82] have emerged as the most widely used architecture in applications such as natural language processing and image classification. Transformers have grown larger [5] and deeper [83], bu equipping them with longer context remains difficult [80], since the self-attention module at their hear has time and memory complexity quadratic in sequence length. An important question is whether making attention faster and more memory-efficient can help Transformer models address their runtime and memory challenges for long sequences.\\n\\nMany approximate attention methods have aimed to reduce the compute and memory requirements o attention. These methods range from sparse-approximation [74] to low-rank approximation [12] [50] [84], and their combinations [3} [9] [92]. Although these methods reduce the compute requirements to linear or near-linear in sequence length, many of them do not display wall-clock speedup against standard attention and have not gained wide adoption. One main reason is that they focus on FLOP reduction (which may no correlate with wall-clock speed) and tend to ignore overheads from memory access (IO).\\n\\nIn this paper, we argue that a missing principle is making attention algorithms [O-aware [I]—that is, carefully accounting for reads and writes to different levels of fast and slow memory (e.g., between fast GPU on-chip SRAM and relatively slow GPU high bandwidth memory, or HBM [45], Figure[I] left). On modern\\n\\nOuter Loop\\n\\n—___*_, Ki dxN . Attention on GPT-2 Copy Block to SRAM : Outer Loop Vinxd J Matmul\\n\\na\\n\\n£0\\\\ SRAM: 19 TB/s (20 MB) j 1 | Dropout 1 1 z HBM: 1.5TB/s (40GB) 2 1 1 Copy ©} £10 8 + Compute Block | z a ] Softmax 5 Lat on SRAM lz =| = IO MCISa DRAM: 12.8GB/s £ a 1/3 slF. Fused (CPU DRAM) (>1 TB) I ni Mask Kernel 1 1 3 . S L 4 Matmul Memory Hierarchy with Output to HBM ] Matmu Bandwidth & Memory Size sm(QKV: Nxd PyTorch FlashAttention\\n\\nInner Loop FlashAttention\\n\\nFigure 1: Left: FLASHATTENTION uses tiling to prevent materialization of the large N x N attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), FLASHATTENTION loops through blocks of the K and V matrices and loads them to fast on-chip SRAM. In each block, FLASHATTENTION loops over blocks of Q matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM. Right: Speedup over the PyTorch implementation of attention on GPT-2. FLASHATTENTION does not read and write the large N x N attention matrix to HBM, resulting in an 7.6x speedup on the attention computation.\\n\\nGPUs, compute speed has out-paced memory speed [62] [63], and most operations in Transformers are bottlenecked by memory accesses [43]. IO-aware algorithms have been critical for similar memory-bound operations, when reading and writing data can account for a large portion of the runtime—such as database joins [71], image processing [70], numerical linear algebra [4], and more [40] [85]. However, common Python interfaces to deep learning such as PyTorch and Tensorflow do not allow fine-grained control of memory access.\\n\\nWe propose FLASHATTENTION, a new attention algorithm that computes exact attention with far fewer memory accesses. Our main goal is to avoid reading and writing the attention matrix to and from HBM. This requires (i) computing the softmax reduction without access to the whole input (ii) not storing the large intermediate attention matrix for the backward pass. We apply two well-established techniques to address these challenges. (i) We restructure the attention computation to split the input into blocks and make several passes over input blocks, thus incrementally performing the softmax reduction (also known as tiling). (ii) We store the softmax normalization factor from the forward pass to quickly recompute attention on-chip in the backward pass, which is faster than the standard approach of reading the intermediate attention matrix from HBM. We implement FLASHATTENTION in CUDA to achieve fine-grained control over memory access and fuse all the attention operations into one GPU kernel. Even with the increased FLOPs due to recomputation, our algorithm both runs faster (up to 7.6x on GPT-2 [67], Figure [i]right) and uses less memory—linear in sequence length—than standard attention, thanks to the massively reduced amount of HBM access.\\n\\nWe analyze the IO complexity of FLASHATTENTION, proving that it requires O(N?d?M~!) HBM accesses where d is the head dimension and M is the size of SRAM, as compared to Q(Nd + N?) of standard attention. For typical values of d and M, FLASHATTENTION requires many times fewer HBM accesses compared to standard attention (up to 9x fewer, as shown in Fig.|2). Moreover, we provide a lower bound, showing that no exact attention algorithm can asymptotically improve on the number of HBM accesses over all SRAM sizes.\\n\\nWe also show that FLASHATTENTION can serve as a useful primitive for realizing the potential of approximate attention algorithms by overcoming their issues with memory access overhead. As a proof of concept, we implement block-sparse FLASHATTENTION, a sparse attention algorithm that is 2-4x faster than even FLASHATTENTION, scaling up to sequence length of 64k. We prove that block-sparse FLASHATTENTION has better IO complexity than FLASHATTENTION by a factor proportional to the sparsity ratio. We discuss further extensions to other operations (attention on multi-GPU, kernel regression, block-sparse matrix\\n\\nmultiply) in Section [5] We open-source FLASHATTENTION to make it easier to build on this primitive[}]\\n\\nWe empirically validate that FLASHATTENTION speeds up model training and improves model quality by modeling longer context. We also benchmark the runtime and memory footprint of FLASHATTENTION and block-sparse FLASHATTENTION compared to prior attention implementations.\\n\\ne Faster Model Training. FLASHATTENTION trains Transformer models faster in wall-clock time. We train BERT-large (seq. length 512) 15% faster than the training speed record in MLPerf 1.1 [58], GPT2 (seq. length 1K) 3x faster than baseline implementations from HuggingFace [87] and Megatron-LM [77], and long-range arena (seq. length 1K-4K) 2.4x faster than baselines.\\n\\ne Higher Quality Models. FLASHATTENTION scales Transformers to longer sequences, which improves their quality and enables new capabilities. We observe a 0.7 improvement in perplexity on GPT-2 and 6.4 points of lift from modeling longer sequences on long-document classification [13]. FLASHATTENTION enables the first Transformer that can achieve better-than-chance performance on the Path-X challenge, solely from using a longer sequence length (16K). Block-sparse FLASHATTENTION enables a Transformer to scale to even longer sequences (64K), resulting in the first model that can achieve better-than-chance performance on Path-256.\\n\\ne Benchmarking Attention. FLASHATTENTION is up to 3x faster than the standard attention implemen- tation across common sequence lengths from 128 to 2K and scales up to 64K. Up to sequence length of 512, FLASHATTENTION is both faster and more memory-efficient than any existing attention method, whereas for sequence length beyond 1K, some approximate attention methods (e.g., Linformer) start to become faster. On the other hand, block-sparse FLASHATTENTION is faster than all existing approximate attention methods that we know of.\\n\\n2 Background\\n\\nWe provide some background on the performance characteristics of common deep learning operations on modern hardware (GPUs). We also describe the standard implementation of attention.\\n\\n2.1 Hardware Performance\\n\\nWe focus here on GPUs. Performance on other hardware accelerators are similar [46] [48].\\n\\nGPU Memory Hierarchy. The GPU memory hierarchy (Fig. [i] left) comprises multiple forms of memory of different sizes and speeds, with smaller memory being faster. As an example, the A100 GPU has 40-80GB of high bandwidth memory (HBM) with bandwidth 1.5-2.0TB/s and 192KB of on-chip SRAM er each of 108 streaming multiprocessors with bandwidth estimated around 19TB/s . The on-chip SRAM is an order of magnitude faster than HBM but many orders of magnitude smaller in size. As compute has gotten faster relative to memory speed [61] [63], operations are increasingly bottlenecked by memory (HBM) accesses. Thus exploiting fast SRAM becomes more important.\\n\\nExecution Model. GPUs have a massive number of threads to execute an operation (called a kernel).\\n\\nEach kernel loads inputs from HBM to registers and SRAM, computes, then writes outputs to HBM.\\n\\nPerformance characteristics. Depending on the balance of computation and memory accesses, op-\\n\\nerations can be classified as either compute-bound or memory-bound. This is commonly measured by the\\n\\narithmetic intensity ; which is the number of arithmetic operations per byte of memory ac\\n\\n. Compute-bound: the time taken by the operation is determined by how many arithmetic operations there are, while time accessing HBM is much smaller. Typical examples are matrix multiply with large inner dimension, and convolution with large number of channels.\\n\\n2. Memory-bound: the time taken by the operation is determined by the number of memory accesses, while time spent in computation is much smaller. Examples include most other operations: elementwise (e.g., activation, dropout), and reduction (e.g., sum, softmax, batch norm, layer norm).\\n\\nKernel fusion. The most common approach to accelerate memory-bound operations is kernel fusion: if there are multiple operations applied to the same input, the input can be loaded once from HBM, instead of\\n\\nmultiple times for each operation. Compilers can automatically fuse many elementwise operations [75].\\n\\n1PLASHATTENTION code is available at https: //github.com/HazyResearch/flash- attention\\n\\nw\\n\\nHowever, in the context of model training, the intermediate values still need to be written to HBM to save for the backward pass, reducing the effectiveness of naive kernel fusion.\\n\\n2.2 Standard Attention Implementation\\n\\nGiven input sequences Q, K, V ¢ R‘*¢ where N is the sequence length and d is the head dimension, we want to compute the attention output O « RN*4:\\n\\nS=QK™ «R**, P=softmax(S)—«RY*Y, O=PVeERN*,\\n\\nwhere softmax is applied row-wise.\\n\\nStandard attention implementations materialize the matrices § and P to HBM, which takes O(N?) memory. Often N > d (e.g., for GPT2, N = 1024 and d = 64). We describe the standard attention implementation in Algorithm |0| As some or most of the operations are memory-bound (e.g., softmax), the large number of memory accesses translates to slow wall-clock time.\\n\\nThis problem is exacerbated by other elementwise operations applied to the attention matrix, such as masking applied to S or dropout applied to P. As a result, there have been many attempts to fuse several elementwise operations, such as fusing masking with softmax [77].\\n\\nIn Section [3.2] we will show that the standard attention implementation performs HBM accesses quadratic in the sequence length N. We also compare the number of FLOPs and number of HBM accesses of standard attention and of our method (FLASHATTENTION).\\n\\nAlgorithm 0 Standard Attention Implementation\\n\\nRequire: Matrices Q,K, V ¢ R‘*¢ in HBM. 1: Load Q,K by blocks from HBM, compute § = QK\", write S to HBM. 2: Read S from HBM, compute P = softmax(S), write P to HBM. 3: Load P and V by blocks from HBM, compute O = PV, write O to HBM. 4: Return O.\\n\\n3. FLASHATTENTION: Algorithm, Analysis, and Extensions\\n\\nWe show how to compute exact attention with fewer HBM reads/writes and without storing large intermediate matrices for the backward pass. This yields an attention algorithm that is both memory efficient and faster in wall-clock time. We analyze its IO complexity, showing that our method requires much fewer HBM accesses compared to standard attention. We further show that FLASHATTENTION can serve as a useful primitive by extending it to handle block-sparse attention.\\n\\nWe focus here on the forward pass for ease of exposition; Ap pendix [B] contains details for the backward.\\n\\n3.1 An Efficient Attention Algorithm With Tiling and Recomputation\\n\\nGiven the inputs Q, K, V ¢ R“*¢ in HBM, we aim to compute the attention output O ¢ RN*4 and write it to HBM. Our goal is to reduce the amount of HBM accesses (to sub-quadratic in N).\\n\\nWe apply two established techniques (tiling, recomputation) to overcome the technical challenge of computing exact attention in sub-quadratic HBM accesses. We describe this in Algorithm [I] The main idea is that we split the inputs Q, K, V into blocks, load them from slow HBM to fast SRAM, then compute the attention output with respect to those blocks. By scaling the output of each block by the right normalization factor before adding them up, we get the correct result at the end.\\n\\nTiling. We compute attention by blocks. Softmax couples columns of K, so we decompose the large softmax with scaling (66). For numerical stability, the softmax of vector x € R? is computed as:\\n\\nFQ) €(x)\"\\n\\nm(x):=max x;, f(x) := [en-m) Lee exam(x) | > Oxy:= » f(x), softmax(x) :=\\n\\nFor vectors x“, x2) € R8, we can decompose the softmax of the concatenated x = [x x)] € R? as:\\n\\nm(x) = m([x@ x®@]) = max(m(x), m(x)), f= [ems >-m09 Fe) ers) -m(s) #(¢))] ;\\n\\nf(x) = e(fx x)]) = er x)-m(x) £1) $ eM) mx) ¢(2)), softmax(x) = fo. Therefore if we keep track of some extra statistics (m(x), €(x)), we can compute softmax one block at a time We thus split the inputs Q, K, V into blocks (Algorithm ine 3) , compute the softmax values along with extra statistics (Algorithm [I] line [T0), and combine the results (Algorithm [I] ine [12)\\n\\nRecomputation. One of our goals is to not store O(N?) intermediate values for the backward pass. The backward pass typically requires the matrices §,P ¢ RY** to compute the gradients with respect to Q,K, V. However, by storing the output O and the softmax normalization statistics (m, £), we can recompute the attention matrix § and P easily in the backward pass from blocks of Q, K, V in SRAM. This can be seen as a form of selective gradient checkpointing [10] [34]. While gradient checkpointing has been suggested to reduce the maximum amount of memory required [66], all implementations (that we know off) have to trade speed for memory. In contrast, even with more FLOPs, our recomputation speeds up the backward pass due to reduced HBM accesses (Fig. |2). The full backward pass description is in Appendix [B]\\n\\nImplementation details: Kernel fusion. Tiling enables us to implement our algorithm in one CUDA kernel, loading input from HBM, performing all the computation steps (matrix multiply, softmax, optionally masking and dropout, matrix multiply), then write the result back to HBM (masking and dropout in Appendix [B). This avoids repeatedly reading and writing of inputs and outputs from and to HBM.\\n\\nAlgorithm 1 FLAsHATTENTION\\n\\nRequire: Matrices Q,K, V ¢ R“*¢ in HBM, on-chip SRAM of size M. 1: Set block sizes B. =[4], B, = min (41. d). 2: Initialize O = (0)vxa € RN*4, € = (0)w € RY, m = (-co)y € RN in HBM. 3: Divide Q into T, = [| blocks Qi,...,Qz, of size B, x d each, and divide K, V in to T, = [3] blocks K,,..., Ky, and Vj,..., Vz., of size B. x d each. 4: Divide O into T, blocks O;,...,O7, of size B, x d each, divide ¢ into T, blocks €,..., &, of size B- each, divide m into T, blocks m,,...,my, of size B, each. for 1 <j<T. do 6: Load Kj, V; from HBM to on-chip SRAM. 7 forl<i<T, do\\n\\non\\n\\n8: Load Q;, 0;, €;,m; from HBM to on-chip SRAM.\\n\\n9: On chip, compute $,; = QiK7 € RErxBe |\\n\\n10: On chip, compute mj; = rowmax(S;;) € R?, P;; = exp(Sij — mij) € R8*Fe (pointwise), bij = rowsum(P;;) eR.\\n\\n11: On chip, compute m?°” = max(mj;, mij) € R?, Epew = emt sme emir G5 eR.\\n\\n12: Write 0; — diag(£r\")\"! (diag(£)e™ \"0; + e-\"™\"\"B, -V;) to HBM.\\n\\n13: Write €; — €P°\", m; — m7?\" to HBM.\\n\\n14: end for 15: end for 16: Return O.\\n\\nWe show FLASHATTENTION’s correctness, runtime, and memory requirement (proof in Appendix\\n\\nTheorem 1. Algorithm{]] returns O = softmax(QK\")V with O(N?d) FLOPs and requires O(N) additional memory beyond inputs and output.\\n\\n3.2 Analysis: IO Complexity of FLASHATTENTION\\n\\nWe analyze the IO complexity of FLASHATTENTION, showing significant reduction in HBM accesses compared to standard attention. We also provide a lower bound, proving that no exact attention algorithm can\\n\\nThis style of aggregation is called algebraic aggregation [33].\\n\\nEffect of Block Size Sparsity Speedup\\n\\n= V6 = € Dense Attention _| Standard FLASHATTENTION. 3 4 655 1597 FlashAttention = a @ GFLOPs 66.6 75.2 é runtime 5 B10 —o HBM R/W (GB) 40.3 44 2244 5 + x os Runtime (ms) ALT 73 s |“ 22 ¥ 50 oo aS t F} iva = 64128 256 512 2 20 60 Block Size % Non-Zero Blocks\\n\\nFigure 2: Left: Forward + backward runtime of standard attention and FLASHATTENTION for GPT-2 medium (seq. length 1024, head dim. 64, 16 heads, batch size 64) on A100 GPU. HBM access is the primary factor affecting runtime. Middle: Forward runtime of FLASHATTENTION (seq. length 1024, head dim. 64, 16 heads, batch size 64) on A100 GPU. Fewer HBM accesses result in faster runtime, up to a point. Right: The runtime (for seq. length 4K) of block-sparse FLASHATTENTION is faster than FLASHATTENTION by a factor proportional to the sparsity.\\n\\nasymptotically improve on HBM accesses over all SRAM sizes. Proofs are in Appendix [C]\\n\\nTheorem 2. Let N be the sequence length, d be the head dimension, and M be size of SRAM withd < M < Nd. Standard attention (Algorithm|0) requires @(Nd +N?) HBM accesses, while FLASHATTENTION (Algorithm|1) requires @(N?d?M~-!) HBM accesses.\\n\\nFor typical values of d (64-128) and M (around 100KB), d? is many times smaller than M, and thus FLASHATTENTION requires many times fewer HBM accesses than standard implementation. This leads to both faster execution and lower memory footprint, which we validate in Section [£.3}\\n\\nThe main idea of the proof is that given the SRAM size of M, we can load blocks of K, V of size @(M) each (Algorithm []]line|6). For each block of K and V, we iterate over all blocks of Q (Algorithm [I] ]ine[8) to compute the intermediate values, resulting in @(NdM~\\') passes over Q. Each pass loads @(Nd) elements, which amounts to @(N?d?M~!) HBM accesses. We similarly prove that the backward pass of standard attention requires @(Nd + N?) HBM accesses while the backward pass of FLASHATTENTION requires @(N?d?M~!) HBM accesses (Appendix[B).\\n\\nWe prove a lower-bound: one cannot asymptotically improve on the number of HBM accesses for all values of M (the SRAM size) when computing exact attention.\\n\\nProposition 3. Let N be the sequence length, d be the head dimension, and M be size of SRAM with d<M<Nd. There does not exist an algorithm to compute exact attention with o(N?d?M~!) HBM accesses for all M in the range [d, Nd].\\n\\nThe proof relies on the fact that for M = @(Nd) any algorithm must perform Q(N?d?M7!) = Q(Nd) HBM accesses. This type of lower bound over a subrange of M is common in the streaming algorithms iterature [88]. We leave proving parameterized complexity [27] lower bounds in terms of M as exciting future work.\\n\\nWe validate that the number of HBM accesses is the main determining factor of attention run-time. n Fig. 2] (eft), we see that even though FLASHATTENTION has higher FLOP count compared to standard attention (due to recomputation in the backward pass), it has much fewer HBM accesses, resulting in much faster runtime. In Fig. |2|(middle), we vary the block size B. of FLASHATTENTION, which results in different amounts of HBM accesses, and measure the runtime of the forward pass. As block size increases, the number of HBM accesses decreases (as we make fewer passes over the input), and runtime decreases. For large enough block size (beyond 256), the runtime is then bottlenecked by other factors (e.g., arithmetic operations). Moreover, larger block size will not fit into the small SRAM size.\\n\\n3.3 Extension: Block-Sparse FLASHATTENTION\\n\\nWe extend FLASHATTENTION to approximate attention: we propose block-sparse FLASHATTENTION, whose IO complexity is smaller than FLASHATTENTION by a factor proportional to the sparsity. Given inputs Q,K, V ¢ R‘*4 and a mask matrix M € {0,1}%*\", we want to compute:\\n\\nS=QK™eR*\", P=softmax(SO 14) €RY*Y, O=PVeERN*4,\\n\\nwhere (S$ © 1y,)x1 = Sxi if My, = 1 and —co if My; = 0. We require M to have block form: for some block sizes B,, Be, for all k,l, Mx. = Mi; with i = |k/B,], j = |1/Be] for some M € {0, 1}/BrxN/Be,\\n\\nGiven a predefined block sparsity mask M ¢€ {0, 1}%/8r*N/8e we can easily adapt Algorithm [1] to only compute the nonzero blocks of the attention matrix. The algorithm is identical to Algorithm [I] except we skip zero blocks. We reproduce the algorithm description in Algorithm [5]in Appendix [B]\\n\\nWe also analyze the IO complexity of block-sparse FLASHATTENTION.\\n\\nProposition 4. Let N be the sequence length, d be the head dimension, and M be size of SRAM with d<M<Nd. Block-sparse FLASHATTENTION (Algorithm |[5) requires @(Nd + N?d?M~\\'s) HBM accesses where s is the fraction of nonzero blocks in the block-sparsity mask.\\n\\nWe see that applying block-sparsity yields a direct improvement by the sparsity to the larger term in the IO complexity. For large sequence lengths N, s is often set to N~!/? or N-! log N [92], resulting in @(NVN) or O(N log N) IO complexity. For downstream experiments, we use the fixed butterfly sparsity pattern [17], which has been shown to be able to approximate arbitrary sparsity [16]. i (right), we validate that as the sparsity increases, the runtime of block-sparse FLASHATTENTION improves proportionally. On the LRA benchmark, block-sparse FLASHATTENTION achieves 2.8x speedup, while performing on par with standard attention (Section [4).\\n\\n4 Experiments\\n\\nWe evaluate the impact of using FLASHATTENTION to train Transformer models. We validate two claims\\n\\nabout training time and model accuracy, and report attention runtime and memory benchmarks.\\n\\ne Training Speed. FLASHATTENTION outperforms the MLPerf 1.1 speed record for BERT by 15%, and speeds up GPT-2 up to 3x over HuggingFace [87] and 1.8x over Megatron [77] over standard Transformers. FLASHATTENTION speeds up the long-range arena (LRA) benchmark 2.4x.\\n\\ne Quality. FLASHATTENTION scales Transformers to longer sequences, yielding higher quality. FLASHAT- TENTION trains GPT-2 with context length 4K faster than Megatron trains GPT-2 with context length 1K, while achieving 0.7 better perplexity. Modeling longer sequences yields 6.4 points of lift on two long- document classification tasks. Finally, FLASHATTENTION yields the first Transformer that can achieve better-than-random performance on the challenging Path-X task (sequence length 16K), and block-sparse FLASHATTENTION yields the first sequence model that we know of that can achieve better-than-random performance on Path-256 (sequence length 64K).\\n\\ne Benchmarking Attention. We measure the runtime and memory performance of FLASHATTENTION and block-sparse FLASHATTENTION based on sequence length. We confirm that the memory footprint of FLASHATTENTION scales linearly with seq. length and is up to 3x faster than standard attention for common seq. lengths (up to 2K). We confirm that runtime of block-sparse FLASHATTENTION scales linearly in seq. length and is faster than all existing approximate attention baselines.\\n\\nAdditional experiment details are in Appendix |[E]\\n\\n4.1 Faster Models with FLASHATTENTION\\n\\nBERT. FLASHATTENTION yields the fastest single-node BERT training speed that we know of. We train a BERT-large [22] model with FLASHATTENTION on Wikipedia. Table[i] compares our training time to the implementation from Nvidia that set the training speed record for MLPerf 1.1 [58]. Our implementation is 15% faster.\\n\\nTable 1: Training time of BERT-large, starting from the same initialization provided by the MLPerf benchmark, to reach the target accuracy of 72.0% on masked language modeling. Averaged over 10 runs on 8xA100 GPUs.\\n\\nBERT Implementation | Training time (minutes) Nvidia MLPerf 1.1 20.0 41.5 FLASHATTENTION (ours) 17.4414\\n\\nGPT-2. FLASHATTENTION yields faster training times for GPT-2 [67] on the large OpenWebtext dataset [32] than the widely used HuggingFace and Megatron-LM [77] implementations. Table] shows up to 3x end- to-end speedup compared to Huggingface and 1.7x speedup compared to Megatron-LM. FLASHATTENTION\\n\\nachieves the same perplexity as the other two implementations, as we do not change the model definition. Appendix|E] ncludes plots of the validation perplexity throughout training, confirming that FLASHATTENTION is as numerically stable as the baselines and produces the same training / validation curves.\\n\\nTable 2: GPT-2 small and medium using FLASHATTENTION achieve up to 3x speed up compared to Huggingface implementation and up to 1.7x compared to Megatron-LM. Training time reported on 8xA100s GPUs.\\n\\nModel implementations OpenWebText (ppl) Training time (speedup) GPT-2 small - Huggingface 18.2 9.5 days (1.0x) GPT-2 small - Megatron-LM [77] 18.2 4.7 days (2.0x) GPT-2 small - FLASHATTENTION 18.2 2.7 days (3.5x) GPT-2 medium - Huggingface [87] 14.2 21.0 days (1.0x) GPT-2 medium - Megatron-LM [77] 14.3 11.5 days (1.8x) GPT-2 medium - FLASHATTENTION 14.3 6.9 days (3.0x)\\n\\nLong-range Arena. We compare vanilla Transformer (with either standard implementation or FLASHAT- TENTION) on the long-range arena (LRA [80]) benchmark. We measure accuracy, throughput, and training time of all models. Each task has a different sequence length varying between 1024 and 4096. We follow the implementation and experimental setting in Tay et al. [80Jand Xiong et al. pol] Table|3}shows that FLASHAT- TENTION achieves up 2.4x speed-up compared to standard attention. Block-sparse FLASHATTENTION is faster than all of the approximate attention methods that we have tested.\\n\\nTable 3: The performance of standard attention, FLASHATTENTION, block-sparse FLASHATTENTION, and approximate attention baselines on the Long-Range-Arena benchmarks.\\n\\nModels ListOps Text Retrieval Image Pathfinder | Avg | Speedup\\n\\nTransformer 36.0 63.6 81.6 42.3 72.7 59.3 -\\n\\nFLASHATTENTION 37.6 63.9 81.4 43.5 72.7 59.8 2.4x\\n\\nBlock-sparse FLASHATTENTION 37.0 63.0 81.3 43.6 73.3 59.6 2.8x\\n\\nLinformer [84] 35.6 55.9 77.7 37.8 67.6 54.9 2.5x\\n\\nLinear Attention 38.8 63.2 80.7 42.6 72.5 59.6 2.3x\\n\\nPerformer [12] 36.8 63.6 82.2 42.1 69.9 58.9 1.8x\\n\\nLocal Attention [80] 36.1 60.2 76.7 40.6 66.6 56.0 1.7x\\n\\nReformer 36.5 63.8 78.5 39.6 69.4 57.6 1.3x\\n\\nSmyrf [19] 36.1 64.1 79.0 39.6 70.5 57.9 1.7x\\n\\n4.2 Better Models with Longer Sequences\\n\\nLanguage Modeling with Long Context. The runtime and memory-efficiency of FLASHATTENTION allow us to increase the context length of GPT-2 by 4x while still running faster than the optimized implementation from Megatron-LM. Table [4] shows that that GPT-2 with FLASHATTENTION and context length 4K is still 30% faster than GPT-2 from Megatron with context length 1K, while achieving 0.7 better perplexity.\\n\\nTable 4: GPT-2 small with FLASHATTENTION, with 4x larger context length compared to Megatron-LM, is still 30% faster while achieving 0.7 better perplexity. Training time on 8xA100 GPUs is reported.\\n\\nModel implementations | Context length OpenWebText (ppl) Training time (speedup) GPT-2 small - Megatron-LM 1 18.2 4.7 days (1.0x) GPT-2 small - FLASHATTENTION 1 18.2 2.7 days (1.7x) GPT-2 small - FLASHATTENTION 2 17.6 3.0 days (1.6x) GPT-2 small - FLASHATTENTION 4 17.5 3.6 days (1.3x)\\n\\nLong Document Classification. Training Transformers with longer sequences with FLASHATTENTION improves performance on the MIMIC-III [47] and ECtHR [6] [7] datasets. MIMIC-III contains intensive care unit patient discharge summaries, each annotated with multiple labels. ECtHR contains legal cases from the\\n\\n3LRA accuracy results are known to be highly dependent on the tuning procedure {90}. Our reproduced baselines perform better than as reported in the original comparison [80].\\n\\nAttention Runtime (Fwd Pass + Bwd Pass) Attention Memory Usage\\n\\na 10? 2 Z Crossover Points z 20 = Q 2 3° £ 2 10 2 > 20x 2 8 & G 128 256 512 1024 2048 4096 8192 = 256 8K 16K 32K 64K Sequence Length Sequence Length = *=** FlashAttention === PyTorch Attention === Linformer Attention = mmm Block-Sparse FlashAttention Megatron Attention === = OpenAl Sparse Attention\\n\\nFigure 3: Left: runtime of forward pass + backward pass. Right: attention memory usage.\\n\\nEuropean Court of Human Rights, each of which is mapped to articles of the Convention of Human Rights that were allegedly violaged. Both of these datasets contain very long text documents; the average number of tokens in MIMIC is 2,395 tokens, and the longest document contains 14,562 tokens, while the average and longest numbers in ECtHR are 2,197 and 49,392, respectively. We evaluate lift from increasing the sequence length of a pretrained RoBERTa model [56] (we repeat the positional embeddings, as in Beltagy et al. [3]). Table [5] shows that sequence length 16K outperforms length 512 by 4.3 points on MIMIC, and that length\\n\\n8K outperforms length 512 by 8.5 points on ECtHR. The discrepancies may be due to subtle distribution shifts: MIMIC-II contains specialized medical text and thus may be more susceptible to a distribution shift in the document length, whereas ECtHR contains general language.\\n\\nTable 6: We report the first Transformer\\n\\nmodel that can achieve non-random perfor-\\n\\nmance on Path-X and Path-256.\\n\\nTable 5: Long Document performance (mi- cro F) at different sequence lengths using\\n\\nPath-X__ Path-256 FLASHATTENTION. x x x x\\n\\n512 10242048 4096819216384 en riormer Th x x\\n\\nMIMICIN G7] [52.8 50.7 517 546 564 57.1 Local Attenti x x ECtHR [6] | 72.2 74.3 77.1 78.6 80.7 79.2 cat Miter x x\\n\\nx x\\n\\nSHATTENTION 61.4 x\\n\\nBlock-sparse FLASHATTENTION | 56.0 63.1\\n\\nPath-X and Path-256. The Path-X and Path-256 benchmarks are challenging tasks from the long-range arena benchmark designed to test long context. The task is to classify whether two points in a black and white 128x128 (or 256x256) image have a path connecting them, and the images are fed to the transformer one pixel at a time. In prior work, all transformer models have either run out of memory, or only achieved random performance [80]. There has been a search for alternative architectures that can model such long context [37]. We present here the first result of Transformer models being able to solve Path-X and Path-256 (Table [6). We pretrain a transformer on Path-64, and then transfer to Path-X by spatially interpolating the positional embeddings. FLASHATTENTION achieves 61.4 accuracy on Path-X. Additionally, block-sparse FLASHATTENTION enables the Transformers to scale to sequence length 64K, achieving 63.1 accuracy] on Path-256.\\n\\n4.3 Benchmarking Attention\\n\\nWe vary sequence length and measure runtime and memory usage of FLASHATTENTION and block-sparse FLASHATTENTION against various attention baselines on one A100 GPU with 40 GB HBM, with dropout and a padding mask. We compare against reference implementations for exact attention, approximate attention, and sparse attention. We report a subset of baselines in the main body; Appendix [E] contains more baselines and full details.\\n\\n4Path-256 requires longer sequences but has relatively shorter paths than Path-X, so it is easier to obtain a higher accuracy.\\n\\nRuntime. Figure [3] (left) reports the runtime in milliseconds of the forward + backward pass of FLASHAT- TENTION and block-sparse FLASHATTENTION compared to the baselines in exact, approximate, and sparse attention (exact numbers in Appendix |E}. Runtime grows quadratically with sequence length, but FLASHAT- TENTION runs significantly faster than exact attention baselines, up to 3x faster than the PyTorch implementation. The runtimes of many approximate/sparse attention mechanisms grow linearly with se- quence length, but FLASHATTENTION still runs faster than approximate and sparse attention for short sequences due to fewer memory accesses. The approximate attention runtimes begin to cross over with FLASHATTENTION at sequences between 512 and 1024. On the other hand, block-sparse FLASHATTENTION is faster than all implementations of exact, sparse, and approximate attention that we know of, across all sequence lengths.\\n\\nMemory Footprint. Figure [3] (right) shows the memory footprint of FLASHATTENTION and block-sparse FLASHATTENTION compared to various exact, approximate, and sparse attention baselines. FLASHATTENTION and block-sparse FLASHATTENTION have the same memory footprint, which grows linearly with sequence length. FLASHATTENTION is up to 20x more memory efficient than exact attention baselines, and is more memory-efficient than the approximate attention baselines. All other algorithms except for Linformer run out of memory on an A100 GPU before 64K, and FLASHATTENTION is still 2x more efficient than Linformer.\\n\\n5 Limitations and Future Directions\\n\\nWe discuss limitations of our approach and future directions. Related work is given in Appendix [A]\\n\\nCompiling to CUDA. Our current approach to building IO-aware implementations of attention requires writing a new CUDA kernel for each new attention implementation. This requires writing the attention algorithm in a considerably lower-level language than PyTorch, and requires significant engineering effort. Implementations may also not be transferrable across GPU architectures. These limitations suggest the need for a method that supports writing attention algorithms in a high-level language (e.g., PyTorch), and compiling to IO-aware implementations in CUDA—-similar to efforts such as Halide in image processing [70].\\n\\nIO-Aware Deep Learning. We believe that the IO-aware approach can extend beyond attention. Attention is the most memory-intensive computation in Transformers, but every layer in a deep network touches GPU HBM. We hope our work inspires IO-aware implementations of additional modules. We discuss these potential extensions in Appendix [D]\\n\\nMulti-GPU IO-Aware Methods. Our IO-aware implementation of attention is optimal within con- stants for computing attention on a single GPU. However, the attention computation may be parallelizable across multiple GPUs [72]. Using multiple GPUs adds an additional layer to IO analysis—accounting for data transfer between GPUs. We hope our work inspires future work in this direction.\\n\\nAcknowledgments\\n\\nOur implementation uses Apex’s FMHA code (https: //github.com/NVIDIA/apex/tree/master/apex/\\n\\nas a starting point. We thank Young-Jun Ko for the in-depth explanation of his FMHA implementation and for his thoughtful answers to our questions about CUDA. We thank Sabri Eyuboglu, Megan Leszczynski, Laurel Orr, Yuhuai Wu, Beidi Chen, and Xun Huang for their constructive feedback and suggestions on early drafts of the paper. We thank Markus Rabe and Charles Staats for helpful discussion of their attention algorithm.\\n\\nWe gratefully acknowledge the support of NIH under No. U54EB020405 (Mobilize), NSF under Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), and 1937301 (RTML); ARL under No, W911NF-21-2-0251 (Interactive Human-AI Teaming); ONR under No. N000141712266 (Unifying Weak Supervision); ONR N00014-20-1-2480: Understanding and Applying Non-Euclidean Geometry in Machine Learning; N000142012275 (NEPTUNE); NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, Google Cloud, Salesforce, Total, the HAI-GCP & HAI-Azure Cloud Credits for Research program, the Stanford Data Science Initiative (SDSI), Department of Defense (DoD) through the National Defense Science and Engineering Graduate Fellowship (NDSEG) Program, and members of the Stanford DAWN project: Facebook, Google, and VMWare. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes\\n\\n10\\n\\nnotwithstanding any copyright notation thereon. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of NIH, ONR, or the U.S. Government. Atri Rudra’s research is supported by NSF grant CCF-1763481.\\n\\nReferences\\n\\n1\\n\\n10\\n\\n11\\n\\n12\\n\\n13\\n\\n14\\n\\nAlok Aggarwal and § Vitter, Jeffrey. The input/output complexity of sorting and related problems. Communications of the ACM, 31(9):1116-1127, 1988.\\n\\nIrwan Bello. LambdaNetworks: Modeling long-range interactions without attention. arXiv preprint ar Xiv:2102.08602, 2021.\\n\\nIz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150, 2020.\\n\\nL Susan Blackford, Antoine Petitet, Roldan Pozo, Karin Remington, R Clint Whaley, James Demmel, Jack Dongarra, Iain Duff, Sven Hammarling, Greg Henry, et al. An updated set of basic linear algebra subprograms (blas). ACM Transactions on Mathematical Software, 28(2):135-151, 2002.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.\\n\\nTlias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. Neural legal judgment prediction in English. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4317-4323, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1424.\\n\\nURL |https://www.aclweb.org/anthology/P19- 1424\\n\\nIlias Chalkidis, Manos Fergadiotis, Dimitrios Tsarapatsanis, Nikolaos Aletras, Jon Androutsopoulos, and Prodromos Malakasiotis. Paragraph-level rationale extraction through regularization: A case study on european court of human rights cases. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics, Mexico City, Mexico, 2021. Association for Computational Linguistics.\\n\\nBenjamin Charlier, Jean Feydy, Joan Alexis Glaunés, Frangois-David Collin, and Ghislain Durif. Kernel operations on the gpu, with autodiff, without memory overflows. Journal of Machine Learning Research, 22(74):1-6, 2021. URL |http://jmlr. org/papers/v22/20-275.html\\n\\nBeidi Chen, Tri Dao, Eric Winsor, Zhao Song, Atri Rudra, and Christopher Ré. Scatterbrain: Unifying sparse and low-rank attention. In Advances in Neural Information Processing Systems (NeurIPS), 2021.\\n\\nTianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear memory cost. arXiv preprint arXiv:1604.06174, 2016.\\n\\nRewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse transformers. arXiv preprint arXiv:1904.10509, 2019.\\n\\nKrzysztof Marcin Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Quincy Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking attention with performers. In International Conference on Learning Representations (ICLR), 2020.\\n\\nXiang Dai, Ilias Chalkidis, Sune Darkner, and Desmond Elliott. Revisiting transformer-based models for long document classification. arXiv preprint arXiv:2204.06683, 2022.\\n\\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime G Carbonell, Quoc Le, and Ruslan Salakhutdinov. Transformer-XL: Attentive language models beyond a fixed-length context. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2978-2988, 2019.\\n\\n11\\n\\n15\\n\\n16\\n\\n17\\n\\n18\\n\\n19\\n\\n20\\n\\n21\\n\\n22\\n\\n23\\n\\n24\\n\\n25\\n\\n26\\n\\n27 28\\n\\n29\\n\\n30\\n\\n31\\n\\n32\\n\\nTri Dao, Albert Gu, Matthew Eichhorn, Atri Rudra, and Christopher Ré. Learning fast algorithms for linear transforms using butterfly factorizations. In International Conference on Machine Learning\\n\\n(ICML), 2019.\\n\\nTri Dao, Nimit Sohoni, Albert Gu, Matthew Eichhorn, Amit Blonder, Megan Leszczynski, Atri Rudra, and Christopher Ré. Kaleidoscope: An efficient, learnable representation for all structured linear maps. In International Conference on Learning Representations (ICLR), 2020.\\n\\nTri Dao, Beidi Chen, Kaizhao Liang, Jiaming Yang, Zhao Song, Atri Rudra, and Christopher Ré. Pixelated butterfly: Simple and efficient sparse training for neural network models. In International Conference on Learning Representations (ICLR), 2022.\\n\\nTri Dao, Beidi Chen, Nimit Sohoni, Arjun Desai, Michael Poli, Jessica Grogan, Alexander Liu, Aniruddh Rao, Atri Rudra, and Christopher Ré. Monarch: Expressive structured matrices for efficient and accurate training. In International Conference on Machine Learning (ICML), 2022.\\n\\nGiannis Daras, Nikita Kitaev, Augustus Odena, and Alexandros G Dimakis. Smyrf-efficient attention using asymmetric clustering. Advances in Neural Information Processing Systems, 33:6476-6489, 2020.\\n\\nChristopher De Sa, Albert Gu, Rohan Puttagunta, Christopher Ré, and Atri Rudra. A two-pronged progress in structured dense matrix vector multiplication. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1060-1079. SIAM, 2018.\\n\\nPeter J Denning. The working set model for program behavior. Communications of the ACM, 11(5): 323-333, 1968. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep\\n\\nbidirectional transformers for language understanding. 2019.\\n\\nXin Dong, Shangyu Chen, and Sinno Jialin Pan. Learning to prune deep neural networks via layer-wise optimal brain surgeon. arXiv preprint arXiv:1705.07565, 2017.\\n\\nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2020.\\n\\nY Eidelman and I Gohberg. On a new class of structured matrices. Integral Equations and Operator\\n\\nTheory, 34(3):293-324, 1999.\\n\\nJean Feydy, Joan Glaunés, Benjamin Charlier, and Michael Bronstein. Fast geometric learning with symbolic matrices. Advances in Neural Information Processing Systems, 33, 2020.\\n\\nJérg Flum and Martin Grohe. Parameterized Complexity Theory. Springer, 2006.\\n\\nJonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. In International Conference on Learning Representations, 2018.\\n\\nJonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.\\n\\nJonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, and Michael Carbin. Linear mode connectivity and the lottery ticket hypothesis. In International Conference on Machine Learning, pages 3259-3269. PMLR, 2020.\\n\\nKaran Goel, Albert Gu, Chris Donahue, and Christopher Ré. It’s raw! audio generation with state-space models. In International Conference on Machine Learning (ICML), 2022.\\n\\nAaron Gokaslan, Vanya Cohen, Pavlick Ellie, and Stefanie Tellex. Openwebtext corpus, 2019.\\n\\n12\\n\\n33\\n\\n34\\n\\n35\\n\\n36\\n\\n37\\n\\n38\\n\\n39\\n\\n50\\n\\nJim Gray, Surajit Chaudhuri, Adam Bosworth, Andrew Layman, Don Reichart, Murali Venkatrao, Frank Pellow, and Hamid Pirahesh. Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals. Data mining and knowledge discovery, 1(1):29-53, 1997.\\n\\nAndreas Griewank and Andrea Walther. Evaluating derivatives: principles and techniques of algorithmic differentiation. SIAM, 2008.\\n\\nAlbert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher Ré. Hippo: Recurrent memory with optimal polynomial projections. In Advances in neural information processing systems (NeurIPS), 2020.\\n\\nAlbert Gu, Isys Johnson, Karan Goel, Khaled Saab, Tri Dao, Atri Rudra, and Christopher Ré. Combining recurrent, convolutional, and continuous-time models with linear state space layers. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nAlbert Gu, Karan Goel, and Christopher Ré. Efficiently modeling long sequences with structured state spaces. In The International Conference on Learning Representations (ICLR), 2022.\\n\\nSong Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural networks. arXiv preprint arXiv:1506.02626, 2015.\\n\\nSong Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In International Conference on Learning Representations, 2016.\\n\\nJohn Hennessy and David Patterson. Memory hierarchy design. Computer Architecture: A Quantitative Approach, pages 390-525, 2003.\\n\\nSara Hooker. The hardware lottery. arXiv preprint arXiv:2009.06489, 2020.\\n\\nWeizhe Hua, Zihang Dai, Hanxiao Liu, and Quoc V Le. Transformer quality in linear time. arXiv preprint arXiv:2202.10447, 2022.\\n\\nAndrei Ivanov, Nikoli Dryden, Tal Ben-Nun, Shigang Li, and Torsten Hoefler. Data movement is all you need: A case study on optimizing transformers. Proceedings of Machine Learning and Systems, 3:\\n\\n711-732, 2021.\\n\\nZhe Jia and Peter Van Sandt. Dissecting the Ampere GPU architecture via microbenchmarking. GPU Technology Conference, 2021.\\n\\nZhe Jia, Marco Maggioni, Benjamin Staiger, and Daniele P Scarpazza. Dissecting the nvidia Volta GPU architecture via microbenchmarking. arXiv preprint arXiv:1804.06826, 2018.\\n\\nZhe Jia, Blake Tillman, Marco Maggioni, and Daniele Paolo Scarpazza. Dissecting the graphcore IPU architecture via microbenchmarking. arXiv preprint arXiv:1912.03418, 2019.\\n\\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3(1):1-9, 2016.\\n\\nNorman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. In-datacenter performance analysis of a tensor processing unit. In Proceedings of the 44th annual international symposium on computer architecture, pages 1-12, 2017.\\n\\nThomas Kailath, Sun-Yuan Kung, and Martin Morf. Displacement ranks of matrices and linear equations. Journal of Mathematical Analysis and Applications, 68(2):395-407, 1979.\\n\\nAngelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Francois Fleuret. Transformers are RNNs: Fast autoregressive transformers with linear attention. In International Conference on Machine Learning, pages 5156-5165. PMLR, 2020.\\n\\n51\\n\\n52\\n\\n53\\n\\n54\\n\\n55\\n\\n56\\n\\n57\\n\\n58\\n\\n59\\n\\n60\\n\\n61 62 63 64\\n\\n65\\n\\n66\\n\\n67\\n\\n68\\n\\n69\\n\\nNikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. In The International Conference on Machine Learning (ICML), 2020.\\n\\nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. Albert: A lite BEDRT for self-supervised learning of language representations. In The International Conference on Learning Representations (ICLR), 2020.\\n\\nMingzhen Li, Yi Liu, Xiaoyan Liu, Qingxiao Sun, Xin You, Hailong Yang, Zhongzhi Luan, Lin Gan, Guangwen Yang, and Depei Qian. The deep learning compiler: A comprehensive survey. [EEE Transactions on Parallel and Distributed Systems, 32(3):708-727, 2020.\\n\\nValerii Likhosherstov, Krzysztof Choromanski, Jared Davis, Xingyou Song, and Adrian Weller. Sub-linear memory: How to make performers slim. arXiv preprint arXiv:2012. 11346, 2020.\\n\\nJi Lin, Yongming Rao, Jiwen Lu, and Jie Zhou. Runtime neural pruning. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Dangi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\\n\\nXuezhe Ma, Xiang Kong, Sinong Wang, Chunting Zhou, Jonathan May, Hao Ma, and Luke Zettlemoyer. Luna: Linear unified nested attention. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nPeter Mattson, Christine Cheng, Gregory Diamos, Cody Coleman, Paulius Micikevicius, David Patterson, Hanlin Tang, Gu-Yeon Wei, Peter Bailis, Victor Bittorf, et al. Mlperf training benchmark. Proceedings of Machine Learning and Systems, 2:336-349, 2020.\\n\\nFrank McSherry, Michael Isard, and Derek G Murray. Scalability! but at what {COST}? In 15th Workshop on Hot Topics in Operating Systems (HotOS XV), 2015.\\n\\nMaxim Milakov and Natalia Gimelshein. Online normalizer calculation for softmax. arXiv preprint arXiv:1805.02867, 2018.\\n\\nNVIDIA. Nvidia Tesla V100 GPU architecture, 2017. NVIDIA. Nvidia A100 tensor core GPU architecture, 2020.\\n\\nNVIDIA. Nvidia H100 tensor core GPU architecture, 2022.\\n\\nD Stott Parker. Random butterfly transformations with applications in computational linear algebra.\\n\\n1995.\\n\\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high- performance deep learning library. Advances in neural information processing systems, 32, 2019.\\n\\nMarkus N Rabe and Charles Staats. Self-attention does not need O(n?) memory. arXiv preprint arXiv:2112.05682, 2021.\\n\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\\n\\nJack Rae and Ali Razavi. Do transformers need deep long-range memory? In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online, July 2020. Association for\\n\\nComputational Linguistics. URL https: //www.aclweb.org/anthology/2020.acl-main.672\\n\\nJack W Rae, Anna Potapenko, Siddhant M Jayakumar, and Timothy P Lillicrap. Compressive trans- formers for long-range sequence modelling. In The International Conference on Learning Representations\\n\\n(ICLR), 2020.\\n\\n14\\n\\n70\\n\\n71\\n\\n72\\n\\n73\\n\\n74\\n\\n75. 76\\n\\n77\\n\\n78\\n\\n79\\n\\n80\\n\\n81\\n\\n82\\n\\n83\\n\\n84\\n\\n85.\\n\\n86\\n\\nJonathan Ragan-Kelley, Connelly Barnes, Andrew Adams, Sylvain Paris, Frédo Durand, and Saman Amarasinghe. Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines. Acm Sigplan Notices, 48(6):519-530, 2013.\\n\\nRaghu Ramakrishnan, Johannes Gehrke, and Johannes Gehrke. Database management systems, volume 3. McGraw-Hill New York, 2003.\\n\\nBenjamin Recht and Christopher Ré. Parallel stochastic gradient algorithms for large-scale matrix completion. Mathematical Programming Computation, 5(2):201-226, 2013.\\n\\nHongyu Ren, Hanjun Dai, Zihang Dai, Mengjiao Yang, Jure Leskovec, Dale Schuurmans, and Bo Dai. Combiner: Full attention transformer with sparse computation cost. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nAurko Roy, Mohammad Saffar, Ashish Vaswani, and David Grangier. Efficient content-based sparse attention with routing transformers. Transactions of the Association for Computational Linguistics, 9: 53-68, 2021.\\n\\nAmit Sabne. XLA: Compiling machine learning for peak performance. 2020.\\n\\nVictor Sanh, Thomas Wolf, and Alexander M Rush. Movement pruning: Adaptive sparsity by fine-tuning. arXiv preprint arXiv:2005.07683, 2020.\\n\\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-LM: Training multi-billion parameter language models using model parallelism. arXiv preprint\\n\\nar Xiv:1909.08058, 2019.\\n\\nVikas Sindhwani, Tara Sainath, and Sanjiv Kumar. Structured transforms for small-footprint deep learning. In Advances in Neural Information Processing Systems, pages 3088-3096, 2015.\\n\\nSainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, and Armand Joulin. Adaptive attention span in transformers. In Proceedings of the Annual Meeting of the Association for Computational Linguistics,\\n\\n2019.\\n\\nYi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler. Long range arena: A benchmark for efficient transformers. In International Conference on Learning Representations, 2020.\\n\\nYi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. Efficient transformers: A survey. arXiv preprint arXiv:2009.06782, 2020.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\\n\\nHongyu Wang, Shuming Ma, Li Dong, Shaohan Huang, Dongdong Zhang, and Furu Wei. Deepnet: Scaling transformers to 1,000 layers. arXiv preprint arXiv:2203.00555, 2022.\\n\\nSinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768, 2020.\\n\\nSamuel Williams, Andrew Waterman, and David Patterson. Roofline: an insightful visual performance model for multicore architectures. Communications of the ACM, 52(4):65-76, 2009.\\n\\nMichael E Wolf and Monica S Lam. A data locality optimizing algorithm. In Proceedings of the ACM SIGPLAN 1991 conference on Programming language design and implementation, pages 30-44, 1991.\\n\\n[87] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric\\n\\n88\\n\\n89\\n\\n90\\n\\n91\\n\\n92\\n\\n93\\n\\n94\\n\\nCistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online, October 2020. Association for Computational Linguistics. URL\\n\\nhttps: //www.aclweb.org/anthology/2020.emnlp-demos .6\\n\\nDavid P Woodruff. Optimal space lower bounds for all frequency moments. In SODA, volume 4, pages 167-175. Citeseer, 2004.\\n\\nFelix Wu, Angela Fan, Alexei Baevski, Yann N Dauphin, and Michael Auli. Pay less attention with lightweight and dynamic convolutions. In The International Conference on Learning Representations\\n\\n(ICLR), 2019.\\n\\nYunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, and Vikas Singh. Nystrémformer: A nyst6ém-based algorithm for approximating self-attention. In Proceedings of the AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence, volume 35, page 14138, 2021.\\n\\nLi Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zi-Hang Jiang, Francis EH Tay, Jiashi Feng, and Shuicheng Yan. Tokens-to-token vit: Training vision transformers from scratch on imagenet. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 558-567, 2021.\\n\\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for longer sequences. Advances in Neural Information Processing Systems, 33, 2020.\\n\\nShuangfei Zhai, Walter Talbott, Nitish Srivastava, Chen Huang, Hanlin Goh, Ruixiang Zhang, and Josh Susskind. An attention free transformer. arXiv preprint arXiv:2105.14103, 2021.\\n\\nChen Zhu, Wei Ping, Chaowei Xiao, Mohammad Shoeybi, Tom Goldstein, Anima Anandkumar, and Bryan Catanzaro. Long-short transformer: Efficient transformers for language and vision. Advances in Neural Information Processing Systems, 34, 2021.\\n\\n16\\n\\nA Related Work\\n\\nIO-Aware Runtime Optimization. The broad concept of optimizing for reading and writing to fast /slow memory has a long history in computer science and has been known by many names. We draw the most direct connection to the literature of analyzing I/O complexity in this work [I], but concepts of memory hierarchies are fundamental and has appeared in many forms, from the working set model [2]], to data locality [86], to the Roofline model of arithmetic intensity [85], to analyses of scalability [59], to standard textbook treatments of computer architecture [40]. We hope that this work encourages the community to adopt these ideas in more parts of the deep learning stack.\\n\\nEfficient ML Models with Structured Matrices. Matrix multiply is the core computational bottle- neck of most machine learning models. To reduce the computational complexity, there have been numerous approaches to learn over a more efficient set of matrices. These matrices are called structured matrices, which have subquadratic (o(n?) for dimension n x n) number of parameters and runtime. Most common examples of structured matrices are sparse and low-rank matrices, along with fast transforms commonly encountered\\n\\nin signal processing (Fourier, Chebyshev, sine/cosine, orthogonal polynomials). There have been several more general classes of structured matrices proposed in machine learning: Toeplitz-like [78], low-displacement rank [49], quasi-separable [25]). The butterfly pattern we use for our block-sparse attention is motivated by the fact that butterfly matrices (64] and their products have been shown to be able to express any structured matrices with almost optimal runtime and number of parameters [20]. However, even though structured matrices are efficient in theory, they have not seen wide adoption since it is hard to translate their efficiency to wall-clock speedup since dense unconstrained matrix multiply has very optimize implementation, a phenomenon known as the hardware lottery [I]. Extensions of butterfly matrices [17] [18] aimed to make butterfly matrices more hardware-friendly.\\n\\nSparse Training. Our block-sparse FLASHATTENTION can be seen as a step towards making sparse model training more efficient. Sparse models have seen success in compressing models for inference (pruning) by sparsifying the weight matrices [23] [38] [39] 55] [76]. For model training, the lottery tickets hypothesis [28] [29] [30] suggests that there are a set of small sub-networks derived from a larger dense network that performs as well as the original dense network. Out block-sparse FLASHATTENTION can also be seen as a fixed lottery ticket in the context of attention: we fix the sparsity pattern to be the butterfly pattern through training, and observe that it performs almost as well as the (dense) FLASHATTENTION on the Long-range Arena tasks.\\n\\nEfficient Transformer. Transformer-based models have become the most widely-used architecture in natural language processing [22] and computer vision [24]|91]. However, one of their computational bottlenecks is that their time and memory scales quadratic in the sequence length. There are numerous approaches to overcome this bottleneck, including approximation with hashing (i.e., sparse) such as Reformer an Smyrf [19] and with low-rank approximation such as Performer [54]. One can even combine sparse and low-rank approximation for better accuracy (e.g., Longformer [3], BigBird [92], Scatterbrain [9], Long-shor transformer [94], Combiner [73]). Other approaches include compressing along the sequence dimension to attend to multiple tokens at once [571 [79] [89]. One can also attend over the states from previous sequences to help lengthen the context (e.g., Transformer-XL and Compressive Transformer [69}). We recommen the survey for more details.\\n\\nThere are several lines of work on developing other modules instead of attention to model longer context. HiPPO [35] and its extensions, most notably S4 [BT] [36] [37] projects the history on a polynomial basis, allowing accurate reconstruction of the history through state-space models. They combine the strengths o! CNNs (efficient training), RNNs (efficient inference), and continuous models (robust to change in sampling rates). LambdaNetworks [2], AFT and FLASH [42] are other attempts at replacing attention in the context of image classification and language modeling.\\n\\nB_ Algorithm Details\\n\\nWe first derive the forward and backward passes of attention and show that they can be computed in a memory-efficient manner (requiring extra memory linear instead of quadratic in the sequence length). Though they reduce the amount of extra memory required, naively they still incur quadratic HBM accesses, resulting in slower execution speed. We describe the FLASHATTENTION algorithm to implement both the forward\\n\\n17\\n\\nand the backward passes on GPUs that reduces HBM accesses, leading to both faster runtime and smaller memory footprint.\\n\\nB.1 Memory-efficient forward pass\\n\\nThe main challenge in making attention memory-efficient is the softmax that couples the columns of K (and columns of V). Our approach is to compute the softmax normalization constant separately to decouple the columns. This technique has been used in the literature to show that attention computation does not need quadratic extra memory (though the number of HBM accesses is still quadratic, resulting in slow run-time).\\n\\nFor simplicity, we omit here the max-shifting step during softmax. The full algorithm in Appendix [B.3] contains all the steps.\\n\\nRecall that given input sequences Q, K, V €\\n\\nRN*4, we want to compute the attention output O € RN*4:\\n\\nS=QK™« RX\", P =softmax(S) eRY*, O=PVeERN*4, We have that S;; = qe kj; where q; and k; are the i-th and j-th columns of Q and K respectively. Define the normalization constants of softmax: , Li = yiet ky (1) Jj Let v; be the j-th column of V, then the i-th columns of the output is ed ki\\n\\nLj\\n\\n04 = PV =D\" Pijvj = Vj. (2)\\n\\nJ J\\n\\nWe see that once L; is computed, we can compute 0; without extra memory by repeatedly summing\\n\\net Kj Li\\n\\nv;. Therefore the forward pass can be computed with O(n) extra memory:\\n\\n1. Compute L; for all i according to Eq. (i).\\n\\nwhich takes O(n) extra memory.\\n\\n2. Compute 0; for all i according to Eq. Q. which takes O(d) extra memory.\\n\\nB.2. Memory-efficient backward pass\\n\\nWe derive the backward pass of attention and show that it can also be computed with linear memory. Rabe and Staats [66] suggests that the backward pass can be done without quadratic extra memory by applying gradient checkpointing to the memory-efficient forward pass. We instead derive the backward pass explicitly and show how it can be computed in a memory-efficient manner.\\n\\nSuppose that there is a scalar loss function ¢, and let the output gradient be dO € R\"*¢ (where dO denotes a6). We want to compute the input gradients dQ,dK,dV € Rd (where dQ, dK, dV denote 3. oe a6 respectively).\\n\\nThe gradient dV is easy to see. Applying reverse-mode autodiff by hand (aka the chain rule), we obtain (in matrix notation) dV = P7 dO. Thus:\\n\\nT edi ki\\n\\ndv; = >) Pijdoi =>) L doj. (3) i\\n\\n7 i i\\n\\nSince we already computed L;, dv; can be computed without extra memory by repeated summing. The gradients dQ and dK are a little more complicated. We go through the gradients dP and dS first. From Eq. (2), we have that dP = dOV’, and so: dP jj = do} Vj.\\n\\nRecall that P;. = softmax(S;;). Using the fact that the Jacobian of y = softmax(x) is diag(y) — yy’, we have that dS; = (diag(P;.) — Pi-P{,)dP;. = Pi. 0 dP). -— (P/.dP;.)Pi-,\\n\\n18\\n\\nwhere o denotes pointwise multiplication.\\n\\nDefine + q5 kj qk; Dj = PhaP;, = Y\\\\ dof vj = dof Y) v; = do} oi, (4) Jj \\' Jj then dS;, = P;, © dP;, — D;Pi:. Hence\\n\\ndS;; = PijdPij — DjPij = Pij(dPij — Di). Now we can get the gradients dQ and dK. Recall that S;; = gq) kj, so\\n\\nedi kj\\n\\ndq; =) dSijkj =D\" Pij(dPij — Dik; = (dol vy ~ Didky. (5)\\n\\nJ J io”\\n\\nSimilarly,\\n\\nT edi Ki . dk; = 48i;4i = >) Pig aP i; - Didi = » L (do} v; — Di)qi- (6)\\n\\ni i t\\n\\nTherefore the backward pass can also be computed with O(n) extra memory: 1. Compute dv; for all j according to Eq. (3). which takes O(d) extra memory. 2. Compute D; for all i according to Eq. (4. which takes O(n) extra memory. 3. Compute dq; for all i according to Eq. (5). which takes O(d) extra memory. 4. Compute dk; for all j according to Eq. (6), which takes O(d) extra memory.\\n\\nB.3. FLASHATTENTION: Forward Pass\\n\\nWe describe the full details of FLASHATTENTION forward pass. Given input sequences Q, K, V € R“*¢, we want to compute the attention output O ¢ RN*4:\\n\\nS= TQK\" € RN*N gmasked = MASK(S) € RN*N | P= softmax(S™*skedy € RN*N\\n\\nPropped = dropout(P, parop), O = PUPPY ¢ RNxd\\n\\nwhere tT € R is some softmax scaling (typically Ta MASK is some masking function that sets some entries of the input to —co and keep other entries the same (e.g., key padding mask when sequences in the batch don’t have the same lengths and are padded), and dropout(x, p) applies dropout to x elementwise (i.e., output cart with probability 1 -— p and output 0 with probability p for each element x).\\n\\nThe full algorithm is in Algorithm [} We save the output O, the softmax statistics and m, and the pseudo-random number generator state R for the backward pass.\\n\\n19\\n\\nAlgorithm 2 FLASHATTENTION Forward Pass\\n\\nRequire: Matrices Q,K,V ¢ R‘*“ in HBM, on-chip SRAM of size M, softmax scaling constant Tt € R, masking function MASK, dropout probability parop-\\n\\n1: Initialize the pseudo-random number generator state R and save to HBM.\\n\\n2: Set block sizes B. = [4] ,B, = min (4) ,d).\\n\\n3: Initialize O = (0) xa € RN*4,€ = (0)y € RY, m = (-c)y € RN in HBM.\\n\\n4: Divide Q into T, = [| blocks Qi,...,Qz, of size B, x d each, and divide K, V in to T, = [| blocks K,,..., Ky, and Vj,..., Vz., of size B. x d each. Divide O into T,. blocks O;,..., Oz, of size B, x d each, divide ¢ into T, blocks ¢;,...,€r, of size B, each, divide m into T, blocks m,..., mr, of size B; each. 6: for 1 <j <T. do 7: Load K;,V; from HBM to on-chip SRAM.\\n\\non\\n\\n8: forl<i<T, do\\n\\n9: Load Q;, 0;, €;,m; from HBM to on-chip SRAM.\\n\\n10: On chip, compute $;; = TQiKT € RB xBe |\\n\\n11: On chip, compute Spyasked = MASK(S;;). -\\n\\n12: On chip, compute mj; = rowmax(S?/*5**) eR’, Py = exp(Sprasked — mj) € Rr*Be (pointwise), bij = rowsum(P;;) € Re,\\n\\n13: On chip, compute m?°Y = max(m;, fijj) € RB, rev = eM E+ emir C5 E RBr,\\n\\n14: On chip, compute Pyyopped = dropout(Pj;, Parop)-\\n\\n15: Write 0; — diag(¢2\")-1(diag(é;)e™—\"™ 0; + em—mP™ PPP) to HIBM.\\n\\n16: Write €; — €P°\", m; — m7?\" to HBM.\\n\\n17: end for\\n\\n18: end for\\n\\n19: Return O,¢,m,R.\\n\\nB.4. FLASHATTENTION: Backward Pass\\n\\nWe describe the full details of FLASHATTENTION backward pass. Given input sequences Q, K, V € R*4, the output O € RN*4, and the output gradient dO, we want to compute the input gradients dQ, dK,dV € RY*¢. We first describe the standard attention backward pass in Algorithm [3] for completeness.\\n\\nAlgorithm 3 Standard Attention Backward Pass\\n\\nRequire: Matrices Q,K, V,dO ¢ RY*4, Pe RY*\" in HBM. 1: Load P, dO by blocks from HBM, compute dV = P™dO € R™4, write dV to HBM. : Load dO, V by blocks from HBM, compute dP = dOV™ € R“*\", write dP to HBM. : Read P, dP from HBM, compute dS « RY*\" where dS;; = Pij(dPij — DX) PidPi1), write dS to HBM. : Load dS and K by blocks from HBM, compute dQ = dSK, write dQ to HBM. : Load dS and Q by blocks from HBM, compute dK = dS\"Q, write dK to HBM. 6: Return dQ, dK, dV.\\n\\nae ww\\n\\nWe now make two observations about FLASHATTENTION backward pass:\\n\\n1. We do not need to store the dropout mask of size O(N?) from the forward pass. Instead, we can save the pseudo-random number generator states from the forward pass and re-generate the dropout mask in the backward pass. This allows us to only use O(N) extra memory.\\n\\n2. When computing the softmax gradient, we use Eq. (4p to compute D; = P/dP;, without reducing over P;, and dP;, of size N (they might not fit into SRAM). Instead we can rewrite D; = do; 0; and compute the dot product between vectors of size d.\\n\\n20\\n\\nThe full FLASHATTENTION backward pass algorithm is in Algorithm [4] Conceptually it is just a block version of the derivation in Appendix [B.2]\\n\\nAlgorithm 4 FLASHATTENTION Backward Pass\\n\\nRequire: Matrices Q,K, V,0,dO ¢ R‘*¢ in HBM, vectors €,m € RY in HBM, on-chip SRAM of size M, softmax scaling constant t € R, masking function MASK, dropout probability parop, pseudo-random number generator state R from the forward pass.\\n\\n1: Set the pseudo-random number generator state to R.\\n\\n2: Set block sizes B. = [4] ,B, = min (4) ,d).\\n\\n3: Divide Q into T, = [| blocks Q;,...,Qz, of size B, x d each, and divide K, V in to T, = [| blocks\\n\\nK,,..., Ky, and Vj,..., Vz., of size B. x d each.\\n\\n4: Divide O into T, blocks O;,...,O7, of size B, x d each, divide dO into T, blocks dOj;,...,dOz, of size B, x d each, divide € into T, blocks €,...,€r, of size B, each, divide m into T, blocks m,..., mr, of size B, each.\\n\\nInitialize dQ = (0)vxa in HBM and divide it into T, blocks dQ,,..., dQ;, of size B, x d each. Initialize\\n\\ndK = (0)vxa,dV = (0)vx@ in HBM and divide dK, dV in to T, blocks dKj,...,dKr, and dVj,...,dVz.,\\n\\nof size B, x d each.\\n\\n6: for 1 <j <T. do\\n\\n7: Load Kj, V; from HBM to on-chip SRAM.\\n\\n8: Initialize dK; = (0)g.xa,dVj = (0)a.xa on SRAM.\\n\\n9: forl<i<T, do\\n\\non\\n\\n10: Load Q;, 0;,d0;, dQ,, ¢;, m; from HBM to on-chip SRAM.\\n\\n11: On chip, compute $,; = TQ:KT € RB xBe |\\n\\n12: On chip, compute Spyasked = MASK(S;;).\\n\\n13: On chip, compute P;; = diag(J;)~! exp(Spasked — mj) € RBr*Be,\\n\\n14: On chip, compute dropout mask Z;; € R\\'r*Be where each entry has value = with probability 1— Parop and value 0 with probability parop.\\n\\n15: On chip, compute Pyyopped = Pj; ° Z;; (pointwise multiply).\\n\\n16: On chip, compute av; <—dV;+ (Perr) TO; € RBexd |\\n\\n17: On chip, compute apyyopred = d0;V; € RBrxBe |\\n\\n18: On chip, compute dP;; = dPsrorped o Z;; (pointwise multiply).\\n\\n19: On chip, compute D; = rowsum(dO; 0 0;) € R3\".\\n\\n20: On chip, compute d§,;; = Pi; 0 (dP;; — Di) € RErxBe |\\n\\n21: Write dQ; — dQ; + 7d8,;;K; ¢ R84 to HBM.\\n\\n22: On chip, compute dK; — aK; +7d$/;Q; € RBexd,\\n\\n23: end for\\n\\n24: Write dK; — dK,,dV; — dV, to HBM. 25: end for\\n\\n26: Return dQ, dK, dV.\\n\\nWe see that similar to the forward pass, the backward pass performs O(N?) FLOPs and only requires O(N) extra memory beyond inputs, output, output gradient, and input gradients. We analyze the IO-complexity of the backward pass, similar to the forward pass (Theorem |2).\\n\\nTheorem 5. Let N be the sequence length, d be the head dimension, and M be size of SRAM withd < M < Nd. Standard attention (Algorithm|[d) backward pass requires @(Nd +N?) HBM accesses, while FLASHATTENTION backward pass (Algorithm|4| requires @(N2d?M~\\') HBM accesses.\\n\\nThe proof is in Appendix [C]\\n\\n21\\n\\nB.5 Comparison with Rabe and Staats\\n\\nWe describe here some similarities and differences between our FLASHATTENTION algorithm and the algorithm of Rabe and Staats [66].\\n\\nConceptually, both FLASHATTENTION and Rabe and Staats operate on blocks of the attention matrix using the well-established technique of tiling (or softmax scaling) [51] [60]. To reduce the memory footprint, both methods avoid storing the large attention matrix in the forward pass and recompute it in the backwar pass.\\n\\nThe first major difference is that Rabe and Staats focuses on the reducing the total memory footprint (maximum amount of GPU memory required) while FLASHATTENTION focuses on reducing memory accesses (the number of memory reads/writes). As mentioned in Section [2] the amount of memory access is the primary determining factor of runtime. Reducing memory accesses also necessarily reduces the total amoun of memory required (e.g., if an operation incurs A memory accesses, then its total memory requirement is a‘ most A). As a result, FLASHATTENTION is faster than standard attention (2-4x) while Rabe and Staats is around the same speed or slightly slower than standard attention. In terms of total memory required, both methods offer substantial memory saving. The second difference between the two methods is the way information is summarized from each block to pass to the next block. Rabe and Staats summarizes each block with its temporary output along with the softmax normalization statistics. At the end of the forward pass, the temporary outputs of all the blocks are combined using the statistics to produce the final output. FLASHATTENTION instead incrementally updates the output (Algorithm [1] ine after processing each block, so only one copy of the output is needed (instead of K copies for K blocks). This means that FLASHATTENTION has smaller total memory requirement compared to Rabe and Staats [66]. The final major difference is the way the backward pass is computed. Rabe and Staats uses gradient checkpointing to recompute the attention matrix and the temporary output of each block. FLASHATTENTION instead simplifies the backward pass analytically (Appendices ). It only recomputes the attention matrix and does not recompute the temporary output of each block. This reduces the memory requirement for the backward pass and yields speedup.\\n\\nC_ Proofs\\n\\nProof of Theorem [I] We first count the number of FLOPs and extra memory required. The dominating FLOPs are from matrix multiplication. In the inner loop, (Algorithm [1] line >). we compute Q.K; € R3*Be for Q; € R84 and K;¢€ Rex4 which takes O(B,B.d) FLOPs. We also compute\\n\\n(Algorithm fil ine [12) P/V; € R3rX4 for P;; € RB*Be and Vie R8ex4_ which takes O(B,B-d) FLOPs. We execute the inner loops TT; = [4] [#] times. Therefore the total number of FLOPs is\\n\\nBe\\n\\n(6) N* B,Bed| = O(N? d) BoB. or eet] = : In terms of extra memory required, we see that we need O(N) memory to store the statistics (€,m).\\n\\nWe now prove the algorithm’s correctness by induction on j for 0 < j < T,. Let K,j € R/Bex4 be the first 7B. rows of K, and similarly V.; € R/8ex4 the the first 7B. rows of V. Let Sj = QK’, € RN*/Be. and P...; =softmax(S,..;) € RN*/8e (softmax applied row-wise). Let m/, £2),0% be the values of m,€,O in HBM after the j-th iteration of the outer loop (Algorithm [I] line 5}. (Note that these values of m, €,O are updated after each iteration of the outer loop.) We want to show that after the j-th iteration of the outer loop, we have computed in HBM:\\n\\nmD = rowmax(S, .;) € RY, (W= rowsum(exp(S, .; — m)))eRX, OW = PL Vij € RN™¢,\\n\\nBased on our initialization (Algorithm [I] line , this claim is true for j = 0 (ie., before the any iteration of the outer loop is executed). Suppose that the claim holds for some j = 0,...,T-— 1. We want to show that the claim also holds for j + 1. Indeed, when we update the statistics in the inner loop (Algorithm [I] line [I0}\\n\\n22\\n\\non the (j +1)-th iteration of the outer loop, we update m/*) = max(m),m) where m € R™ is the row-max of S. j.j41, the slice of S from column jB, to column (j +1)B, — 1. This implies that\\n\\nmF) = rowmax(S. :j41) € RN.\\n\\nSimilarly, we update\\n\\nj. DomUtD a7 m—mItD 5 CUED = gin mI) Oi) g. git) &\\n\\nwhere f = rowsum(exp(S, j:j41 —m)) € RY. By the same algebraic manipulation in Section [3.1| we obtain:\\n\\ncay = rowsum/(exp(S;,.j41 — mU*))) eR. Let Vj:j+1 be the slice of V from column jB, to column (j + 1)B, — 1, we also update: OND = diag(e4*9) 1 diag(e em\" OW + eM exp (Sj. j41 — Hi) Vjjs) = diag (UP) “\"(diag(e ye\" PR. V, EM” exp(S)j41)V jet) = diag(€4*Y) \"(diag Mer” diag(€) exp(S.,.j — mV. +e™ = iag(LItD) He) exp(S,,.;)V.j + emg exp($j.j41) Vj.j+1)\\n\\n= diag(€V*))“!(exp(S,,.j — mY*Y)V.; + exp(Sj.j41 — mY) Vj. j41)\\n\\n= iag(et))- (exp ([8.2j Sj.j41] -mi))| V3) |\\n\\nVisju1\\n\\n(i+\\n\\n’ exp(Sj.j+1) Vj.j41)\\n\\n= softmax(S. j+1) V:j+1-\\n\\nWe then see that the claim is also true for j + 1. By induction, the claim is true for all j =0,...,T7.. When j =T7,, we conclude that the final value of O in HBM is softmax(S)V = softmax(QK\")V. Oo\\n\\nProof of Theorem [A We first analyze the IO complexity of standard attention implementation. The inputs Q.K, V ¢ R\\\\*¢ reside in HBM, and the at the end of the algorithm the output O € RY” is written to HBM.\\n\\nIn the first step of computing the matrix multiply § = QK\", the inputs Q,K are read from HBM and the output S « RX* is written to HBM (Algorithm [0] line[Ip. This incurs @(Nd + N?) HBM accesses.\\n\\nIn the second step of computing P = softmax(S), the input S is read from HBM and the output P is written to HBM (Algorit hm [0] line [2). This incurs @(N?) HBM accesses.\\n\\nIn the last step of computing O = PV, the inputs P, V are read from global memory and the output O is written to HBM (Algorit hm [0] line [3p. This incurs @(Nd + N?) HBM accesses.\\n\\nOverall, standard attention implementation requires @(Nd + N?) global memory accesses.\\n\\nWe now analyze the IO complexity of streaming attention.\\n\\nFollowing Algorithm [I] we see that each element of K and V is loaded from HBM once (alborithe line |6). We make T, passes over Q and O, each pass loading all of Q and all of O to HBM (Algorithm line|8). Therefore the number of HBM accesses is © (Nd + NdT,) = O(NdT.).\\n\\nWe derive the conditions on the block sizes B. and B,. We need the blocks K; and V; of size B, x d to fit into on-chip memory, which translates to:\\n\\nB-d = O(M) oa.-0(\").\\n\\nSimilarly, we need the blocks Q;, 0; of size B, x d to fit into on-chip memory, which translates to:\\n\\nB,d = O(M) © B, -o(4).\\n\\nFinally, we need the block §;; of size B, x B, to fit into on-chip memory, which translates to:\\n\\nB,B. = O(M).\\n\\n23\\n\\nWe therefore set:\\n\\nWe then have: “pol\\n\\nAs a result, the number of HBM accesses is: N?d? ©(NdT,) =® (“Sr ] . oO\\n\\nProof of Proposition [3 For contradiction, suppose that there exists an algorithm that computes exact attention where the number for HBM access for all M € [d, Nd] is\\n\\nN?d? oO . (\"r]\\n\\nIn the regime of M = ©(Na), this results in the number of HBM accesses:\\n\\nN?d? “|\\n\\nWd =o0(Nd).\\n\\nHowever, the input to attention (matrices Q,K,V) and the output O have size Nd and they start out being in HBM, so if the algorithm computes exact attention it must incur at least Q(Nd) HBM accesses. This is a contradiction. oO Proof of Theorem [5} The IO complexity of the attention backward is very similar to the IO complexity of he attention forward (Theorem [2). Here we provide a sketch of the proof.\\n\\nWe first analyze the IO complexity of standard attention backward pass. The inputs Q,K, V,dO € RY*¢ reside in HBM, and the at the end of the algorithm the outputs dQ, dK, dV ¢ R‘™¢ are written to HBM. At each step of the standard attention backward pass, one needs to load inputs of size Nd or N? from HBM, and needs to write the outputs of size N? or Nd to HBM. This incurs @(Nd + N?) HBM accesses. We now analyze the IO complexity of FLASHATTENTION backward pass.\\n\\nSimilar to Theorem [2] we see that each element of K and V is loaded from HBM once. Each element of dK and dV is only written to HBM once. We make T, passes over Q, O, dO, each pass loading all of Q,O,dO o HBM. We also make T, passes over dQ, each pass reading/writing all of dQ from/to HBM. Therefore the number of HBM accesses is © (Nd + NdT,) = @(NdT-).\\n\\nAs in the proof of Theorem [2] the constraints on the block sizes are that:\\n\\nN Be\\n\\nAs a result, the number of HBM accesses is:\\n\\nWe then have:\\n\\n“|\\n\\n0 (NadT,) = 9 rj\\n\\n24\\n\\nAlgorithm 5 Block-Sparse FLASHATTENTION Forward Pass\\n\\nRequire: Matrices Q,K,V ¢ R‘*“ in HBM, on-chip SRAM of size M, softmax scaling constant Tt € R, masking function MASK, dropout probability Parop, block sizes B. = [4]. 8, = min ([44],d), block sparsity mask M € {0, 1}N/8rxN/Be\\n\\n1: Initialize the pseudo-random number generator state R and save to HBM.\\n\\n2: Initialize O = (0)vxa € RN*4, € = (0)w € RY, m = (-co)y € RN in HBM.\\n\\n3: Divide Q into T, = [| blocks Q;,...,Qz, of size B, x d each, and divide K, V in to T, = [| blocks\\n\\nK,,..., Ky, and Vj,..., Vz., of size B. x d each.\\n\\n4: Divide O into T, blocks O;,...,O7, of size B, x d each, divide ¢ into T, blocks €;,...,¢p, of size B, each,\\n\\ndivide m into T, blocks m,..., mr, of size B; each.\\n\\nfor 1 <j<T. do\\n\\n6: Load Kj, V; from HBM to on-chip SRAM.\\n\\non\\n\\n7 forl<i<T, do\\n\\n8: if M;; #0 then\\n\\n9: Load Q;, 0;, €;,m; from HBM to on-chip SRAM.\\n\\n10: On chip, compute $;; = TQiK € RB xBe |\\n\\n11: On chip, compute Spasked = MASK(S;;).\\n\\n12: On chip, compute mj; = rowmax(Sjvke) eR, Pi = exp(Spasked — mij) € R3r*Be (pointwise), bj = rowsum(P;;) € Re,\\n\\n13: On chip, compute m?°Y = max(mj,1ii;;) € RB\", rev = em, eH Es, E RBr,\\n\\n14: On chip, compute Pyyopped = dropout(Pj;, Parop)-\\n\\n15: Write O; — diag(¢?”) “1 (diag(E)e™-\"\"” O; + e™/ mp peoppedyy ;) to HBM.\\n\\n16: Write € — €?°\", m; — m?*” to HBM.\\n\\n17: end if\\n\\n1s: end for\\n\\n19: end for\\n\\n20: Return O, ¢,m,R.\\n\\nD_ Extension Details\\n\\nD.1 + Block-sparse FLASHATTENTION\\n\\nWe describe the full block-sparse FLASHATTENTION algorithm in Algorithm [5] The algorithm is identical to Algorithm 2] except that we skip zero blocks. We prove the IO-complexity of block-sparse FLASHATTENTION.\\n\\nProof of Proposition [4} The proof is very similar to the proof of Theorem [2] For the block-sparse case, notice that we only need to load blocks corresponding to nonzero blocks. As a result, the number of HBM accesses are scaled by s, the fraction of nonzero blocks in the block-sparsity mask. However, for small values of s, we would still need to write the result O ¢ RN*¢. Therefore the number of HBM accesses is\\n\\nN?d?\\n\\no(va+\\n\\nD.2 Potential Extensions\\n\\nWe discuss here a few potential extensions of the IO-aware approach to speed up deep learning training. Multi-GPU Attention. Large language models are trained on hundreds or thousands of GPUs, and\\n\\none typically splits the attention computation between 4-8 GPUs on the same node [77]. This introduces\\n\\nanother level of memory hierarchy: beside GPU SRAM and GPU HBM, we also have the HBM of other\\n\\nGPUs. For very long sequences, the different GPUs on the same node can cooperate to compute attention by aking into account the asymmetry of different levels of memory hierarchy.\\n\\nSparse MLP layers. Typical dense MLP layers are compute-bound and not memory-bound. To improve\\n\\nheir efficiency, MLP layers with sparse weight matrices can be used [17]. However, many sparse MLP layers are instead memory-bound, and their speedup is often not proportional to the sparsity. We believe that an O-aware implementation can alleviate this issue and realize the benefits of sparsity. We are excited about ‘uture work in this direction, to reduce the computational requirement of large models and improve their wall-block runtime. Kernel machine learning. Our approach in FLASHATTENTION relies on the fact that the N x N attention matrix is a function of a low-rank matrix QK™ (of rank d « N). As a result, we can repeatedly oad the inputs Q,K and recompute the block of the attention matrix that we need, significantly reducing HBM access. As similar scenario happens in kernel machine learning: each element Kj; of the N x N kernel matrix K is a function of two vectors of size d < N, as it measures the similarity between two datapoints x; and x;. The KeOps library [8] [26] is a successful example of how reducing memory reads/writes can speed up kernel operations. We hope that this will motivate kernel methods that focus more on reducing IOs instead of just FLOPs.\\n\\nE Full Experimental Results\\n\\nE.1 BERT\\n\\nWe train BERT-large following the training procedure and hyperparameters of the reference MLPerf 1.1 implementation. In particular, we use the LAMB optimizer with learning rate 3.75e-3, with batch size 448, trained for at most 7100 steps. The training is stopped once the validation accuracy (for masked language modeling) reaches the target 72.0%, and the wall-clock run-time is measured. We train with FP16 precision using Apex AMP (with O2 optimization level).\\n\\nWe compare our results with the reported training speed from Nvidia that was submitted to MLPerf 1.1 (Table {i}.\\n\\nWe use the same train / validation data split provided by MLPerf 1.1 reference implementation. In particular, we evaluate on the same 10000 validation examples as the baseline from Nvidia.\\n\\nWe train the model on 8xA100-80GB GPUs. Each training run takes between 16 and 19 minutes, and we average the results of 10 runs.\\n\\nE.2. GPT-2\\n\\nWe use the standard implementations of GPT-2 [67] from Huggingface transformers library and from Nvidia’s Megatron-LM repo. We follow the training recipe of the Megatron-LM repo.\\n\\nWe use an effective batch size of 512, and use gradient accumulation to fit into available GPU memory. We use the AdamW optimizer, with learning rate 6e-4 for GPT-2 small and 1.5e-4 for GPT-2 medium, and weight decay of 0.1. All models are trained with the same hyperparameters for 400K steps. We run all implementations with mixed-precision training (PyTorch AMP).\\n\\nWe use the Openwebtext dataset, with the GPT-2 BPE tokenizer. We randomly select 0.5% of the dataset as the validation set, with the rest being used as training set. This random selection of validation set is done once, and all models are evaluated on the same validation set.\\n\\nWe train the model on 8xA100-40GB GPUs, and we measure the wall-clock training time. Training GPT-2 small takes between 2.7-9.5 days, and training GPT-2 medium takes between 6.9-21.0 days (Table [2).\\n\\n. 41 we plot of the validation perplexity throughout training of GPT-2 small/medium, using either HuggingFace implementation or our FLASHATTENTION implementation. We see that FLASHATTENTION be- haves the same as the baseline implementation and the validation perplexity curves of the two implementations almost lie on top of each other.\\n\\nLong Document Classification. For MIMIC-III and ECtHR, we follow the hyperparameters of Dai et al.\\n\\n[13].\\n\\n26\\n\\n30 —— GPT-2-small HuggingFace —— GPT-2-small FlashAttention 25 4 — GPT-2-medium HuggingFace > —— GPT-2-medium FlashAttention € Lv 2 204 © Qa w > 15 4 10\\n\\n: : : 100k 200k 300k Training steps\\n\\nFigure 4: Validation perplexity of GPT-2 small/medium using two implementations. We confirm that FLASHATTENTION yields the same validation curves as the baseline implementation from HuggingFace.\\n\\nE.3. LRA details\\n\\nWe follow the hyperparameters from the Long-range arena paper [80], the Long-range arena repo (h //github .com/google-research/long-range-arena), and the Nystrémformer reproduction [90]. To be generous to the baseline methods, if we are unable to reproduce the performance of any baseline for any of the five tasks, we report the better performance from Tay et al. or Xiong et al. [90] for that baseline on that task.\\n\\nAfter hyperparameter tuning, almost all of the attention methods achieve similar accuracy on all of the five LRA tasks.\\n\\nWe run all methods with mixed-precision training, except for Performer (not stable with mixed precision) and Local Attention (implementation does not support FP16).\\n\\nTo calculate the overall wallclock-time speedup, we take the geometric mean of the wallclock-time speedup of each of the five tasks.\\n\\nPath-X For Path-X and Path-256, we follow the hyperparameters from the PathFinder-32 experiments from the long-range arena paper{80]. For both, we first pretrain a model on Path-64. We take the checkpoint after 200 epochs, upsample its positional embedding (we duplicate the positional embeddings gridwise in space), and fine-tune it on the downstream task for 200 epochs with one epoch of linear warmup, and cosine decay of the learning rate. For Path-X, we take the best performing checkpoint (according to val accuracy), and additionally fine-tune it for 200 epochs with the same warmup and learning rate (this adds roughly 4 points of accuracy to FLASHATTENTION for Path-X, but the model starts overfitting afterwards).\\n\\nE.4 Comparison with Apex FMHA\\n\\nWe compare our method/implementation with Apex FMHA (https: //github.com/NVIDIA/apex/tree/ master/apex/contrib/csrc/fmha).\\n\\nWhen we started this project, Apex FMHA was the fastest implementation of attention (that we knew of), tailored for short sequences of length at most 512. In fact, almost all MLPerf submissions for BERT training benchmark running on Nvidia GPUs use FMHA for their model code, as of MLPerf 1.1 [58]. Since\\n\\n27\\n\\nTable 7: Runtime (ms) of FLASHATTENTION compared to FMHA by sequence length, with masking and dropout, measured on an A100-SXM4-40GB GPU. Batch size 64, 16 heads, head dimension 64 (i.e., BERT-large size).\\n\\nAttention Method | 128 256 512\\n\\nApex FMHA forward | 0.10 0.29 1.14 FLASHATTENTION forward | 0.08 0.22 0.81\\n\\nApex FMHA backward | 0.17 0.52 1.81 FLASHATTENTION backward | 0.20 0.53 2.00\\n\\nApex FMHA forward + backward | 0.27 0.81 = 2.95 FLASHATTENTION forward + backward | 0.28 0.75 2.81\\n\\nFMHA targets BERT models, it only supports head dimension 64, and only runs on A100 GPUs. FMHA ‘uses the attention computation dropout(softmax(MASK(QK\")))V into one CUDA kernel. In the forward ass, it stores the attention matrix softmax(MASk(QK’ )) to HBM to be used in gradient computation. As a result, it does not offer substantial memory saving (though for shorter sequences memory footprint is often not a primary concern).\\n\\nWe use FMHA code as a starting point, and apply two well-established techniques (tiling and recomputa- ion) to deal with long sequences and to save memory as mentioned in Section |3| As a result, we can support much longer sequences (e.g., up to length 64K). We also support more head dimensions (16, 32, 64, 128) and roader GPU types (all Turing and Ampere GPUs at the time of writing).\\n\\nIn Table [7] we compare the performance of FLASHATTENTION and Apex FMHA for short sequences (as FMHA only supports sequence length at most 512). Generally FLASHATTENTION is slightly faster than F MHA in the forward pass and slightly slower than FMHA in the backward pass. This is because we do not store the attention matrix in the forward pass and recompute it in the backward pass. Compared to FMHA, he overall runtime of FLASHATTENTION is about 4% slower for sequence length 128, 8% faster for sequence length 256, and 5% faster for sequence length 512.\\n\\nE.5 Speedup On Different Hardware and Configurations\\n\\nSpeedup varies between different types of GPU types and generations depending on HBM bandwidth and SRAM size. In this section, we profile FLASHATTENTION speedup on different GPUs and configurations.\\n\\nFlashAttention Speedup, A100\\n\\n@@—™ Dropout + Masking lm Masking Only lm No Masking, No Dropout 0) I I 128 256 512\\n\\n1024 2048 4096 Sequence Length\\n\\nBy L\\n\\nWw 1\\n\\nSpeedup (X times faster) BR N\\n\\nFigure 5: Speedup over standard PyTorch attention at different sequence lengths, on A100.\\n\\nA100 Figure [5]shows speedup on an A100 GPU with batch size 8, head dimension 64, and 12 attention heads, across different sequence lengths. We generally see 2-4x speedup, and we see more speedup when using dropout and masking due to kernel fusion.\\n\\n28\\n\\nFlashAttention Speedup, A100, d=128\\n\\n@mm™ Dropout + Padding Masking @@m_ Padding Masking Only\\n\\nCausal Mask | | | | @@—™_ No Masking, No Dropout\\n\\n1024 2048 * sequence Length\\n\\n3.04\\n\\n2.57\\n\\n2.05\\n\\n154\\n\\n1.0 4\\n\\nSpeedup (X times faster)\\n\\n0.54\\n\\n0.0\\n\\nFigure 6: Speedup over standard PyTorch attention at different sequence lengths, on A100, with head dimension 128.\\n\\nA100, Head Dimension 128 Speedup also changes when we increase the head dimension. Each block requires more memory, so we need to use smaller block sizes to fit into SRAM. Figure |6]shows speedup with head dimension 128 on an A100 (batch size 16, 12 heads). We see less speedup overall—but we can still see significant speedup (up to 3x) with a causal mask, where half the blocks are masked out.\\n\\nFlashAttention Speedup, GTX 3090\\n\\n@@—™ Dropout + Masking\\n\\n44 @ Masking Only @mm_ No Masking, No Dropout 3 4 24 14 i¢}\\n\\n1024 2048 oe eequence Length\\n\\nSpeedup (X times faster)\\n\\nFigure 7: Speedup over standard PyTorch attention at different sequence lengths, on RTX 3090.\\n\\nRTX 3090 Figure [7] shows speedup on an RTX 3090 GPU. Here, we use batch size 12 with 12 attention heads. We observe slightly higher speedups on the RTX 3090 (between 2.5-4.5x), since the memory bandwidth on an RTX 3090 is lower than on an A100 (roughly 900 GB/s vs. 1.5 TB/s).\\n\\nT4 Figure [8] shows speedup on a T4 GPU. T4 SRAM is smaller than A100, so we need to make the block sizes smaller in FLASHATTENTION. As a result, we observe less speedup on T4, which matches the IO complexity analysis in Section 3.2] T4 GPUs are commonly used for inference, so we also report speedup on the forward pass only.\\n\\n29\\n\\nFlashAttention Speedup, T4\\n\\n354 l@@—™_ Dropout + Masking g @m_ Masking Only £ 3.04 l@amm_ No Masking, No Dropout G3 2.54 iS 6 2.04 iad e154 3 © 1.04 oO Q 0.54 0.0\\n\\n1024 2048 ees Length\\n\\nFlashAttention Speedup, T4 (Forward Only)\\n\\n@@—™ Dropout + Masking\\n\\n44 @ Masking Only @mm_ No Masking, No Dropout 3 4 24 14 i¢}\\n\\n1024 2048 oe eequence Length\\n\\nSpeedup (X times faster)\\n\\nFigure 8: Speedup over standard PyTorch attention at different sequence lengths, on T4. Top: Combined forward pass + backward pass. Bottom: Forward pass only.\\n\\nE.6 Full Benchmarking Results\\n\\nWe report the full benchmarking results and experimental details on A100.\\n\\nBaselines We compare against reference implementations for exact attention from PyTorch/HuggingFace and Megatron, approximate attention, and sparse attention. For approximate attention, we compare against reference implementations of Reformer [51], Local Attention [68], Linformer Attention [84], Smyrf [19], and LongShortFormer (LSFormer) [94]. For sparse attention, we compare against reference implementations of Block-Sparse Attention form OpenAI [II], Longformer|3], and BigBird Attention [92]. For the approximate and sparse attention, we use a compression ratio of 1/8, or a compressed sequence length of 256, whichever is smaller.\\n\\nSetup We measure runtime and memory usage of the attention computation with 8 heads of dimension 64, and batch size 16 on a machine with one A100 GPU with 40 GB of GPU HBM. We vary sequence length in our experiments. We compute attention on random vectors for Q, K, and V (we do not measure the projection from the hidden layer). For dropout, we use dropout 0.1; for masking, we use a padding mask with uniformly-random mask lengths between the total sequence length and the total sequence length minus 20. To measure runtime, we take the average of 100 measurements of the attention call. We only measure memory footprint once, since it does not vary between runs.\\n\\n30\\n\\nTable 8: Pointers to results tables.\\n\\nDropout Masking Pass Table Yes Yes Forward Table |9 Yes Yes Backwar Table |10 Yes Yes Combined Table [IT\\n\\nfe) Yes Forward Table [12 fe) Yes Backwar Table fe) Yes Combined Table Yes No Forward Table [15 Yes No Backwar Table [16 Yes No Combined Table fe) No Forward Table fe) No Backwar Table oO No Combined Table [20 oO No Memory Usage (Combined) | Table |2T\\n\\nTable 9: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout and masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.36 0.34 0.78 2.54 9.33 36.33 - - - - Megatron 0.40 0.40 1.10 3.65 16.19 - - - - - Reformer 2.03 3.15 5.67 11.02 22.59 46.14 97.38 212.13 - - Local Attention 0.83 0.86 1.01 2.20 7.13 14,32 28.60 57.79 117.67 - Linformer 0.67 0.52 0.69 0.71 1.65 3.18 6.15 12.16 24.17 52.39 Smyrf 2.27 2.34 3.91 7.44 14.71 29.22 58.27 116.41 - - LSformer 1.18 1.27 1.34 3.38 11.40 22.55 44.95 89.76 179.66 - Block Sparse 1.12 1.11 2.13 2.77 6.95 20.91 - - - - Longformer 1.22 1.14 1.08 1.95 5.72 12.98 - - - - BigBird 1.13 1.12 1.12 1.77 6.03 13.68 - - - - FLASHATTENTION 0.04 0.06 0.21, 0.82 2.85 10.41 41.74 167.19 670.76 2682.35 Block-Sparse FLASHATTENTION 0.06 0.06 0.06 0.12 0.44 0.86 1.70 3.29 6.55 13.34\\n\\nWe report timing results on the forward pass, backward pass, and combined forward\\n\\nbackward pass.\\n\\nWe measure each method with and without dropout, masking, or both—except for Block Sparse, Longformer, and BigBird. These methods did not successfully run the backward pass with masking due to a bug in external libraries, so we measured them without masking to be generous. We use FP16 for all measurements, except for Local Attention, whose implementation only supports FP32.\\n\\nFor each baseline, we increase sequence length until it runs out of memory on the GPU, except for the following exceptions: The Megatron implementation does not support sequence lengths longer than 2048. Block-Sparse (OpenAI) does not support sequence lengths longer than 4096. Longformer and BigBird do not\\n\\nsupport sequence lengths longer than 8092. We measure memory usage on the combined forward + backward pass, without dropout or masking.\\n\\nResults Table\\n\\n31\\n\\nsummarizes all the experimental configurations and contains pointers to the results tables.\\n\\nTable 10: Backward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout and masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.37 0.49 1.66 5.81 22.32 87.67 - - - -\\n\\nMegatron 0.35 0.32 0.77 2.42\\n\\nReformer 2.37 4.59 8.91 17.68\\n\\nLocal Attention 0.55 0.62 1.49 4.03\\n\\nLinformer 0.89 0.80 0.81 0.93\\n\\nSmyrf 1.41 2.83 5.43 10.72\\n\\nLSformer 1.75 1.76 3.01 7.50\\n\\n70.05 140.01 - - 27.61 55.20 110.27 221.40 - 4.75 9.29 18.27 36.53. - 42.31 84.48 168.95 - - 39.08 76.39 150.82 - -\\n\\nBlock Sparse 1.29 1.28 2.18 3.04 21.16 - - - - Longformer 1.27 1.31 . 2.04 10.74 25.95, - - - BigBird 1.33 1.28 1.32 1.81 11.44 27.45, -\\n\\nFLASHATTENTION 0.30 0.26 0.68 2.02 Block-Sparse FLASHATTENTION 0.30 0.27 0.29 0.59\\n\\n26.89 105.70 418.96 1666.89 6660.44 2.94 5.82 11.85 23.98 47.61\\n\\nTable 11: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length, with dropout and masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.84 0.86 2.35 8.29 31.75 124.19 - - - - Megatron 0.87 0.89 1.33 4.21 16.50 - Reformer 4.30 7.76 14.60 28.74 57.79 116.34 237.57 - - Local Attention 1.40 1.60 2.06 6.06 20.94 42.01 84.08 168.48 339.45 - Linformer 1.57 1.49 1.60 4.19 8.04 15.71 30.92 61.47 - Smyrf 3.41 5.08 18.18 36.03 71.68 143.04 285.87 - - LSformer 3.08 3.10 10.90 31.59 61.72 121.51 241.18 - - Block Sparse 2.54 2.52 5.44 13.29 39.19 - - - - Longformer 2.47 2.49 3.10 10.39 22.49 60.44 - - - BigBird 2.51 2.49 3.40 10.97 23.89 63.28 - - - FLASHATTENTION 0.43 0.41 2.55 9.56 37.49 147.75 586.61 2339.11 9341.30 Block-Sparse FLASHATTENTION 0.44 0.44 0.89 1.95 4.12 7.64 16.60 32.73 64.11\\n\\nTable 12: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 PyTorch Attention 0.30 0.30 0.63 1.93 Megatron 0.45 0.41 0.43 1.52 Reformer 1.87 3.00 5.37 10.43\\n\\nLocal Attention 0.70 0.81 1.02 2.09 Linformer 0.63 0.50 0.67 0.65\\n\\nSmyrf 2.38 2.32 3.76 7.16\\n\\nLSformer 1,22 1.29 1.44 3.28\\n\\nBlock Sparse 0.96 1.04 1.66 2.16 Longformer 0.99 0.98 0.99 1.56 BigBird 0.96 1.02 1.02 1.48 FLASHATTENTION 0.03 0.04 0.17 0.68 Block-Sparse FLASHATTENTION 0.05, 0.04 0.05 0.11\\n\\n4096 8192 16384 32768 65536 27.45 112.90 - -\\n\\n43.83 92.80 203.24 - 13.34 26.77 54.02 110.11 - 2.60 5.04 9.92 19.69 43.47 28.09 55.98 111.73 - 21.72 43.29 86.32 172.76 -\\n\\n11.07 32.98 - - - 11.59 34.16 - - 8.40 33.55 134.14 537.50 2150.88 0.68 1.33 2.54 5.34 10.73\\n\\nTable 13: Backward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 4096 8192 16384 32768 65536 PyTorch Attention 0.44 0.46 5.33 79.87 - - - - Megatron 0.29 0.31 1.95 - - - - - Reformer 2.31 4.47 17.20 68.09 136.02 - - - Local Attention 0.51 0.62 3.81 26.72 53.41 106.82 214.15 - Linformer 0.76 0.81 0.87 4.25 8.35 16.38 32.67 72.11 Smyrf 1.34 2.77 10.46 41.27 82.41 164.86 - - LSformer 1.66 1.61 7.42 38.35, 74.92 147.86 - - Block Sparse 1.24 1.25 2.91 19.67 - - - - Longformer 1.27 1.23 1.85 10.21 24.89 - - - BigBird 1.43 1.50 1.69 10.86 26.26 - - - FLASHATTENTION 0.21 0.22 0.62 1.84 22.25 86.21 338.91 1343.91 5361.09 Block-Sparse FLASHATTENTION 0.22 0.22 0.26 0.57 3.13 5.98 12.21 23.49 47.85\\n\\nTable 14: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length, with masking. Best in bold, second best underlined.\\n\\nAttention Method | 128 256 512 —-1024_—.2048——-4096 8192 16384-32768 65536 PyTorch Attention | 0.80 0.81 2.08 7.23 27.51 107.58 = = Megatron | 0.81 0.83 1.09 _3.36_—_—:12.39 - - Reformer | 4.16 7.46 14.06 27.68 55.66 112.15 229.37 Local Attention | 1.39 1.68 2.08 5.83 20.04 40.16 80.44 161.35 325.11 - Linformer | 1.51 142 156 167 3.67 13.63 26.77 53.36 117.56 Smyrf | 3.38 4.93 9.07 17.66 34.94 138.72 277.41 - = LSformer | 3.08 3.10 4.26 10.90 _31.59 121.51 241.18 - - Block Sparse | 2.39 240 3.31 5.02 12.25 Longformer | 2.36 2.34 2.38 2.94 9.83 BigBird | 2.35 2.35 2.37 3.25 10.36 FLASHATTENTION | 0.32 0.30 0.83. 237 7.95 Block-Sparse FLASHATTENTION | 0.34 0.34 0.36 0.69 1.85\\n\\n58.12 - - - 60.63 - - - 119.98 473.65 1883.43 7513.01 7.16 14.85 30.46 60.03\\n\\nTable 15: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout. Best in bold, second best underlined.\\n\\nAttention Method | 128 256 512-1024 ~—-2048—— 4096-8192 16384-32768 65536, PyTorch Attention | 0.26. 0.24 0.57 1.80 656 25.34 = = = = Megatron | 0.27 0.27 (0.56 «1.88 6.56 - - - - - Reformer | 1.83 2.96 5.31 10.33 21.19 4342 91.96 201.34 = Local Attention | 0.51 0.60 0.78 2.01 6.23 12.52 25.07 50.50 102.18 - Linformer | 0.47 0.37 0.49 0.52 1.37 2.65 5.12, 10.13 -20.25 44.16 Smyrf | 2.12 2.01 315 5.97 i183 23.36 4648 92.72 - LSformer | 1.28 1.33 1.51 3.39 «11.40 -22.54 44.96 89.85 «179.73 - Block Sparse | 1.03. 1.00. 1.72 2.39 596 17.88 = Longformer | 1.02 1.03 1.03 1.73 5.10 11.63 34.22 - - - BigBird | 0.99 1.03 1.01 1.58 5.36 —-:12.27 35.56 - - FLASHATTENTION | 0.10 0.10 0.22 0.83 2.81 10.38 41.63 167.01 668.74 2678.11 Block-Sparse FLASHATTENTION | 0.54 0.51 0.68 0.61 0.67 1.10 1.89 3.71 7.18 14.41\\n\\nTable 16: Backward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.44 0.35 2.94 10.77 41.67 - - - - Megatron 0.28 0.33 2.94 10.80 - - - - - Reformer 2.24 4.34 16.62 33.02 65.77 131.52 - - Local Attention 0.51 0.58 3.71 12.96 25.98 51.94 103.72 207.78 - Linformer 0.84 0.74 0.85 2.28 4.37 8.66 33.78 - Smyrf 1.27 2.56 9.66 19.16 38.13 76.17 LSformer 1.67 1.77 7.52 20.10 39.13 76.35, Block Sparse 1.27 1.36 3.04 7.27 21.18 - Longformer 1.28 1.34 1.98 5.24 10.74 25.95, - - - BigBird 1.48 1.47 1.81 5.57 11.38 27.43 - - FLASHATTENTION 0.15 0.18 1.86 6.50 26.21 104.27 416.10 1661.92 6643.01 Block-Sparse FLASHATTENTION 0.17 0.17 0.40 1.10 2.04 4.43 9.33 18.28 37.31\\n\\nTable 17: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length, with dropout. Best in bold, second best underlined.\\n\\nAttention Method | 128 256 1024 2048 1638432768 65536\\n\\nPyTorch Attention | 0.60 0.67 Z82 17.47 =\\n\\nMegatron | 0.88 _0.90 4.73 17.41 - - -\\n\\nReformer | 4.06 7.28 26.98 54.27 =\\n\\nLocal Attention | 1.09 1.40 5.61 19.23 154.63 311.12 -\\n\\nLinformer | 1.31 1.21 139 3.73 27.69 55.00 -\\n\\nSmyrf | 3.00 4.37 15.66 31.04 245.65 - -\\n\\nLSformer | 3.07 3.17 10.89 31.54 240.94 - -\\n\\nBlock Sparse | 2.54 2.52 5.44 13.29 =\\n\\nLongformer | 2.47 2.49 3.10 10.39 - - -\\n\\nBigBird | 2.51 2.49 3.40 10.97 - - - FLASHATTENTION | 0.35 0.36 252 9.16 583.45 2332.01 Block-Sparse FLASHATTENTION | 0.91 0.83 0.92 1.83 13.56 26.71\\n\\n33\\n\\nTable 18: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.21 0.22 0.43 1.27 4,32 16.47 67.77 - - - Megatron 0.24 0.26 0.42 1.33 4.28 - - - Reformer 1.77 2.82 5.01 9.74 20.03 41.11 87.39 192.40 - - Local Attention 0.48 0.57 0.80 1.90 5.76 11.56 23.13 46.65 94.74 - Linformer 0.46 0.36 0.45 0.50 1.09 2.09 4.01 7.90 15.70 35.40 Smyrf 1.94 1.96 3.01 5.69 11.26 22.23 44,21 88.22 - LSformer 1.21 1.34 1.34 3.31 11.01 21.71 43.27 86.32 172.85 - Block Sparse 0.96 1.04 1.66 2.16 5.41 16.15 - Longformer 0.98 0.99 1.56 4.79 11.07 32.98 - - - BigBird 0.96 1.02 1.02 1.48 5.05 11.59 34.16 - - FLASHATTENTION 0.08 0.09 0.18 0.68 2.40 8.42 33.54 134.03 535.95, 2147.05 Block-Sparse FLASHATTENTION 0.56 0.52 0.63 0.65 0.61 0.96 1.69 3.02 5.69 11.77\\n\\nTable 19: Backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.26 0.29 2.44 8.82 33.87 - - = = Megatron 0.29 0.30 2.59 8.86 - - - -\\n\\n16.12 32.02 63.84 127.60 - - 3.60 12.52 25.08 50.22 100.23 200.66 - 0.80 2.04 3.88 7.67 15.04 30.11 63.15 9.42 18.65 37.12 74.15 148.35 - - 7.40 19.72 38.27 74.89 147.99 - - 2.91 6.78 19.67 - - - - 1.85 4.99 10.21 24.89 - - - 1.69 5.25 10.86 26.26 - - - 1.62 5.45 21.57 84.75, 336.00 1338.56 5343.19 0.38 1.20 2.34 4.69 9.10 18.74 37.04\\n\\nReformer 2.18 4.21\\n\\nLocal Attention 0.51 0.64\\n\\nLinformer 0.69 0.76\\n\\nSmyrf | 1.24 2.49\\n\\nLSformer 1.68 1.61\\n\\nBlock Sparse 1.24 1.25\\n\\nLongformer 1.27 1.23\\n\\nBigBird 1.43 1.50\\n\\nFLASHATTENTION | 0.11 0.16 Block-Sparse FLASHATTENTION | 0.11 0.12\\n\\nTable 20: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.67 0.70 3.67 13.22 50.44 - - = =\\n\\nMegatron 0.74 0.65 3.80 13.21 - - - - -\\n\\nReformer 3.93 7.01 25.89 52.09 215.13 - - -\\n\\nLocal Attention 1.09 1.27 5.38 18.32 73.67 147.29 296.35 - Linformer 1.31 1.25 1.29 3.20 11.93 23.39 46.72 100.52\\n\\nSmyrf 2.98 4,23 15.12 29.96 118.60 237.02 - -\\n\\nLSformer 3.03 3.05 10.70 30.77 234.94 - -\\n\\nBlock Sparse 2.39 2.40 5.02 12.25 - - - -\\n\\nLongformer 2.36 2.34 2.94 9.83 58.12 - - -\\n\\nBigBird 2.35 2.35 3.25 10.36 60.63 - - - FLASHATTENTION 0.31 0.31 2.29 7.64 118.50 470.51 1876.08 7492.85,\\n\\nBlock-Sparse FLASHATTENTION 0.74 0.77 0.88 1.71 3.21 6.56 12.60 24.93 50.39\\n\\nTable 21: Memory usage (MB) of various exact/approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 36 104 336 1184 4416 17024 - - - - Megatron 36 104 336 1184 4416 - - Reformer 377 754 1508 3016 6033) 12067 24134 - - Local Attention 53, 110 232 592 1696 3392 6784 13568 27136 - Linformer 25, 52 114 287 832 1652 3292 6572 13132 26252 Smyrf 217 434 868 1737 3474 6947 13894 27788 - - LSformer 72 152 333 796 2540 5068 10125 20240 - - Block Sparse 33 82 228 408 910 2401 - Longformer 30 61 124 277 681 1370 2748 - - - BigBird 33 66 131 294 708 1431 2872 - - - FLASHATTENTION 22 44 104 209 418 836 1672 3344 6688 13376 Block-Sparse FLASHATTENTION 22 44 104 209 418 836 1672 3344 6690 13384'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c53c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5ac817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3abe16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfc66244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 31529\n",
      "Embedding Cost in USD: 0.063058\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "def print_embedding_cost(texts):\n",
    "    enc = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000*0.002:.6f}')\n",
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad390b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "output_summary = chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948f5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper introduces FLASHATTENTION, an IO-aware exact attention algorithm designed for GPUs that reduces memory reads/writes between GPU memory levels, improving the speed and memory efficiency of Transformers on long sequences. By leveraging techniques such as tiling and recomputation, FLASHATTENTION achieves faster training speeds and higher model quality compared to existing methods, enabling Transformers to handle longer context and achieve better performance on various tasks. The algorithm is open-sourced and outperforms existing attention implementations in terms of speed and memory efficiency. Additionally, the analysis shows a significant reduction in HBM accesses compared to standard attention, highlighting the efficiency and effectiveness of FLASHATTENTION in handling attention computations on GPUs. The paper also introduces an extension to FLASHATTENTION called block-sparse FLASHATTENTION, which further improves IO complexity by incorporating sparsity. Experimental results demonstrate that FLASHATTENTION outperforms existing implementations in terms of training speed and model accuracy, making it the fastest algorithm for training BERT and GPT-2 models. The algorithm also enables Transformers to handle longer sequences, resulting in higher model quality and improved performance on various benchmarks, including the MIMIC-III and ECtHR datasets. Additionally, FLASHATTENTION achieves significant accuracy improvements on challenging tasks like Path-X and Path-256, showcasing its effectiveness in handling long context and improving model performance. The paper also delves into the details of the FLASHATTENTION algorithm, including the memory-efficient forward and backward passes, as well as the implementation details for both the forward and backward passes. The algorithm's efficiency and effectiveness in handling attention computations on GPUs are further highlighted, making it a valuable contribution to the field of deep learning and natural language processing. The paper also provides a detailed comparison with the algorithm of Rabe and Staats, highlighting the differences in memory efficiency and computational approach between the two methods. Additionally, the paper discusses the IO complexity of streaming attention, deriving conditions on block sizes and providing a proof of the algorithm's efficiency. The paper also explores potential extensions of the IO-aware approach to speed up deep learning training, such as multi-GPU attention, sparse MLP layers, and kernel machine learning. Experimental results for BERT, GPT-2, and Long-range arena tasks demonstrate the effectiveness and efficiency of FLASHATTENTION in improving model performance and training speed. The paper further provides insights into the speedup of FLASHATTENTION on different hardware configurations, showcasing its adaptability and performance across various GPU types and generations. The new experimental results and comparisons with other attention mechanisms further validate the superior performance of FLASHATTENTION in terms of speed, memory efficiency, and model accuracy across different sequence lengths and configurations. The addition of Block-Sparse FLASHATTENTION further enhances the algorithm's efficiency and memory usage, making it a competitive choice for attention mechanisms in deep learning applications.\n"
     ]
    }
   ],
   "source": [
    "print(output_summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd90fe7",
   "metadata": {},
   "source": [
    "### Refine with custom prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2dc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "Write a concise summary of the following extracting the key information:\n",
    "Text: `{text}`\n",
    "CONCISE SUMMARY:'''\n",
    "\n",
    "\n",
    "initial_prompt = PromptTemplate(template=prompt_template, input_variables=['text'])\n",
    "\n",
    "refine_template = '''\n",
    "Your job is to produce a final summary.\n",
    "I have provided an existing summary up to a certain point: {existing_answer}.\n",
    "Please refine the existing summary with some more context below.\n",
    "---------------------\n",
    "{text}\n",
    "---------------------\n",
    "Start the final summary with INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWING by BULLET POINTS\n",
    "if possible AND end the summary with CONCLUSION PHRASE.\n",
    "'''\n",
    "\n",
    "refine_prompt = PromptTemplate(\n",
    "    template=refine_template,\n",
    "    input_variables=['existing_answer', 'text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf7239c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    question_prompt=initial_prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "output_summary = chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "703f8b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"2205.14135v2 [cs.LG] 23 Jun 2022\\n\\narXiv\\n\\nFLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness\\n\\nTri Dao’, Daniel Y. Fu’, Stefano Ermon', Atri Rudra?, and Christopher Ré*\\n\\n‘Department of Computer Science, Stanford University *Department of Computer Science and Engineering, University at Buffalo, SUNY\\n\\n{trid,danfu}@cs.stanford.edu, ermon@stanford.edu, atri@buffalo.edu, chrismre@cs.stanford.edu\\n\\nJune 24, 2022\\n\\nAbstract\\n\\nTransformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. We argue that a missing principle is making attention algorithms JO- aware—accounting for reads and writes between levels of GPU memory. We propose FLASHATTENTION, an IO-aware exact attention algorithm that uses tiling to reduce the number of memory reads/writes between GPU high bandwidth memory (HBM) and GPU on-chip SRAM. We analyze the IO complexity of FLASHATTENTION, showing that it requires fewer HBM accesses than standard attention, and is optimal for a range of SRAM sizes. We also extend FLASHATTENTION to block-sparse attention, yielding an approximate attention algorithm that is faster than any existing approximate attention method. FLASHATTENTION trains Transformers faster than existing baselines: 15% end-to-end wall-clock speedup on BERT-large (seq. length 512) compared to the MLPerf 1.1 training speed record, 3x speedup on GPT-2 (seq. length 1K), and 2.4x speedup on long-range arena (seq. length 1K-4K). FLASHATTENTION and block-sparse FLASHATTENTION enable longer context in Transformers, yielding higher quality models (0.7 better perplexity on GPT-2 and 6.4 points of lift on long-document classification) and entirely new capabilities: the first Transformers to achieve better-than-chance performance on the Path-X challenge (seq. length 16K, 61.4% accuracy) and Path-256 (seq. length 64K, 63.1% accuracy).\\n\\n1 Introduction\\n\\nTransformer models [82] have emerged as the most widely used architecture in applications such as natural language processing and image classification. Transformers have grown larger [5] and deeper [83], bu equipping them with longer context remains difficult [80], since the self-attention module at their hear has time and memory complexity quadratic in sequence length. An important question is whether making attention faster and more memory-efficient can help Transformer models address their runtime and memory challenges for long sequences.\\n\\nMany approximate attention methods have aimed to reduce the compute and memory requirements o attention. These methods range from sparse-approximation [74] to low-rank approximation [12] [50] [84], and their combinations [3} [9] [92]. Although these methods reduce the compute requirements to linear or near-linear in sequence length, many of them do not display wall-clock speedup against standard attention and have not gained wide adoption. One main reason is that they focus on FLOP reduction (which may no correlate with wall-clock speed) and tend to ignore overheads from memory access (IO).\\n\\nIn this paper, we argue that a missing principle is making attention algorithms [O-aware [I]—that is, carefully accounting for reads and writes to different levels of fast and slow memory (e.g., between fast GPU on-chip SRAM and relatively slow GPU high bandwidth memory, or HBM [45], Figure[I] left). On modern\\n\\nOuter Loop\\n\\n—___*_, Ki dxN . Attention on GPT-2 Copy Block to SRAM : Outer Loop Vinxd J Matmul\\n\\na\\n\\n£0\\\\ SRAM: 19 TB/s (20 MB) j 1 | Dropout 1 1 z HBM: 1.5TB/s (40GB) 2 1 1 Copy ©} £10 8 + Compute Block | z a ] Softmax 5 Lat on SRAM lz =| = IO MCISa DRAM: 12.8GB/s £ a 1/3 slF. Fused (CPU DRAM) (>1 TB) I ni Mask Kernel 1 1 3 . S L 4 Matmul Memory Hierarchy with Output to HBM ] Matmu Bandwidth & Memory Size sm(QKV: Nxd PyTorch FlashAttention\\n\\nInner Loop FlashAttention\\n\\nFigure 1: Left: FLASHATTENTION uses tiling to prevent materialization of the large N x N attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), FLASHATTENTION loops through blocks of the K and V matrices and loads them to fast on-chip SRAM. In each block, FLASHATTENTION loops over blocks of Q matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM. Right: Speedup over the PyTorch implementation of attention on GPT-2. FLASHATTENTION does not read and write the large N x N attention matrix to HBM, resulting in an 7.6x speedup on the attention computation.\\n\\nGPUs, compute speed has out-paced memory speed [62] [63], and most operations in Transformers are bottlenecked by memory accesses [43]. IO-aware algorithms have been critical for similar memory-bound operations, when reading and writing data can account for a large portion of the runtime—such as database joins [71], image processing [70], numerical linear algebra [4], and more [40] [85]. However, common Python interfaces to deep learning such as PyTorch and Tensorflow do not allow fine-grained control of memory access.\\n\\nWe propose FLASHATTENTION, a new attention algorithm that computes exact attention with far fewer memory accesses. Our main goal is to avoid reading and writing the attention matrix to and from HBM. This requires (i) computing the softmax reduction without access to the whole input (ii) not storing the large intermediate attention matrix for the backward pass. We apply two well-established techniques to address these challenges. (i) We restructure the attention computation to split the input into blocks and make several passes over input blocks, thus incrementally performing the softmax reduction (also known as tiling). (ii) We store the softmax normalization factor from the forward pass to quickly recompute attention on-chip in the backward pass, which is faster than the standard approach of reading the intermediate attention matrix from HBM. We implement FLASHATTENTION in CUDA to achieve fine-grained control over memory access and fuse all the attention operations into one GPU kernel. Even with the increased FLOPs due to recomputation, our algorithm both runs faster (up to 7.6x on GPT-2 [67], Figure [i]right) and uses less memory—linear in sequence length—than standard attention, thanks to the massively reduced amount of HBM access.\\n\\nWe analyze the IO complexity of FLASHATTENTION, proving that it requires O(N?d?M~!) HBM accesses where d is the head dimension and M is the size of SRAM, as compared to Q(Nd + N?) of standard attention. For typical values of d and M, FLASHATTENTION requires many times fewer HBM accesses compared to standard attention (up to 9x fewer, as shown in Fig.|2). Moreover, we provide a lower bound, showing that no exact attention algorithm can asymptotically improve on the number of HBM accesses over all SRAM sizes.\\n\\nWe also show that FLASHATTENTION can serve as a useful primitive for realizing the potential of approximate attention algorithms by overcoming their issues with memory access overhead. As a proof of concept, we implement block-sparse FLASHATTENTION, a sparse attention algorithm that is 2-4x faster than even FLASHATTENTION, scaling up to sequence length of 64k. We prove that block-sparse FLASHATTENTION has better IO complexity than FLASHATTENTION by a factor proportional to the sparsity ratio. We discuss further extensions to other operations (attention on multi-GPU, kernel regression, block-sparse matrix\\n\\nmultiply) in Section [5] We open-source FLASHATTENTION to make it easier to build on this primitive[}]\\n\\nWe empirically validate that FLASHATTENTION speeds up model training and improves model quality by modeling longer context. We also benchmark the runtime and memory footprint of FLASHATTENTION and block-sparse FLASHATTENTION compared to prior attention implementations.\\n\\ne Faster Model Training. FLASHATTENTION trains Transformer models faster in wall-clock time. We train BERT-large (seq. length 512) 15% faster than the training speed record in MLPerf 1.1 [58], GPT2 (seq. length 1K) 3x faster than baseline implementations from HuggingFace [87] and Megatron-LM [77], and long-range arena (seq. length 1K-4K) 2.4x faster than baselines.\\n\\ne Higher Quality Models. FLASHATTENTION scales Transformers to longer sequences, which improves their quality and enables new capabilities. We observe a 0.7 improvement in perplexity on GPT-2 and 6.4 points of lift from modeling longer sequences on long-document classification [13]. FLASHATTENTION enables the first Transformer that can achieve better-than-chance performance on the Path-X challenge, solely from using a longer sequence length (16K). Block-sparse FLASHATTENTION enables a Transformer to scale to even longer sequences (64K), resulting in the first model that can achieve better-than-chance performance on Path-256.\\n\\ne Benchmarking Attention. FLASHATTENTION is up to 3x faster than the standard attention implemen- tation across common sequence lengths from 128 to 2K and scales up to 64K. Up to sequence length of 512, FLASHATTENTION is both faster and more memory-efficient than any existing attention method, whereas for sequence length beyond 1K, some approximate attention methods (e.g., Linformer) start to become faster. On the other hand, block-sparse FLASHATTENTION is faster than all existing approximate attention methods that we know of.\\n\\n2 Background\\n\\nWe provide some background on the performance characteristics of common deep learning operations on modern hardware (GPUs). We also describe the standard implementation of attention.\\n\\n2.1 Hardware Performance\\n\\nWe focus here on GPUs. Performance on other hardware accelerators are similar [46] [48].\", metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='We focus here on GPUs. Performance on other hardware accelerators are similar [46] [48].\\n\\nGPU Memory Hierarchy. The GPU memory hierarchy (Fig. [i] left) comprises multiple forms of memory of different sizes and speeds, with smaller memory being faster. As an example, the A100 GPU has 40-80GB of high bandwidth memory (HBM) with bandwidth 1.5-2.0TB/s and 192KB of on-chip SRAM er each of 108 streaming multiprocessors with bandwidth estimated around 19TB/s . The on-chip SRAM is an order of magnitude faster than HBM but many orders of magnitude smaller in size. As compute has gotten faster relative to memory speed [61] [63], operations are increasingly bottlenecked by memory (HBM) accesses. Thus exploiting fast SRAM becomes more important.\\n\\nExecution Model. GPUs have a massive number of threads to execute an operation (called a kernel).\\n\\nEach kernel loads inputs from HBM to registers and SRAM, computes, then writes outputs to HBM.\\n\\nPerformance characteristics. Depending on the balance of computation and memory accesses, op-\\n\\nerations can be classified as either compute-bound or memory-bound. This is commonly measured by the\\n\\narithmetic intensity ; which is the number of arithmetic operations per byte of memory ac\\n\\n. Compute-bound: the time taken by the operation is determined by how many arithmetic operations there are, while time accessing HBM is much smaller. Typical examples are matrix multiply with large inner dimension, and convolution with large number of channels.\\n\\n2. Memory-bound: the time taken by the operation is determined by the number of memory accesses, while time spent in computation is much smaller. Examples include most other operations: elementwise (e.g., activation, dropout), and reduction (e.g., sum, softmax, batch norm, layer norm).\\n\\nKernel fusion. The most common approach to accelerate memory-bound operations is kernel fusion: if there are multiple operations applied to the same input, the input can be loaded once from HBM, instead of\\n\\nmultiple times for each operation. Compilers can automatically fuse many elementwise operations [75].\\n\\n1PLASHATTENTION code is available at https: //github.com/HazyResearch/flash- attention\\n\\nw\\n\\nHowever, in the context of model training, the intermediate values still need to be written to HBM to save for the backward pass, reducing the effectiveness of naive kernel fusion.\\n\\n2.2 Standard Attention Implementation\\n\\nGiven input sequences Q, K, V ¢ R‘*¢ where N is the sequence length and d is the head dimension, we want to compute the attention output O « RN*4:\\n\\nS=QK™ «R**, P=softmax(S)—«RY*Y, O=PVeERN*,\\n\\nwhere softmax is applied row-wise.\\n\\nStandard attention implementations materialize the matrices § and P to HBM, which takes O(N?) memory. Often N > d (e.g., for GPT2, N = 1024 and d = 64). We describe the standard attention implementation in Algorithm |0| As some or most of the operations are memory-bound (e.g., softmax), the large number of memory accesses translates to slow wall-clock time.\\n\\nThis problem is exacerbated by other elementwise operations applied to the attention matrix, such as masking applied to S or dropout applied to P. As a result, there have been many attempts to fuse several elementwise operations, such as fusing masking with softmax [77].\\n\\nIn Section [3.2] we will show that the standard attention implementation performs HBM accesses quadratic in the sequence length N. We also compare the number of FLOPs and number of HBM accesses of standard attention and of our method (FLASHATTENTION).\\n\\nAlgorithm 0 Standard Attention Implementation\\n\\nRequire: Matrices Q,K, V ¢ R‘*¢ in HBM. 1: Load Q,K by blocks from HBM, compute § = QK\", write S to HBM. 2: Read S from HBM, compute P = softmax(S), write P to HBM. 3: Load P and V by blocks from HBM, compute O = PV, write O to HBM. 4: Return O.\\n\\n3. FLASHATTENTION: Algorithm, Analysis, and Extensions\\n\\nWe show how to compute exact attention with fewer HBM reads/writes and without storing large intermediate matrices for the backward pass. This yields an attention algorithm that is both memory efficient and faster in wall-clock time. We analyze its IO complexity, showing that our method requires much fewer HBM accesses compared to standard attention. We further show that FLASHATTENTION can serve as a useful primitive by extending it to handle block-sparse attention.\\n\\nWe focus here on the forward pass for ease of exposition; Ap pendix [B] contains details for the backward.\\n\\n3.1 An Efficient Attention Algorithm With Tiling and Recomputation\\n\\nGiven the inputs Q, K, V ¢ R“*¢ in HBM, we aim to compute the attention output O ¢ RN*4 and write it to HBM. Our goal is to reduce the amount of HBM accesses (to sub-quadratic in N).\\n\\nWe apply two established techniques (tiling, recomputation) to overcome the technical challenge of computing exact attention in sub-quadratic HBM accesses. We describe this in Algorithm [I] The main idea is that we split the inputs Q, K, V into blocks, load them from slow HBM to fast SRAM, then compute the attention output with respect to those blocks. By scaling the output of each block by the right normalization factor before adding them up, we get the correct result at the end.\\n\\nTiling. We compute attention by blocks. Softmax couples columns of K, so we decompose the large softmax with scaling (66). For numerical stability, the softmax of vector x € R? is computed as:\\n\\nFQ) €(x)\"\\n\\nm(x):=max x;, f(x) := [en-m) Lee exam(x) | > Oxy:= » f(x), softmax(x) :=\\n\\nFor vectors x“, x2) € R8, we can decompose the softmax of the concatenated x = [x x)] € R? as:\\n\\nm(x) = m([x@ x®@]) = max(m(x), m(x)), f= [ems >-m09 Fe) ers) -m(s) #(¢))] ;\\n\\nf(x) = e(fx x)]) = er x)-m(x) £1) $ eM) mx) ¢(2)), softmax(x) = fo. Therefore if we keep track of some extra statistics (m(x), €(x)), we can compute softmax one block at a time We thus split the inputs Q, K, V into blocks (Algorithm ine 3) , compute the softmax values along with extra statistics (Algorithm [I] line [T0), and combine the results (Algorithm [I] ine [12)\\n\\nRecomputation. One of our goals is to not store O(N?) intermediate values for the backward pass. The backward pass typically requires the matrices §,P ¢ RY** to compute the gradients with respect to Q,K, V. However, by storing the output O and the softmax normalization statistics (m, £), we can recompute the attention matrix § and P easily in the backward pass from blocks of Q, K, V in SRAM. This can be seen as a form of selective gradient checkpointing [10] [34]. While gradient checkpointing has been suggested to reduce the maximum amount of memory required [66], all implementations (that we know off) have to trade speed for memory. In contrast, even with more FLOPs, our recomputation speeds up the backward pass due to reduced HBM accesses (Fig. |2). The full backward pass description is in Appendix [B]\\n\\nImplementation details: Kernel fusion. Tiling enables us to implement our algorithm in one CUDA kernel, loading input from HBM, performing all the computation steps (matrix multiply, softmax, optionally masking and dropout, matrix multiply), then write the result back to HBM (masking and dropout in Appendix [B). This avoids repeatedly reading and writing of inputs and outputs from and to HBM.\\n\\nAlgorithm 1 FLAsHATTENTION\\n\\nRequire: Matrices Q,K, V ¢ R“*¢ in HBM, on-chip SRAM of size M. 1: Set block sizes B. =[4], B, = min (41. d). 2: Initialize O = (0)vxa € RN*4, € = (0)w € RY, m = (-co)y € RN in HBM. 3: Divide Q into T, = [| blocks Qi,...,Qz, of size B, x d each, and divide K, V in to T, = [3] blocks K,,..., Ky, and Vj,..., Vz., of size B. x d each. 4: Divide O into T, blocks O;,...,O7, of size B, x d each, divide ¢ into T, blocks €,..., &, of size B- each, divide m into T, blocks m,,...,my, of size B, each. for 1 <j<T. do 6: Load Kj, V; from HBM to on-chip SRAM. 7 forl<i<T, do\\n\\non\\n\\n8: Load Q;, 0;, €;,m; from HBM to on-chip SRAM.\\n\\n9: On chip, compute $,; = QiK7 € RErxBe |\\n\\n10: On chip, compute mj; = rowmax(S;;) € R?, P;; = exp(Sij — mij) € R8*Fe (pointwise), bij = rowsum(P;;) eR.\\n\\n11: On chip, compute m?°” = max(mj;, mij) € R?, Epew = emt sme emir G5 eR.\\n\\n12: Write 0; — diag(£r\")\"! (diag(£)e™ \"0; + e-\"™\"\"B, -V;) to HBM.\\n\\n13: Write €; — €P°\", m; — m7?\" to HBM.\\n\\n14: end for 15: end for 16: Return O.\\n\\nWe show FLASHATTENTION’s correctness, runtime, and memory requirement (proof in Appendix\\n\\nTheorem 1. Algorithm{]] returns O = softmax(QK\")V with O(N?d) FLOPs and requires O(N) additional memory beyond inputs and output.\\n\\n3.2 Analysis: IO Complexity of FLASHATTENTION\\n\\nWe analyze the IO complexity of FLASHATTENTION, showing significant reduction in HBM accesses compared to standard attention. We also provide a lower bound, proving that no exact attention algorithm can\\n\\nThis style of aggregation is called algebraic aggregation [33].\\n\\nEffect of Block Size Sparsity Speedup\\n\\n= V6 = € Dense Attention _| Standard FLASHATTENTION. 3 4 655 1597 FlashAttention = a @ GFLOPs 66.6 75.2 é runtime 5 B10 —o HBM R/W (GB) 40.3 44 2244 5 + x os Runtime (ms) ALT 73 s |“ 22 ¥ 50 oo aS t F} iva = 64128 256 512 2 20 60 Block Size % Non-Zero Blocks\\n\\nFigure 2: Left: Forward + backward runtime of standard attention and FLASHATTENTION for GPT-2 medium (seq. length 1024, head dim. 64, 16 heads, batch size 64) on A100 GPU. HBM access is the primary factor affecting runtime. Middle: Forward runtime of FLASHATTENTION (seq. length 1024, head dim. 64, 16 heads, batch size 64) on A100 GPU. Fewer HBM accesses result in faster runtime, up to a point. Right: The runtime (for seq. length 4K) of block-sparse FLASHATTENTION is faster than FLASHATTENTION by a factor proportional to the sparsity.\\n\\nasymptotically improve on HBM accesses over all SRAM sizes. Proofs are in Appendix [C]\\n\\nTheorem 2. Let N be the sequence length, d be the head dimension, and M be size of SRAM withd < M < Nd. Standard attention (Algorithm|0) requires @(Nd +N?) HBM accesses, while FLASHATTENTION (Algorithm|1) requires @(N?d?M~-!) HBM accesses.', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='For typical values of d (64-128) and M (around 100KB), d? is many times smaller than M, and thus FLASHATTENTION requires many times fewer HBM accesses than standard implementation. This leads to both faster execution and lower memory footprint, which we validate in Section [£.3}\\n\\nThe main idea of the proof is that given the SRAM size of M, we can load blocks of K, V of size @(M) each (Algorithm []]line|6). For each block of K and V, we iterate over all blocks of Q (Algorithm [I] ]ine[8) to compute the intermediate values, resulting in @(NdM~\\') passes over Q. Each pass loads @(Nd) elements, which amounts to @(N?d?M~!) HBM accesses. We similarly prove that the backward pass of standard attention requires @(Nd + N?) HBM accesses while the backward pass of FLASHATTENTION requires @(N?d?M~!) HBM accesses (Appendix[B).\\n\\nWe prove a lower-bound: one cannot asymptotically improve on the number of HBM accesses for all values of M (the SRAM size) when computing exact attention.\\n\\nProposition 3. Let N be the sequence length, d be the head dimension, and M be size of SRAM with d<M<Nd. There does not exist an algorithm to compute exact attention with o(N?d?M~!) HBM accesses for all M in the range [d, Nd].\\n\\nThe proof relies on the fact that for M = @(Nd) any algorithm must perform Q(N?d?M7!) = Q(Nd) HBM accesses. This type of lower bound over a subrange of M is common in the streaming algorithms iterature [88]. We leave proving parameterized complexity [27] lower bounds in terms of M as exciting future work.\\n\\nWe validate that the number of HBM accesses is the main determining factor of attention run-time. n Fig. 2] (eft), we see that even though FLASHATTENTION has higher FLOP count compared to standard attention (due to recomputation in the backward pass), it has much fewer HBM accesses, resulting in much faster runtime. In Fig. |2|(middle), we vary the block size B. of FLASHATTENTION, which results in different amounts of HBM accesses, and measure the runtime of the forward pass. As block size increases, the number of HBM accesses decreases (as we make fewer passes over the input), and runtime decreases. For large enough block size (beyond 256), the runtime is then bottlenecked by other factors (e.g., arithmetic operations). Moreover, larger block size will not fit into the small SRAM size.\\n\\n3.3 Extension: Block-Sparse FLASHATTENTION\\n\\nWe extend FLASHATTENTION to approximate attention: we propose block-sparse FLASHATTENTION, whose IO complexity is smaller than FLASHATTENTION by a factor proportional to the sparsity. Given inputs Q,K, V ¢ R‘*4 and a mask matrix M € {0,1}%*\", we want to compute:\\n\\nS=QK™eR*\", P=softmax(SO 14) €RY*Y, O=PVeERN*4,\\n\\nwhere (S$ © 1y,)x1 = Sxi if My, = 1 and —co if My; = 0. We require M to have block form: for some block sizes B,, Be, for all k,l, Mx. = Mi; with i = |k/B,], j = |1/Be] for some M € {0, 1}/BrxN/Be,\\n\\nGiven a predefined block sparsity mask M ¢€ {0, 1}%/8r*N/8e we can easily adapt Algorithm [1] to only compute the nonzero blocks of the attention matrix. The algorithm is identical to Algorithm [I] except we skip zero blocks. We reproduce the algorithm description in Algorithm [5]in Appendix [B]\\n\\nWe also analyze the IO complexity of block-sparse FLASHATTENTION.\\n\\nProposition 4. Let N be the sequence length, d be the head dimension, and M be size of SRAM with d<M<Nd. Block-sparse FLASHATTENTION (Algorithm |[5) requires @(Nd + N?d?M~\\'s) HBM accesses where s is the fraction of nonzero blocks in the block-sparsity mask.\\n\\nWe see that applying block-sparsity yields a direct improvement by the sparsity to the larger term in the IO complexity. For large sequence lengths N, s is often set to N~!/? or N-! log N [92], resulting in @(NVN) or O(N log N) IO complexity. For downstream experiments, we use the fixed butterfly sparsity pattern [17], which has been shown to be able to approximate arbitrary sparsity [16]. i (right), we validate that as the sparsity increases, the runtime of block-sparse FLASHATTENTION improves proportionally. On the LRA benchmark, block-sparse FLASHATTENTION achieves 2.8x speedup, while performing on par with standard attention (Section [4).\\n\\n4 Experiments\\n\\nWe evaluate the impact of using FLASHATTENTION to train Transformer models. We validate two claims\\n\\nabout training time and model accuracy, and report attention runtime and memory benchmarks.\\n\\ne Training Speed. FLASHATTENTION outperforms the MLPerf 1.1 speed record for BERT by 15%, and speeds up GPT-2 up to 3x over HuggingFace [87] and 1.8x over Megatron [77] over standard Transformers. FLASHATTENTION speeds up the long-range arena (LRA) benchmark 2.4x.\\n\\ne Quality. FLASHATTENTION scales Transformers to longer sequences, yielding higher quality. FLASHAT- TENTION trains GPT-2 with context length 4K faster than Megatron trains GPT-2 with context length 1K, while achieving 0.7 better perplexity. Modeling longer sequences yields 6.4 points of lift on two long- document classification tasks. Finally, FLASHATTENTION yields the first Transformer that can achieve better-than-random performance on the challenging Path-X task (sequence length 16K), and block-sparse FLASHATTENTION yields the first sequence model that we know of that can achieve better-than-random performance on Path-256 (sequence length 64K).\\n\\ne Benchmarking Attention. We measure the runtime and memory performance of FLASHATTENTION and block-sparse FLASHATTENTION based on sequence length. We confirm that the memory footprint of FLASHATTENTION scales linearly with seq. length and is up to 3x faster than standard attention for common seq. lengths (up to 2K). We confirm that runtime of block-sparse FLASHATTENTION scales linearly in seq. length and is faster than all existing approximate attention baselines.\\n\\nAdditional experiment details are in Appendix |[E]\\n\\n4.1 Faster Models with FLASHATTENTION\\n\\nBERT. FLASHATTENTION yields the fastest single-node BERT training speed that we know of. We train a BERT-large [22] model with FLASHATTENTION on Wikipedia. Table[i] compares our training time to the implementation from Nvidia that set the training speed record for MLPerf 1.1 [58]. Our implementation is 15% faster.\\n\\nTable 1: Training time of BERT-large, starting from the same initialization provided by the MLPerf benchmark, to reach the target accuracy of 72.0% on masked language modeling. Averaged over 10 runs on 8xA100 GPUs.\\n\\nBERT Implementation | Training time (minutes) Nvidia MLPerf 1.1 20.0 41.5 FLASHATTENTION (ours) 17.4414\\n\\nGPT-2. FLASHATTENTION yields faster training times for GPT-2 [67] on the large OpenWebtext dataset [32] than the widely used HuggingFace and Megatron-LM [77] implementations. Table] shows up to 3x end- to-end speedup compared to Huggingface and 1.7x speedup compared to Megatron-LM. FLASHATTENTION\\n\\nachieves the same perplexity as the other two implementations, as we do not change the model definition. Appendix|E] ncludes plots of the validation perplexity throughout training, confirming that FLASHATTENTION is as numerically stable as the baselines and produces the same training / validation curves.\\n\\nTable 2: GPT-2 small and medium using FLASHATTENTION achieve up to 3x speed up compared to Huggingface implementation and up to 1.7x compared to Megatron-LM. Training time reported on 8xA100s GPUs.\\n\\nModel implementations OpenWebText (ppl) Training time (speedup) GPT-2 small - Huggingface 18.2 9.5 days (1.0x) GPT-2 small - Megatron-LM [77] 18.2 4.7 days (2.0x) GPT-2 small - FLASHATTENTION 18.2 2.7 days (3.5x) GPT-2 medium - Huggingface [87] 14.2 21.0 days (1.0x) GPT-2 medium - Megatron-LM [77] 14.3 11.5 days (1.8x) GPT-2 medium - FLASHATTENTION 14.3 6.9 days (3.0x)\\n\\nLong-range Arena. We compare vanilla Transformer (with either standard implementation or FLASHAT- TENTION) on the long-range arena (LRA [80]) benchmark. We measure accuracy, throughput, and training time of all models. Each task has a different sequence length varying between 1024 and 4096. We follow the implementation and experimental setting in Tay et al. [80Jand Xiong et al. pol] Table|3}shows that FLASHAT- TENTION achieves up 2.4x speed-up compared to standard attention. Block-sparse FLASHATTENTION is faster than all of the approximate attention methods that we have tested.\\n\\nTable 3: The performance of standard attention, FLASHATTENTION, block-sparse FLASHATTENTION, and approximate attention baselines on the Long-Range-Arena benchmarks.\\n\\nModels ListOps Text Retrieval Image Pathfinder | Avg | Speedup\\n\\nTransformer 36.0 63.6 81.6 42.3 72.7 59.3 -\\n\\nFLASHATTENTION 37.6 63.9 81.4 43.5 72.7 59.8 2.4x\\n\\nBlock-sparse FLASHATTENTION 37.0 63.0 81.3 43.6 73.3 59.6 2.8x\\n\\nLinformer [84] 35.6 55.9 77.7 37.8 67.6 54.9 2.5x\\n\\nLinear Attention 38.8 63.2 80.7 42.6 72.5 59.6 2.3x\\n\\nPerformer [12] 36.8 63.6 82.2 42.1 69.9 58.9 1.8x\\n\\nLocal Attention [80] 36.1 60.2 76.7 40.6 66.6 56.0 1.7x\\n\\nReformer 36.5 63.8 78.5 39.6 69.4 57.6 1.3x\\n\\nSmyrf [19] 36.1 64.1 79.0 39.6 70.5 57.9 1.7x\\n\\n4.2 Better Models with Longer Sequences\\n\\nLanguage Modeling with Long Context. The runtime and memory-efficiency of FLASHATTENTION allow us to increase the context length of GPT-2 by 4x while still running faster than the optimized implementation from Megatron-LM. Table [4] shows that that GPT-2 with FLASHATTENTION and context length 4K is still 30% faster than GPT-2 from Megatron with context length 1K, while achieving 0.7 better perplexity.\\n\\nTable 4: GPT-2 small with FLASHATTENTION, with 4x larger context length compared to Megatron-LM, is still 30% faster while achieving 0.7 better perplexity. Training time on 8xA100 GPUs is reported.\\n\\nModel implementations | Context length OpenWebText (ppl) Training time (speedup) GPT-2 small - Megatron-LM 1 18.2 4.7 days (1.0x) GPT-2 small - FLASHATTENTION 1 18.2 2.7 days (1.7x) GPT-2 small - FLASHATTENTION 2 17.6 3.0 days (1.6x) GPT-2 small - FLASHATTENTION 4 17.5 3.6 days (1.3x)', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='Long Document Classification. Training Transformers with longer sequences with FLASHATTENTION improves performance on the MIMIC-III [47] and ECtHR [6] [7] datasets. MIMIC-III contains intensive care unit patient discharge summaries, each annotated with multiple labels. ECtHR contains legal cases from the\\n\\n3LRA accuracy results are known to be highly dependent on the tuning procedure {90}. Our reproduced baselines perform better than as reported in the original comparison [80].\\n\\nAttention Runtime (Fwd Pass + Bwd Pass) Attention Memory Usage\\n\\na 10? 2 Z Crossover Points z 20 = Q 2 3° £ 2 10 2 > 20x 2 8 & G 128 256 512 1024 2048 4096 8192 = 256 8K 16K 32K 64K Sequence Length Sequence Length = *=** FlashAttention === PyTorch Attention === Linformer Attention = mmm Block-Sparse FlashAttention Megatron Attention === = OpenAl Sparse Attention\\n\\nFigure 3: Left: runtime of forward pass + backward pass. Right: attention memory usage.\\n\\nEuropean Court of Human Rights, each of which is mapped to articles of the Convention of Human Rights that were allegedly violaged. Both of these datasets contain very long text documents; the average number of tokens in MIMIC is 2,395 tokens, and the longest document contains 14,562 tokens, while the average and longest numbers in ECtHR are 2,197 and 49,392, respectively. We evaluate lift from increasing the sequence length of a pretrained RoBERTa model [56] (we repeat the positional embeddings, as in Beltagy et al. [3]). Table [5] shows that sequence length 16K outperforms length 512 by 4.3 points on MIMIC, and that length\\n\\n8K outperforms length 512 by 8.5 points on ECtHR. The discrepancies may be due to subtle distribution shifts: MIMIC-II contains specialized medical text and thus may be more susceptible to a distribution shift in the document length, whereas ECtHR contains general language.\\n\\nTable 6: We report the first Transformer\\n\\nmodel that can achieve non-random perfor-\\n\\nmance on Path-X and Path-256.\\n\\nTable 5: Long Document performance (mi- cro F) at different sequence lengths using\\n\\nPath-X__ Path-256 FLASHATTENTION. x x x x\\n\\n512 10242048 4096819216384 en riormer Th x x\\n\\nMIMICIN G7] [52.8 50.7 517 546 564 57.1 Local Attenti x x ECtHR [6] | 72.2 74.3 77.1 78.6 80.7 79.2 cat Miter x x\\n\\nx x\\n\\nSHATTENTION 61.4 x\\n\\nBlock-sparse FLASHATTENTION | 56.0 63.1\\n\\nPath-X and Path-256. The Path-X and Path-256 benchmarks are challenging tasks from the long-range arena benchmark designed to test long context. The task is to classify whether two points in a black and white 128x128 (or 256x256) image have a path connecting them, and the images are fed to the transformer one pixel at a time. In prior work, all transformer models have either run out of memory, or only achieved random performance [80]. There has been a search for alternative architectures that can model such long context [37]. We present here the first result of Transformer models being able to solve Path-X and Path-256 (Table [6). We pretrain a transformer on Path-64, and then transfer to Path-X by spatially interpolating the positional embeddings. FLASHATTENTION achieves 61.4 accuracy on Path-X. Additionally, block-sparse FLASHATTENTION enables the Transformers to scale to sequence length 64K, achieving 63.1 accuracy] on Path-256.\\n\\n4.3 Benchmarking Attention\\n\\nWe vary sequence length and measure runtime and memory usage of FLASHATTENTION and block-sparse FLASHATTENTION against various attention baselines on one A100 GPU with 40 GB HBM, with dropout and a padding mask. We compare against reference implementations for exact attention, approximate attention, and sparse attention. We report a subset of baselines in the main body; Appendix [E] contains more baselines and full details.\\n\\n4Path-256 requires longer sequences but has relatively shorter paths than Path-X, so it is easier to obtain a higher accuracy.\\n\\nRuntime. Figure [3] (left) reports the runtime in milliseconds of the forward + backward pass of FLASHAT- TENTION and block-sparse FLASHATTENTION compared to the baselines in exact, approximate, and sparse attention (exact numbers in Appendix |E}. Runtime grows quadratically with sequence length, but FLASHAT- TENTION runs significantly faster than exact attention baselines, up to 3x faster than the PyTorch implementation. The runtimes of many approximate/sparse attention mechanisms grow linearly with se- quence length, but FLASHATTENTION still runs faster than approximate and sparse attention for short sequences due to fewer memory accesses. The approximate attention runtimes begin to cross over with FLASHATTENTION at sequences between 512 and 1024. On the other hand, block-sparse FLASHATTENTION is faster than all implementations of exact, sparse, and approximate attention that we know of, across all sequence lengths.\\n\\nMemory Footprint. Figure [3] (right) shows the memory footprint of FLASHATTENTION and block-sparse FLASHATTENTION compared to various exact, approximate, and sparse attention baselines. FLASHATTENTION and block-sparse FLASHATTENTION have the same memory footprint, which grows linearly with sequence length. FLASHATTENTION is up to 20x more memory efficient than exact attention baselines, and is more memory-efficient than the approximate attention baselines. All other algorithms except for Linformer run out of memory on an A100 GPU before 64K, and FLASHATTENTION is still 2x more efficient than Linformer.\\n\\n5 Limitations and Future Directions\\n\\nWe discuss limitations of our approach and future directions. Related work is given in Appendix [A]\\n\\nCompiling to CUDA. Our current approach to building IO-aware implementations of attention requires writing a new CUDA kernel for each new attention implementation. This requires writing the attention algorithm in a considerably lower-level language than PyTorch, and requires significant engineering effort. Implementations may also not be transferrable across GPU architectures. These limitations suggest the need for a method that supports writing attention algorithms in a high-level language (e.g., PyTorch), and compiling to IO-aware implementations in CUDA—-similar to efforts such as Halide in image processing [70].\\n\\nIO-Aware Deep Learning. We believe that the IO-aware approach can extend beyond attention. Attention is the most memory-intensive computation in Transformers, but every layer in a deep network touches GPU HBM. We hope our work inspires IO-aware implementations of additional modules. We discuss these potential extensions in Appendix [D]\\n\\nMulti-GPU IO-Aware Methods. Our IO-aware implementation of attention is optimal within con- stants for computing attention on a single GPU. However, the attention computation may be parallelizable across multiple GPUs [72]. Using multiple GPUs adds an additional layer to IO analysis—accounting for data transfer between GPUs. We hope our work inspires future work in this direction.\\n\\nAcknowledgments\\n\\nOur implementation uses Apex’s FMHA code (https: //github.com/NVIDIA/apex/tree/master/apex/\\n\\nas a starting point. We thank Young-Jun Ko for the in-depth explanation of his FMHA implementation and for his thoughtful answers to our questions about CUDA. We thank Sabri Eyuboglu, Megan Leszczynski, Laurel Orr, Yuhuai Wu, Beidi Chen, and Xun Huang for their constructive feedback and suggestions on early drafts of the paper. We thank Markus Rabe and Charles Staats for helpful discussion of their attention algorithm.\\n\\nWe gratefully acknowledge the support of NIH under No. U54EB020405 (Mobilize), NSF under Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), and 1937301 (RTML); ARL under No, W911NF-21-2-0251 (Interactive Human-AI Teaming); ONR under No. N000141712266 (Unifying Weak Supervision); ONR N00014-20-1-2480: Understanding and Applying Non-Euclidean Geometry in Machine Learning; N000142012275 (NEPTUNE); NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, Google Cloud, Salesforce, Total, the HAI-GCP & HAI-Azure Cloud Credits for Research program, the Stanford Data Science Initiative (SDSI), Department of Defense (DoD) through the National Defense Science and Engineering Graduate Fellowship (NDSEG) Program, and members of the Stanford DAWN project: Facebook, Google, and VMWare. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes\\n\\n10\\n\\nnotwithstanding any copyright notation thereon. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of NIH, ONR, or the U.S. Government. Atri Rudra’s research is supported by NSF grant CCF-1763481.\\n\\nReferences\\n\\n1\\n\\n10\\n\\n11\\n\\n12\\n\\n13\\n\\n14\\n\\nAlok Aggarwal and § Vitter, Jeffrey. The input/output complexity of sorting and related problems. Communications of the ACM, 31(9):1116-1127, 1988.\\n\\nIrwan Bello. LambdaNetworks: Modeling long-range interactions without attention. arXiv preprint ar Xiv:2102.08602, 2021.\\n\\nIz Beltagy, Matthew E Peters, and Arman Cohan. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150, 2020.\\n\\nL Susan Blackford, Antoine Petitet, Roldan Pozo, Karin Remington, R Clint Whaley, James Demmel, Jack Dongarra, Iain Duff, Sven Hammarling, Greg Henry, et al. An updated set of basic linear algebra subprograms (blas). ACM Transactions on Mathematical Software, 28(2):135-151, 2002.\\n\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='Tlias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. Neural legal judgment prediction in English. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4317-4323, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1424.\\n\\nURL |https://www.aclweb.org/anthology/P19- 1424\\n\\nIlias Chalkidis, Manos Fergadiotis, Dimitrios Tsarapatsanis, Nikolaos Aletras, Jon Androutsopoulos, and Prodromos Malakasiotis. Paragraph-level rationale extraction through regularization: A case study on european court of human rights cases. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics, Mexico City, Mexico, 2021. Association for Computational Linguistics.\\n\\nBenjamin Charlier, Jean Feydy, Joan Alexis Glaunés, Frangois-David Collin, and Ghislain Durif. Kernel operations on the gpu, with autodiff, without memory overflows. Journal of Machine Learning Research, 22(74):1-6, 2021. URL |http://jmlr. org/papers/v22/20-275.html\\n\\nBeidi Chen, Tri Dao, Eric Winsor, Zhao Song, Atri Rudra, and Christopher Ré. Scatterbrain: Unifying sparse and low-rank attention. In Advances in Neural Information Processing Systems (NeurIPS), 2021.\\n\\nTianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear memory cost. arXiv preprint arXiv:1604.06174, 2016.\\n\\nRewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. Generating long sequences with sparse transformers. arXiv preprint arXiv:1904.10509, 2019.\\n\\nKrzysztof Marcin Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Quincy Davis, Afroz Mohiuddin, Lukasz Kaiser, et al. Rethinking attention with performers. In International Conference on Learning Representations (ICLR), 2020.\\n\\nXiang Dai, Ilias Chalkidis, Sune Darkner, and Desmond Elliott. Revisiting transformer-based models for long document classification. arXiv preprint arXiv:2204.06683, 2022.\\n\\nZihang Dai, Zhilin Yang, Yiming Yang, Jaime G Carbonell, Quoc Le, and Ruslan Salakhutdinov. Transformer-XL: Attentive language models beyond a fixed-length context. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2978-2988, 2019.\\n\\n11\\n\\n15\\n\\n16\\n\\n17\\n\\n18\\n\\n19\\n\\n20\\n\\n21\\n\\n22\\n\\n23\\n\\n24\\n\\n25\\n\\n26\\n\\n27 28\\n\\n29\\n\\n30\\n\\n31\\n\\n32\\n\\nTri Dao, Albert Gu, Matthew Eichhorn, Atri Rudra, and Christopher Ré. Learning fast algorithms for linear transforms using butterfly factorizations. In International Conference on Machine Learning\\n\\n(ICML), 2019.\\n\\nTri Dao, Nimit Sohoni, Albert Gu, Matthew Eichhorn, Amit Blonder, Megan Leszczynski, Atri Rudra, and Christopher Ré. Kaleidoscope: An efficient, learnable representation for all structured linear maps. In International Conference on Learning Representations (ICLR), 2020.\\n\\nTri Dao, Beidi Chen, Kaizhao Liang, Jiaming Yang, Zhao Song, Atri Rudra, and Christopher Ré. Pixelated butterfly: Simple and efficient sparse training for neural network models. In International Conference on Learning Representations (ICLR), 2022.\\n\\nTri Dao, Beidi Chen, Nimit Sohoni, Arjun Desai, Michael Poli, Jessica Grogan, Alexander Liu, Aniruddh Rao, Atri Rudra, and Christopher Ré. Monarch: Expressive structured matrices for efficient and accurate training. In International Conference on Machine Learning (ICML), 2022.\\n\\nGiannis Daras, Nikita Kitaev, Augustus Odena, and Alexandros G Dimakis. Smyrf-efficient attention using asymmetric clustering. Advances in Neural Information Processing Systems, 33:6476-6489, 2020.\\n\\nChristopher De Sa, Albert Gu, Rohan Puttagunta, Christopher Ré, and Atri Rudra. A two-pronged progress in structured dense matrix vector multiplication. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1060-1079. SIAM, 2018.\\n\\nPeter J Denning. The working set model for program behavior. Communications of the ACM, 11(5): 323-333, 1968. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep\\n\\nbidirectional transformers for language understanding. 2019.\\n\\nXin Dong, Shangyu Chen, and Sinno Jialin Pan. Learning to prune deep neural networks via layer-wise optimal brain surgeon. arXiv preprint arXiv:1705.07565, 2017.\\n\\nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2020.\\n\\nY Eidelman and I Gohberg. On a new class of structured matrices. Integral Equations and Operator\\n\\nTheory, 34(3):293-324, 1999.\\n\\nJean Feydy, Joan Glaunés, Benjamin Charlier, and Michael Bronstein. Fast geometric learning with symbolic matrices. Advances in Neural Information Processing Systems, 33, 2020.\\n\\nJérg Flum and Martin Grohe. Parameterized Complexity Theory. Springer, 2006.\\n\\nJonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. In International Conference on Learning Representations, 2018.\\n\\nJonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.\\n\\nJonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, and Michael Carbin. Linear mode connectivity and the lottery ticket hypothesis. In International Conference on Machine Learning, pages 3259-3269. PMLR, 2020.\\n\\nKaran Goel, Albert Gu, Chris Donahue, and Christopher Ré. It’s raw! audio generation with state-space models. In International Conference on Machine Learning (ICML), 2022.\\n\\nAaron Gokaslan, Vanya Cohen, Pavlick Ellie, and Stefanie Tellex. Openwebtext corpus, 2019.\\n\\n12\\n\\n33\\n\\n34\\n\\n35\\n\\n36\\n\\n37\\n\\n38\\n\\n39\\n\\n50\\n\\nJim Gray, Surajit Chaudhuri, Adam Bosworth, Andrew Layman, Don Reichart, Murali Venkatrao, Frank Pellow, and Hamid Pirahesh. Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals. Data mining and knowledge discovery, 1(1):29-53, 1997.\\n\\nAndreas Griewank and Andrea Walther. Evaluating derivatives: principles and techniques of algorithmic differentiation. SIAM, 2008.\\n\\nAlbert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher Ré. Hippo: Recurrent memory with optimal polynomial projections. In Advances in neural information processing systems (NeurIPS), 2020.\\n\\nAlbert Gu, Isys Johnson, Karan Goel, Khaled Saab, Tri Dao, Atri Rudra, and Christopher Ré. Combining recurrent, convolutional, and continuous-time models with linear state space layers. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nAlbert Gu, Karan Goel, and Christopher Ré. Efficiently modeling long sequences with structured state spaces. In The International Conference on Learning Representations (ICLR), 2022.\\n\\nSong Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural networks. arXiv preprint arXiv:1506.02626, 2015.\\n\\nSong Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In International Conference on Learning Representations, 2016.\\n\\nJohn Hennessy and David Patterson. Memory hierarchy design. Computer Architecture: A Quantitative Approach, pages 390-525, 2003.\\n\\nSara Hooker. The hardware lottery. arXiv preprint arXiv:2009.06489, 2020.\\n\\nWeizhe Hua, Zihang Dai, Hanxiao Liu, and Quoc V Le. Transformer quality in linear time. arXiv preprint arXiv:2202.10447, 2022.\\n\\nAndrei Ivanov, Nikoli Dryden, Tal Ben-Nun, Shigang Li, and Torsten Hoefler. Data movement is all you need: A case study on optimizing transformers. Proceedings of Machine Learning and Systems, 3:\\n\\n711-732, 2021.\\n\\nZhe Jia and Peter Van Sandt. Dissecting the Ampere GPU architecture via microbenchmarking. GPU Technology Conference, 2021.\\n\\nZhe Jia, Marco Maggioni, Benjamin Staiger, and Daniele P Scarpazza. Dissecting the nvidia Volta GPU architecture via microbenchmarking. arXiv preprint arXiv:1804.06826, 2018.\\n\\nZhe Jia, Blake Tillman, Marco Maggioni, and Daniele Paolo Scarpazza. Dissecting the graphcore IPU architecture via microbenchmarking. arXiv preprint arXiv:1912.03418, 2019.\\n\\nAlistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3(1):1-9, 2016.\\n\\nNorman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. In-datacenter performance analysis of a tensor processing unit. In Proceedings of the 44th annual international symposium on computer architecture, pages 1-12, 2017.\\n\\nThomas Kailath, Sun-Yuan Kung, and Martin Morf. Displacement ranks of matrices and linear equations. Journal of Mathematical Analysis and Applications, 68(2):395-407, 1979.\\n\\nAngelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Francois Fleuret. Transformers are RNNs: Fast autoregressive transformers with linear attention. In International Conference on Machine Learning, pages 5156-5165. PMLR, 2020.\\n\\n51\\n\\n52\\n\\n53\\n\\n54\\n\\n55\\n\\n56\\n\\n57\\n\\n58\\n\\n59\\n\\n60\\n\\n61 62 63 64\\n\\n65\\n\\n66\\n\\n67\\n\\n68\\n\\n69\\n\\nNikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. In The International Conference on Machine Learning (ICML), 2020.\\n\\nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. Albert: A lite BEDRT for self-supervised learning of language representations. In The International Conference on Learning Representations (ICLR), 2020.\\n\\nMingzhen Li, Yi Liu, Xiaoyan Liu, Qingxiao Sun, Xin You, Hailong Yang, Zhongzhi Luan, Lin Gan, Guangwen Yang, and Depei Qian. The deep learning compiler: A comprehensive survey. [EEE Transactions on Parallel and Distributed Systems, 32(3):708-727, 2020.', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='Valerii Likhosherstov, Krzysztof Choromanski, Jared Davis, Xingyou Song, and Adrian Weller. Sub-linear memory: How to make performers slim. arXiv preprint arXiv:2012. 11346, 2020.\\n\\nJi Lin, Yongming Rao, Jiwen Lu, and Jie Zhou. Runtime neural pruning. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.\\n\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Dangi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\\n\\nXuezhe Ma, Xiang Kong, Sinong Wang, Chunting Zhou, Jonathan May, Hao Ma, and Luke Zettlemoyer. Luna: Linear unified nested attention. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nPeter Mattson, Christine Cheng, Gregory Diamos, Cody Coleman, Paulius Micikevicius, David Patterson, Hanlin Tang, Gu-Yeon Wei, Peter Bailis, Victor Bittorf, et al. Mlperf training benchmark. Proceedings of Machine Learning and Systems, 2:336-349, 2020.\\n\\nFrank McSherry, Michael Isard, and Derek G Murray. Scalability! but at what {COST}? In 15th Workshop on Hot Topics in Operating Systems (HotOS XV), 2015.\\n\\nMaxim Milakov and Natalia Gimelshein. Online normalizer calculation for softmax. arXiv preprint arXiv:1805.02867, 2018.\\n\\nNVIDIA. Nvidia Tesla V100 GPU architecture, 2017. NVIDIA. Nvidia A100 tensor core GPU architecture, 2020.\\n\\nNVIDIA. Nvidia H100 tensor core GPU architecture, 2022.\\n\\nD Stott Parker. Random butterfly transformations with applications in computational linear algebra.\\n\\n1995.\\n\\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high- performance deep learning library. Advances in neural information processing systems, 32, 2019.\\n\\nMarkus N Rabe and Charles Staats. Self-attention does not need O(n?) memory. arXiv preprint arXiv:2112.05682, 2021.\\n\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\\n\\nJack Rae and Ali Razavi. Do transformers need deep long-range memory? In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online, July 2020. Association for\\n\\nComputational Linguistics. URL https: //www.aclweb.org/anthology/2020.acl-main.672\\n\\nJack W Rae, Anna Potapenko, Siddhant M Jayakumar, and Timothy P Lillicrap. Compressive trans- formers for long-range sequence modelling. In The International Conference on Learning Representations\\n\\n(ICLR), 2020.\\n\\n14\\n\\n70\\n\\n71\\n\\n72\\n\\n73\\n\\n74\\n\\n75. 76\\n\\n77\\n\\n78\\n\\n79\\n\\n80\\n\\n81\\n\\n82\\n\\n83\\n\\n84\\n\\n85.\\n\\n86\\n\\nJonathan Ragan-Kelley, Connelly Barnes, Andrew Adams, Sylvain Paris, Frédo Durand, and Saman Amarasinghe. Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines. Acm Sigplan Notices, 48(6):519-530, 2013.\\n\\nRaghu Ramakrishnan, Johannes Gehrke, and Johannes Gehrke. Database management systems, volume 3. McGraw-Hill New York, 2003.\\n\\nBenjamin Recht and Christopher Ré. Parallel stochastic gradient algorithms for large-scale matrix completion. Mathematical Programming Computation, 5(2):201-226, 2013.\\n\\nHongyu Ren, Hanjun Dai, Zihang Dai, Mengjiao Yang, Jure Leskovec, Dale Schuurmans, and Bo Dai. Combiner: Full attention transformer with sparse computation cost. Advances in Neural Information Processing Systems, 34, 2021.\\n\\nAurko Roy, Mohammad Saffar, Ashish Vaswani, and David Grangier. Efficient content-based sparse attention with routing transformers. Transactions of the Association for Computational Linguistics, 9: 53-68, 2021.\\n\\nAmit Sabne. XLA: Compiling machine learning for peak performance. 2020.\\n\\nVictor Sanh, Thomas Wolf, and Alexander M Rush. Movement pruning: Adaptive sparsity by fine-tuning. arXiv preprint arXiv:2005.07683, 2020.\\n\\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-LM: Training multi-billion parameter language models using model parallelism. arXiv preprint\\n\\nar Xiv:1909.08058, 2019.\\n\\nVikas Sindhwani, Tara Sainath, and Sanjiv Kumar. Structured transforms for small-footprint deep learning. In Advances in Neural Information Processing Systems, pages 3088-3096, 2015.\\n\\nSainbayar Sukhbaatar, Edouard Grave, Piotr Bojanowski, and Armand Joulin. Adaptive attention span in transformers. In Proceedings of the Annual Meeting of the Association for Computational Linguistics,\\n\\n2019.\\n\\nYi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, and Donald Metzler. Long range arena: A benchmark for efficient transformers. In International Conference on Learning Representations, 2020.\\n\\nYi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. Efficient transformers: A survey. arXiv preprint arXiv:2009.06782, 2020.\\n\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\\n\\nHongyu Wang, Shuming Ma, Li Dong, Shaohan Huang, Dongdong Zhang, and Furu Wei. Deepnet: Scaling transformers to 1,000 layers. arXiv preprint arXiv:2203.00555, 2022.\\n\\nSinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768, 2020.\\n\\nSamuel Williams, Andrew Waterman, and David Patterson. Roofline: an insightful visual performance model for multicore architectures. Communications of the ACM, 52(4):65-76, 2009.\\n\\nMichael E Wolf and Monica S Lam. A data locality optimizing algorithm. In Proceedings of the ACM SIGPLAN 1991 conference on Programming language design and implementation, pages 30-44, 1991.\\n\\n[87] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric\\n\\n88\\n\\n89\\n\\n90\\n\\n91\\n\\n92\\n\\n93\\n\\n94\\n\\nCistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online, October 2020. Association for Computational Linguistics. URL\\n\\nhttps: //www.aclweb.org/anthology/2020.emnlp-demos .6\\n\\nDavid P Woodruff. Optimal space lower bounds for all frequency moments. In SODA, volume 4, pages 167-175. Citeseer, 2004.\\n\\nFelix Wu, Angela Fan, Alexei Baevski, Yann N Dauphin, and Michael Auli. Pay less attention with lightweight and dynamic convolutions. In The International Conference on Learning Representations\\n\\n(ICLR), 2019.\\n\\nYunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, and Vikas Singh. Nystrémformer: A nyst6ém-based algorithm for approximating self-attention. In Proceedings of the AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence, volume 35, page 14138, 2021.\\n\\nLi Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zi-Hang Jiang, Francis EH Tay, Jiashi Feng, and Shuicheng Yan. Tokens-to-token vit: Training vision transformers from scratch on imagenet. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 558-567, 2021.\\n\\nManzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et al. Big bird: Transformers for longer sequences. Advances in Neural Information Processing Systems, 33, 2020.\\n\\nShuangfei Zhai, Walter Talbott, Nitish Srivastava, Chen Huang, Hanlin Goh, Ruixiang Zhang, and Josh Susskind. An attention free transformer. arXiv preprint arXiv:2105.14103, 2021.\\n\\nChen Zhu, Wei Ping, Chaowei Xiao, Mohammad Shoeybi, Tom Goldstein, Anima Anandkumar, and Bryan Catanzaro. Long-short transformer: Efficient transformers for language and vision. Advances in Neural Information Processing Systems, 34, 2021.\\n\\n16\\n\\nA Related Work\\n\\nIO-Aware Runtime Optimization. The broad concept of optimizing for reading and writing to fast /slow memory has a long history in computer science and has been known by many names. We draw the most direct connection to the literature of analyzing I/O complexity in this work [I], but concepts of memory hierarchies are fundamental and has appeared in many forms, from the working set model [2]], to data locality [86], to the Roofline model of arithmetic intensity [85], to analyses of scalability [59], to standard textbook treatments of computer architecture [40]. We hope that this work encourages the community to adopt these ideas in more parts of the deep learning stack.\\n\\nEfficient ML Models with Structured Matrices. Matrix multiply is the core computational bottle- neck of most machine learning models. To reduce the computational complexity, there have been numerous approaches to learn over a more efficient set of matrices. These matrices are called structured matrices, which have subquadratic (o(n?) for dimension n x n) number of parameters and runtime. Most common examples of structured matrices are sparse and low-rank matrices, along with fast transforms commonly encountered', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='in signal processing (Fourier, Chebyshev, sine/cosine, orthogonal polynomials). There have been several more general classes of structured matrices proposed in machine learning: Toeplitz-like [78], low-displacement rank [49], quasi-separable [25]). The butterfly pattern we use for our block-sparse attention is motivated by the fact that butterfly matrices (64] and their products have been shown to be able to express any structured matrices with almost optimal runtime and number of parameters [20]. However, even though structured matrices are efficient in theory, they have not seen wide adoption since it is hard to translate their efficiency to wall-clock speedup since dense unconstrained matrix multiply has very optimize implementation, a phenomenon known as the hardware lottery [I]. Extensions of butterfly matrices [17] [18] aimed to make butterfly matrices more hardware-friendly.\\n\\nSparse Training. Our block-sparse FLASHATTENTION can be seen as a step towards making sparse model training more efficient. Sparse models have seen success in compressing models for inference (pruning) by sparsifying the weight matrices [23] [38] [39] 55] [76]. For model training, the lottery tickets hypothesis [28] [29] [30] suggests that there are a set of small sub-networks derived from a larger dense network that performs as well as the original dense network. Out block-sparse FLASHATTENTION can also be seen as a fixed lottery ticket in the context of attention: we fix the sparsity pattern to be the butterfly pattern through training, and observe that it performs almost as well as the (dense) FLASHATTENTION on the Long-range Arena tasks.\\n\\nEfficient Transformer. Transformer-based models have become the most widely-used architecture in natural language processing [22] and computer vision [24]|91]. However, one of their computational bottlenecks is that their time and memory scales quadratic in the sequence length. There are numerous approaches to overcome this bottleneck, including approximation with hashing (i.e., sparse) such as Reformer an Smyrf [19] and with low-rank approximation such as Performer [54]. One can even combine sparse and low-rank approximation for better accuracy (e.g., Longformer [3], BigBird [92], Scatterbrain [9], Long-shor transformer [94], Combiner [73]). Other approaches include compressing along the sequence dimension to attend to multiple tokens at once [571 [79] [89]. One can also attend over the states from previous sequences to help lengthen the context (e.g., Transformer-XL and Compressive Transformer [69}). We recommen the survey for more details.\\n\\nThere are several lines of work on developing other modules instead of attention to model longer context. HiPPO [35] and its extensions, most notably S4 [BT] [36] [37] projects the history on a polynomial basis, allowing accurate reconstruction of the history through state-space models. They combine the strengths o! CNNs (efficient training), RNNs (efficient inference), and continuous models (robust to change in sampling rates). LambdaNetworks [2], AFT and FLASH [42] are other attempts at replacing attention in the context of image classification and language modeling.\\n\\nB_ Algorithm Details\\n\\nWe first derive the forward and backward passes of attention and show that they can be computed in a memory-efficient manner (requiring extra memory linear instead of quadratic in the sequence length). Though they reduce the amount of extra memory required, naively they still incur quadratic HBM accesses, resulting in slower execution speed. We describe the FLASHATTENTION algorithm to implement both the forward\\n\\n17\\n\\nand the backward passes on GPUs that reduces HBM accesses, leading to both faster runtime and smaller memory footprint.\\n\\nB.1 Memory-efficient forward pass\\n\\nThe main challenge in making attention memory-efficient is the softmax that couples the columns of K (and columns of V). Our approach is to compute the softmax normalization constant separately to decouple the columns. This technique has been used in the literature to show that attention computation does not need quadratic extra memory (though the number of HBM accesses is still quadratic, resulting in slow run-time).\\n\\nFor simplicity, we omit here the max-shifting step during softmax. The full algorithm in Appendix [B.3] contains all the steps.\\n\\nRecall that given input sequences Q, K, V €\\n\\nRN*4, we want to compute the attention output O € RN*4:\\n\\nS=QK™« RX\", P =softmax(S) eRY*, O=PVeERN*4, We have that S;; = qe kj; where q; and k; are the i-th and j-th columns of Q and K respectively. Define the normalization constants of softmax: , Li = yiet ky (1) Jj Let v; be the j-th column of V, then the i-th columns of the output is ed ki\\n\\nLj\\n\\n04 = PV =D\" Pijvj = Vj. (2)\\n\\nJ J\\n\\nWe see that once L; is computed, we can compute 0; without extra memory by repeatedly summing\\n\\net Kj Li\\n\\nv;. Therefore the forward pass can be computed with O(n) extra memory:\\n\\n1. Compute L; for all i according to Eq. (i).\\n\\nwhich takes O(n) extra memory.\\n\\n2. Compute 0; for all i according to Eq. Q. which takes O(d) extra memory.\\n\\nB.2. Memory-efficient backward pass\\n\\nWe derive the backward pass of attention and show that it can also be computed with linear memory. Rabe and Staats [66] suggests that the backward pass can be done without quadratic extra memory by applying gradient checkpointing to the memory-efficient forward pass. We instead derive the backward pass explicitly and show how it can be computed in a memory-efficient manner.\\n\\nSuppose that there is a scalar loss function ¢, and let the output gradient be dO € R\"*¢ (where dO denotes a6). We want to compute the input gradients dQ,dK,dV € Rd (where dQ, dK, dV denote 3. oe a6 respectively).\\n\\nThe gradient dV is easy to see. Applying reverse-mode autodiff by hand (aka the chain rule), we obtain (in matrix notation) dV = P7 dO. Thus:\\n\\nT edi ki\\n\\ndv; = >) Pijdoi =>) L doj. (3) i\\n\\n7 i i\\n\\nSince we already computed L;, dv; can be computed without extra memory by repeated summing. The gradients dQ and dK are a little more complicated. We go through the gradients dP and dS first. From Eq. (2), we have that dP = dOV’, and so: dP jj = do} Vj.\\n\\nRecall that P;. = softmax(S;;). Using the fact that the Jacobian of y = softmax(x) is diag(y) — yy’, we have that dS; = (diag(P;.) — Pi-P{,)dP;. = Pi. 0 dP). -— (P/.dP;.)Pi-,\\n\\n18\\n\\nwhere o denotes pointwise multiplication.\\n\\nDefine + q5 kj qk; Dj = PhaP;, = Y\\\\ dof vj = dof Y) v; = do} oi, (4) Jj \\' Jj then dS;, = P;, © dP;, — D;Pi:. Hence\\n\\ndS;; = PijdPij — DjPij = Pij(dPij — Di). Now we can get the gradients dQ and dK. Recall that S;; = gq) kj, so\\n\\nedi kj\\n\\ndq; =) dSijkj =D\" Pij(dPij — Dik; = (dol vy ~ Didky. (5)\\n\\nJ J io”\\n\\nSimilarly,\\n\\nT edi Ki . dk; = 48i;4i = >) Pig aP i; - Didi = » L (do} v; — Di)qi- (6)\\n\\ni i t\\n\\nTherefore the backward pass can also be computed with O(n) extra memory: 1. Compute dv; for all j according to Eq. (3). which takes O(d) extra memory. 2. Compute D; for all i according to Eq. (4. which takes O(n) extra memory. 3. Compute dq; for all i according to Eq. (5). which takes O(d) extra memory. 4. Compute dk; for all j according to Eq. (6), which takes O(d) extra memory.\\n\\nB.3. FLASHATTENTION: Forward Pass\\n\\nWe describe the full details of FLASHATTENTION forward pass. Given input sequences Q, K, V € R“*¢, we want to compute the attention output O ¢ RN*4:\\n\\nS= TQK\" € RN*N gmasked = MASK(S) € RN*N | P= softmax(S™*skedy € RN*N\\n\\nPropped = dropout(P, parop), O = PUPPY ¢ RNxd\\n\\nwhere tT € R is some softmax scaling (typically Ta MASK is some masking function that sets some entries of the input to —co and keep other entries the same (e.g., key padding mask when sequences in the batch don’t have the same lengths and are padded), and dropout(x, p) applies dropout to x elementwise (i.e., output cart with probability 1 -— p and output 0 with probability p for each element x).\\n\\nThe full algorithm is in Algorithm [} We save the output O, the softmax statistics and m, and the pseudo-random number generator state R for the backward pass.\\n\\n19\\n\\nAlgorithm 2 FLASHATTENTION Forward Pass\\n\\nRequire: Matrices Q,K,V ¢ R‘*“ in HBM, on-chip SRAM of size M, softmax scaling constant Tt € R, masking function MASK, dropout probability parop-\\n\\n1: Initialize the pseudo-random number generator state R and save to HBM.\\n\\n2: Set block sizes B. = [4] ,B, = min (4) ,d).\\n\\n3: Initialize O = (0) xa € RN*4,€ = (0)y € RY, m = (-c)y € RN in HBM.\\n\\n4: Divide Q into T, = [| blocks Qi,...,Qz, of size B, x d each, and divide K, V in to T, = [| blocks K,,..., Ky, and Vj,..., Vz., of size B. x d each. Divide O into T,. blocks O;,..., Oz, of size B, x d each, divide ¢ into T, blocks ¢;,...,€r, of size B, each, divide m into T, blocks m,..., mr, of size B; each. 6: for 1 <j <T. do 7: Load K;,V; from HBM to on-chip SRAM.\\n\\non\\n\\n8: forl<i<T, do\\n\\n9: Load Q;, 0;, €;,m; from HBM to on-chip SRAM.\\n\\n10: On chip, compute $;; = TQiKT € RB xBe |\\n\\n11: On chip, compute Spyasked = MASK(S;;). -\\n\\n12: On chip, compute mj; = rowmax(S?/*5**) eR’, Py = exp(Sprasked — mj) € Rr*Be (pointwise), bij = rowsum(P;;) € Re,\\n\\n13: On chip, compute m?°Y = max(m;, fijj) € RB, rev = eM E+ emir C5 E RBr,\\n\\n14: On chip, compute Pyyopped = dropout(Pj;, Parop)-\\n\\n15: Write 0; — diag(¢2\")-1(diag(é;)e™—\"™ 0; + em—mP™ PPP) to HIBM.\\n\\n16: Write €; — €P°\", m; — m7?\" to HBM.\\n\\n17: end for\\n\\n18: end for\\n\\n19: Return O,¢,m,R.\\n\\nB.4. FLASHATTENTION: Backward Pass\\n\\nWe describe the full details of FLASHATTENTION backward pass. Given input sequences Q, K, V € R*4, the output O € RN*4, and the output gradient dO, we want to compute the input gradients dQ, dK,dV € RY*¢. We first describe the standard attention backward pass in Algorithm [3] for completeness.\\n\\nAlgorithm 3 Standard Attention Backward Pass', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='Algorithm 3 Standard Attention Backward Pass\\n\\nRequire: Matrices Q,K, V,dO ¢ RY*4, Pe RY*\" in HBM. 1: Load P, dO by blocks from HBM, compute dV = P™dO € R™4, write dV to HBM. : Load dO, V by blocks from HBM, compute dP = dOV™ € R“*\", write dP to HBM. : Read P, dP from HBM, compute dS « RY*\" where dS;; = Pij(dPij — DX) PidPi1), write dS to HBM. : Load dS and K by blocks from HBM, compute dQ = dSK, write dQ to HBM. : Load dS and Q by blocks from HBM, compute dK = dS\"Q, write dK to HBM. 6: Return dQ, dK, dV.\\n\\nae ww\\n\\nWe now make two observations about FLASHATTENTION backward pass:\\n\\n1. We do not need to store the dropout mask of size O(N?) from the forward pass. Instead, we can save the pseudo-random number generator states from the forward pass and re-generate the dropout mask in the backward pass. This allows us to only use O(N) extra memory.\\n\\n2. When computing the softmax gradient, we use Eq. (4p to compute D; = P/dP;, without reducing over P;, and dP;, of size N (they might not fit into SRAM). Instead we can rewrite D; = do; 0; and compute the dot product between vectors of size d.\\n\\n20\\n\\nThe full FLASHATTENTION backward pass algorithm is in Algorithm [4] Conceptually it is just a block version of the derivation in Appendix [B.2]\\n\\nAlgorithm 4 FLASHATTENTION Backward Pass\\n\\nRequire: Matrices Q,K, V,0,dO ¢ R‘*¢ in HBM, vectors €,m € RY in HBM, on-chip SRAM of size M, softmax scaling constant t € R, masking function MASK, dropout probability parop, pseudo-random number generator state R from the forward pass.\\n\\n1: Set the pseudo-random number generator state to R.\\n\\n2: Set block sizes B. = [4] ,B, = min (4) ,d).\\n\\n3: Divide Q into T, = [| blocks Q;,...,Qz, of size B, x d each, and divide K, V in to T, = [| blocks\\n\\nK,,..., Ky, and Vj,..., Vz., of size B. x d each.\\n\\n4: Divide O into T, blocks O;,...,O7, of size B, x d each, divide dO into T, blocks dOj;,...,dOz, of size B, x d each, divide € into T, blocks €,...,€r, of size B, each, divide m into T, blocks m,..., mr, of size B, each.\\n\\nInitialize dQ = (0)vxa in HBM and divide it into T, blocks dQ,,..., dQ;, of size B, x d each. Initialize\\n\\ndK = (0)vxa,dV = (0)vx@ in HBM and divide dK, dV in to T, blocks dKj,...,dKr, and dVj,...,dVz.,\\n\\nof size B, x d each.\\n\\n6: for 1 <j <T. do\\n\\n7: Load Kj, V; from HBM to on-chip SRAM.\\n\\n8: Initialize dK; = (0)g.xa,dVj = (0)a.xa on SRAM.\\n\\n9: forl<i<T, do\\n\\non\\n\\n10: Load Q;, 0;,d0;, dQ,, ¢;, m; from HBM to on-chip SRAM.\\n\\n11: On chip, compute $,; = TQ:KT € RB xBe |\\n\\n12: On chip, compute Spyasked = MASK(S;;).\\n\\n13: On chip, compute P;; = diag(J;)~! exp(Spasked — mj) € RBr*Be,\\n\\n14: On chip, compute dropout mask Z;; € R\\'r*Be where each entry has value = with probability 1— Parop and value 0 with probability parop.\\n\\n15: On chip, compute Pyyopped = Pj; ° Z;; (pointwise multiply).\\n\\n16: On chip, compute av; <—dV;+ (Perr) TO; € RBexd |\\n\\n17: On chip, compute apyyopred = d0;V; € RBrxBe |\\n\\n18: On chip, compute dP;; = dPsrorped o Z;; (pointwise multiply).\\n\\n19: On chip, compute D; = rowsum(dO; 0 0;) € R3\".\\n\\n20: On chip, compute d§,;; = Pi; 0 (dP;; — Di) € RErxBe |\\n\\n21: Write dQ; — dQ; + 7d8,;;K; ¢ R84 to HBM.\\n\\n22: On chip, compute dK; — aK; +7d$/;Q; € RBexd,\\n\\n23: end for\\n\\n24: Write dK; — dK,,dV; — dV, to HBM. 25: end for\\n\\n26: Return dQ, dK, dV.\\n\\nWe see that similar to the forward pass, the backward pass performs O(N?) FLOPs and only requires O(N) extra memory beyond inputs, output, output gradient, and input gradients. We analyze the IO-complexity of the backward pass, similar to the forward pass (Theorem |2).\\n\\nTheorem 5. Let N be the sequence length, d be the head dimension, and M be size of SRAM withd < M < Nd. Standard attention (Algorithm|[d) backward pass requires @(Nd +N?) HBM accesses, while FLASHATTENTION backward pass (Algorithm|4| requires @(N2d?M~\\') HBM accesses.\\n\\nThe proof is in Appendix [C]\\n\\n21\\n\\nB.5 Comparison with Rabe and Staats\\n\\nWe describe here some similarities and differences between our FLASHATTENTION algorithm and the algorithm of Rabe and Staats [66].\\n\\nConceptually, both FLASHATTENTION and Rabe and Staats operate on blocks of the attention matrix using the well-established technique of tiling (or softmax scaling) [51] [60]. To reduce the memory footprint, both methods avoid storing the large attention matrix in the forward pass and recompute it in the backwar pass.\\n\\nThe first major difference is that Rabe and Staats focuses on the reducing the total memory footprint (maximum amount of GPU memory required) while FLASHATTENTION focuses on reducing memory accesses (the number of memory reads/writes). As mentioned in Section [2] the amount of memory access is the primary determining factor of runtime. Reducing memory accesses also necessarily reduces the total amoun of memory required (e.g., if an operation incurs A memory accesses, then its total memory requirement is a‘ most A). As a result, FLASHATTENTION is faster than standard attention (2-4x) while Rabe and Staats is around the same speed or slightly slower than standard attention. In terms of total memory required, both methods offer substantial memory saving. The second difference between the two methods is the way information is summarized from each block to pass to the next block. Rabe and Staats summarizes each block with its temporary output along with the softmax normalization statistics. At the end of the forward pass, the temporary outputs of all the blocks are combined using the statistics to produce the final output. FLASHATTENTION instead incrementally updates the output (Algorithm [1] ine after processing each block, so only one copy of the output is needed (instead of K copies for K blocks). This means that FLASHATTENTION has smaller total memory requirement compared to Rabe and Staats [66]. The final major difference is the way the backward pass is computed. Rabe and Staats uses gradient checkpointing to recompute the attention matrix and the temporary output of each block. FLASHATTENTION instead simplifies the backward pass analytically (Appendices ). It only recomputes the attention matrix and does not recompute the temporary output of each block. This reduces the memory requirement for the backward pass and yields speedup.\\n\\nC_ Proofs\\n\\nProof of Theorem [I] We first count the number of FLOPs and extra memory required. The dominating FLOPs are from matrix multiplication. In the inner loop, (Algorithm [1] line >). we compute Q.K; € R3*Be for Q; € R84 and K;¢€ Rex4 which takes O(B,B.d) FLOPs. We also compute\\n\\n(Algorithm fil ine [12) P/V; € R3rX4 for P;; € RB*Be and Vie R8ex4_ which takes O(B,B-d) FLOPs. We execute the inner loops TT; = [4] [#] times. Therefore the total number of FLOPs is\\n\\nBe\\n\\n(6) N* B,Bed| = O(N? d) BoB. or eet] = : In terms of extra memory required, we see that we need O(N) memory to store the statistics (€,m).\\n\\nWe now prove the algorithm’s correctness by induction on j for 0 < j < T,. Let K,j € R/Bex4 be the first 7B. rows of K, and similarly V.; € R/8ex4 the the first 7B. rows of V. Let Sj = QK’, € RN*/Be. and P...; =softmax(S,..;) € RN*/8e (softmax applied row-wise). Let m/, £2),0% be the values of m,€,O in HBM after the j-th iteration of the outer loop (Algorithm [I] line 5}. (Note that these values of m, €,O are updated after each iteration of the outer loop.) We want to show that after the j-th iteration of the outer loop, we have computed in HBM:\\n\\nmD = rowmax(S, .;) € RY, (W= rowsum(exp(S, .; — m)))eRX, OW = PL Vij € RN™¢,\\n\\nBased on our initialization (Algorithm [I] line , this claim is true for j = 0 (ie., before the any iteration of the outer loop is executed). Suppose that the claim holds for some j = 0,...,T-— 1. We want to show that the claim also holds for j + 1. Indeed, when we update the statistics in the inner loop (Algorithm [I] line [I0}\\n\\n22\\n\\non the (j +1)-th iteration of the outer loop, we update m/*) = max(m),m) where m € R™ is the row-max of S. j.j41, the slice of S from column jB, to column (j +1)B, — 1. This implies that\\n\\nmF) = rowmax(S. :j41) € RN.\\n\\nSimilarly, we update\\n\\nj. DomUtD a7 m—mItD 5 CUED = gin mI) Oi) g. git) &\\n\\nwhere f = rowsum(exp(S, j:j41 —m)) € RY. By the same algebraic manipulation in Section [3.1| we obtain:\\n\\ncay = rowsum/(exp(S;,.j41 — mU*))) eR. Let Vj:j+1 be the slice of V from column jB, to column (j + 1)B, — 1, we also update: OND = diag(e4*9) 1 diag(e em\" OW + eM exp (Sj. j41 — Hi) Vjjs) = diag (UP) “\"(diag(e ye\" PR. V, EM” exp(S)j41)V jet) = diag(€4*Y) \"(diag Mer” diag(€) exp(S.,.j — mV. +e™ = iag(LItD) He) exp(S,,.;)V.j + emg exp($j.j41) Vj.j+1)\\n\\n= diag(€V*))“!(exp(S,,.j — mY*Y)V.; + exp(Sj.j41 — mY) Vj. j41)\\n\\n= iag(et))- (exp ([8.2j Sj.j41] -mi))| V3) |\\n\\nVisju1\\n\\n(i+\\n\\n’ exp(Sj.j+1) Vj.j41)\\n\\n= softmax(S. j+1) V:j+1-\\n\\nWe then see that the claim is also true for j + 1. By induction, the claim is true for all j =0,...,T7.. When j =T7,, we conclude that the final value of O in HBM is softmax(S)V = softmax(QK\")V. Oo\\n\\nProof of Theorem [A We first analyze the IO complexity of standard attention implementation. The inputs Q.K, V ¢ R\\\\*¢ reside in HBM, and the at the end of the algorithm the output O € RY” is written to HBM.\\n\\nIn the first step of computing the matrix multiply § = QK\", the inputs Q,K are read from HBM and the output S « RX* is written to HBM (Algorithm [0] line[Ip. This incurs @(Nd + N?) HBM accesses.\\n\\nIn the second step of computing P = softmax(S), the input S is read from HBM and the output P is written to HBM (Algorit hm [0] line [2). This incurs @(N?) HBM accesses.\\n\\nIn the last step of computing O = PV, the inputs P, V are read from global memory and the output O is written to HBM (Algorit hm [0] line [3p. This incurs @(Nd + N?) HBM accesses.\\n\\nOverall, standard attention implementation requires @(Nd + N?) global memory accesses.\\n\\nWe now analyze the IO complexity of streaming attention.', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='We now analyze the IO complexity of streaming attention.\\n\\nFollowing Algorithm [I] we see that each element of K and V is loaded from HBM once (alborithe line |6). We make T, passes over Q and O, each pass loading all of Q and all of O to HBM (Algorithm line|8). Therefore the number of HBM accesses is © (Nd + NdT,) = O(NdT.).\\n\\nWe derive the conditions on the block sizes B. and B,. We need the blocks K; and V; of size B, x d to fit into on-chip memory, which translates to:\\n\\nB-d = O(M) oa.-0(\").\\n\\nSimilarly, we need the blocks Q;, 0; of size B, x d to fit into on-chip memory, which translates to:\\n\\nB,d = O(M) © B, -o(4).\\n\\nFinally, we need the block §;; of size B, x B, to fit into on-chip memory, which translates to:\\n\\nB,B. = O(M).\\n\\n23\\n\\nWe therefore set:\\n\\nWe then have: “pol\\n\\nAs a result, the number of HBM accesses is: N?d? ©(NdT,) =® (“Sr ] . oO\\n\\nProof of Proposition [3 For contradiction, suppose that there exists an algorithm that computes exact attention where the number for HBM access for all M € [d, Nd] is\\n\\nN?d? oO . (\"r]\\n\\nIn the regime of M = ©(Na), this results in the number of HBM accesses:\\n\\nN?d? “|\\n\\nWd =o0(Nd).\\n\\nHowever, the input to attention (matrices Q,K,V) and the output O have size Nd and they start out being in HBM, so if the algorithm computes exact attention it must incur at least Q(Nd) HBM accesses. This is a contradiction. oO Proof of Theorem [5} The IO complexity of the attention backward is very similar to the IO complexity of he attention forward (Theorem [2). Here we provide a sketch of the proof.\\n\\nWe first analyze the IO complexity of standard attention backward pass. The inputs Q,K, V,dO € RY*¢ reside in HBM, and the at the end of the algorithm the outputs dQ, dK, dV ¢ R‘™¢ are written to HBM. At each step of the standard attention backward pass, one needs to load inputs of size Nd or N? from HBM, and needs to write the outputs of size N? or Nd to HBM. This incurs @(Nd + N?) HBM accesses. We now analyze the IO complexity of FLASHATTENTION backward pass.\\n\\nSimilar to Theorem [2] we see that each element of K and V is loaded from HBM once. Each element of dK and dV is only written to HBM once. We make T, passes over Q, O, dO, each pass loading all of Q,O,dO o HBM. We also make T, passes over dQ, each pass reading/writing all of dQ from/to HBM. Therefore the number of HBM accesses is © (Nd + NdT,) = @(NdT-).\\n\\nAs in the proof of Theorem [2] the constraints on the block sizes are that:\\n\\nN Be\\n\\nAs a result, the number of HBM accesses is:\\n\\nWe then have:\\n\\n“|\\n\\n0 (NadT,) = 9 rj\\n\\n24\\n\\nAlgorithm 5 Block-Sparse FLASHATTENTION Forward Pass\\n\\nRequire: Matrices Q,K,V ¢ R‘*“ in HBM, on-chip SRAM of size M, softmax scaling constant Tt € R, masking function MASK, dropout probability Parop, block sizes B. = [4]. 8, = min ([44],d), block sparsity mask M € {0, 1}N/8rxN/Be\\n\\n1: Initialize the pseudo-random number generator state R and save to HBM.\\n\\n2: Initialize O = (0)vxa € RN*4, € = (0)w € RY, m = (-co)y € RN in HBM.\\n\\n3: Divide Q into T, = [| blocks Q;,...,Qz, of size B, x d each, and divide K, V in to T, = [| blocks\\n\\nK,,..., Ky, and Vj,..., Vz., of size B. x d each.\\n\\n4: Divide O into T, blocks O;,...,O7, of size B, x d each, divide ¢ into T, blocks €;,...,¢p, of size B, each,\\n\\ndivide m into T, blocks m,..., mr, of size B; each.\\n\\nfor 1 <j<T. do\\n\\n6: Load Kj, V; from HBM to on-chip SRAM.\\n\\non\\n\\n7 forl<i<T, do\\n\\n8: if M;; #0 then\\n\\n9: Load Q;, 0;, €;,m; from HBM to on-chip SRAM.\\n\\n10: On chip, compute $;; = TQiK € RB xBe |\\n\\n11: On chip, compute Spasked = MASK(S;;).\\n\\n12: On chip, compute mj; = rowmax(Sjvke) eR, Pi = exp(Spasked — mij) € R3r*Be (pointwise), bj = rowsum(P;;) € Re,\\n\\n13: On chip, compute m?°Y = max(mj,1ii;;) € RB\", rev = em, eH Es, E RBr,\\n\\n14: On chip, compute Pyyopped = dropout(Pj;, Parop)-\\n\\n15: Write O; — diag(¢?”) “1 (diag(E)e™-\"\"” O; + e™/ mp peoppedyy ;) to HBM.\\n\\n16: Write € — €?°\", m; — m?*” to HBM.\\n\\n17: end if\\n\\n1s: end for\\n\\n19: end for\\n\\n20: Return O, ¢,m,R.\\n\\nD_ Extension Details\\n\\nD.1 + Block-sparse FLASHATTENTION\\n\\nWe describe the full block-sparse FLASHATTENTION algorithm in Algorithm [5] The algorithm is identical to Algorithm 2] except that we skip zero blocks. We prove the IO-complexity of block-sparse FLASHATTENTION.\\n\\nProof of Proposition [4} The proof is very similar to the proof of Theorem [2] For the block-sparse case, notice that we only need to load blocks corresponding to nonzero blocks. As a result, the number of HBM accesses are scaled by s, the fraction of nonzero blocks in the block-sparsity mask. However, for small values of s, we would still need to write the result O ¢ RN*¢. Therefore the number of HBM accesses is\\n\\nN?d?\\n\\no(va+\\n\\nD.2 Potential Extensions\\n\\nWe discuss here a few potential extensions of the IO-aware approach to speed up deep learning training. Multi-GPU Attention. Large language models are trained on hundreds or thousands of GPUs, and\\n\\none typically splits the attention computation between 4-8 GPUs on the same node [77]. This introduces\\n\\nanother level of memory hierarchy: beside GPU SRAM and GPU HBM, we also have the HBM of other\\n\\nGPUs. For very long sequences, the different GPUs on the same node can cooperate to compute attention by aking into account the asymmetry of different levels of memory hierarchy.\\n\\nSparse MLP layers. Typical dense MLP layers are compute-bound and not memory-bound. To improve\\n\\nheir efficiency, MLP layers with sparse weight matrices can be used [17]. However, many sparse MLP layers are instead memory-bound, and their speedup is often not proportional to the sparsity. We believe that an O-aware implementation can alleviate this issue and realize the benefits of sparsity. We are excited about ‘uture work in this direction, to reduce the computational requirement of large models and improve their wall-block runtime. Kernel machine learning. Our approach in FLASHATTENTION relies on the fact that the N x N attention matrix is a function of a low-rank matrix QK™ (of rank d « N). As a result, we can repeatedly oad the inputs Q,K and recompute the block of the attention matrix that we need, significantly reducing HBM access. As similar scenario happens in kernel machine learning: each element Kj; of the N x N kernel matrix K is a function of two vectors of size d < N, as it measures the similarity between two datapoints x; and x;. The KeOps library [8] [26] is a successful example of how reducing memory reads/writes can speed up kernel operations. We hope that this will motivate kernel methods that focus more on reducing IOs instead of just FLOPs.\\n\\nE Full Experimental Results\\n\\nE.1 BERT\\n\\nWe train BERT-large following the training procedure and hyperparameters of the reference MLPerf 1.1 implementation. In particular, we use the LAMB optimizer with learning rate 3.75e-3, with batch size 448, trained for at most 7100 steps. The training is stopped once the validation accuracy (for masked language modeling) reaches the target 72.0%, and the wall-clock run-time is measured. We train with FP16 precision using Apex AMP (with O2 optimization level).\\n\\nWe compare our results with the reported training speed from Nvidia that was submitted to MLPerf 1.1 (Table {i}.\\n\\nWe use the same train / validation data split provided by MLPerf 1.1 reference implementation. In particular, we evaluate on the same 10000 validation examples as the baseline from Nvidia.\\n\\nWe train the model on 8xA100-80GB GPUs. Each training run takes between 16 and 19 minutes, and we average the results of 10 runs.\\n\\nE.2. GPT-2\\n\\nWe use the standard implementations of GPT-2 [67] from Huggingface transformers library and from Nvidia’s Megatron-LM repo. We follow the training recipe of the Megatron-LM repo.\\n\\nWe use an effective batch size of 512, and use gradient accumulation to fit into available GPU memory. We use the AdamW optimizer, with learning rate 6e-4 for GPT-2 small and 1.5e-4 for GPT-2 medium, and weight decay of 0.1. All models are trained with the same hyperparameters for 400K steps. We run all implementations with mixed-precision training (PyTorch AMP).\\n\\nWe use the Openwebtext dataset, with the GPT-2 BPE tokenizer. We randomly select 0.5% of the dataset as the validation set, with the rest being used as training set. This random selection of validation set is done once, and all models are evaluated on the same validation set.\\n\\nWe train the model on 8xA100-40GB GPUs, and we measure the wall-clock training time. Training GPT-2 small takes between 2.7-9.5 days, and training GPT-2 medium takes between 6.9-21.0 days (Table [2).\\n\\n. 41 we plot of the validation perplexity throughout training of GPT-2 small/medium, using either HuggingFace implementation or our FLASHATTENTION implementation. We see that FLASHATTENTION be- haves the same as the baseline implementation and the validation perplexity curves of the two implementations almost lie on top of each other.\\n\\nLong Document Classification. For MIMIC-III and ECtHR, we follow the hyperparameters of Dai et al.\\n\\n[13].\\n\\n26\\n\\n30 —— GPT-2-small HuggingFace —— GPT-2-small FlashAttention 25 4 — GPT-2-medium HuggingFace > —— GPT-2-medium FlashAttention € Lv 2 204 © Qa w > 15 4 10\\n\\n: : : 100k 200k 300k Training steps\\n\\nFigure 4: Validation perplexity of GPT-2 small/medium using two implementations. We confirm that FLASHATTENTION yields the same validation curves as the baseline implementation from HuggingFace.\\n\\nE.3. LRA details\\n\\nWe follow the hyperparameters from the Long-range arena paper [80], the Long-range arena repo (h //github .com/google-research/long-range-arena), and the Nystrémformer reproduction [90]. To be generous to the baseline methods, if we are unable to reproduce the performance of any baseline for any of the five tasks, we report the better performance from Tay et al. or Xiong et al. [90] for that baseline on that task.\\n\\nAfter hyperparameter tuning, almost all of the attention methods achieve similar accuracy on all of the five LRA tasks.', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='We run all methods with mixed-precision training, except for Performer (not stable with mixed precision) and Local Attention (implementation does not support FP16).\\n\\nTo calculate the overall wallclock-time speedup, we take the geometric mean of the wallclock-time speedup of each of the five tasks.\\n\\nPath-X For Path-X and Path-256, we follow the hyperparameters from the PathFinder-32 experiments from the long-range arena paper{80]. For both, we first pretrain a model on Path-64. We take the checkpoint after 200 epochs, upsample its positional embedding (we duplicate the positional embeddings gridwise in space), and fine-tune it on the downstream task for 200 epochs with one epoch of linear warmup, and cosine decay of the learning rate. For Path-X, we take the best performing checkpoint (according to val accuracy), and additionally fine-tune it for 200 epochs with the same warmup and learning rate (this adds roughly 4 points of accuracy to FLASHATTENTION for Path-X, but the model starts overfitting afterwards).\\n\\nE.4 Comparison with Apex FMHA\\n\\nWe compare our method/implementation with Apex FMHA (https: //github.com/NVIDIA/apex/tree/ master/apex/contrib/csrc/fmha).\\n\\nWhen we started this project, Apex FMHA was the fastest implementation of attention (that we knew of), tailored for short sequences of length at most 512. In fact, almost all MLPerf submissions for BERT training benchmark running on Nvidia GPUs use FMHA for their model code, as of MLPerf 1.1 [58]. Since\\n\\n27\\n\\nTable 7: Runtime (ms) of FLASHATTENTION compared to FMHA by sequence length, with masking and dropout, measured on an A100-SXM4-40GB GPU. Batch size 64, 16 heads, head dimension 64 (i.e., BERT-large size).\\n\\nAttention Method | 128 256 512\\n\\nApex FMHA forward | 0.10 0.29 1.14 FLASHATTENTION forward | 0.08 0.22 0.81\\n\\nApex FMHA backward | 0.17 0.52 1.81 FLASHATTENTION backward | 0.20 0.53 2.00\\n\\nApex FMHA forward + backward | 0.27 0.81 = 2.95 FLASHATTENTION forward + backward | 0.28 0.75 2.81\\n\\nFMHA targets BERT models, it only supports head dimension 64, and only runs on A100 GPUs. FMHA ‘uses the attention computation dropout(softmax(MASK(QK\")))V into one CUDA kernel. In the forward ass, it stores the attention matrix softmax(MASk(QK’ )) to HBM to be used in gradient computation. As a result, it does not offer substantial memory saving (though for shorter sequences memory footprint is often not a primary concern).\\n\\nWe use FMHA code as a starting point, and apply two well-established techniques (tiling and recomputa- ion) to deal with long sequences and to save memory as mentioned in Section |3| As a result, we can support much longer sequences (e.g., up to length 64K). We also support more head dimensions (16, 32, 64, 128) and roader GPU types (all Turing and Ampere GPUs at the time of writing).\\n\\nIn Table [7] we compare the performance of FLASHATTENTION and Apex FMHA for short sequences (as FMHA only supports sequence length at most 512). Generally FLASHATTENTION is slightly faster than F MHA in the forward pass and slightly slower than FMHA in the backward pass. This is because we do not store the attention matrix in the forward pass and recompute it in the backward pass. Compared to FMHA, he overall runtime of FLASHATTENTION is about 4% slower for sequence length 128, 8% faster for sequence length 256, and 5% faster for sequence length 512.\\n\\nE.5 Speedup On Different Hardware and Configurations\\n\\nSpeedup varies between different types of GPU types and generations depending on HBM bandwidth and SRAM size. In this section, we profile FLASHATTENTION speedup on different GPUs and configurations.\\n\\nFlashAttention Speedup, A100\\n\\n@@—™ Dropout + Masking lm Masking Only lm No Masking, No Dropout 0) I I 128 256 512\\n\\n1024 2048 4096 Sequence Length\\n\\nBy L\\n\\nWw 1\\n\\nSpeedup (X times faster) BR N\\n\\nFigure 5: Speedup over standard PyTorch attention at different sequence lengths, on A100.\\n\\nA100 Figure [5]shows speedup on an A100 GPU with batch size 8, head dimension 64, and 12 attention heads, across different sequence lengths. We generally see 2-4x speedup, and we see more speedup when using dropout and masking due to kernel fusion.\\n\\n28\\n\\nFlashAttention Speedup, A100, d=128\\n\\n@mm™ Dropout + Padding Masking @@m_ Padding Masking Only\\n\\nCausal Mask | | | | @@—™_ No Masking, No Dropout\\n\\n1024 2048 * sequence Length\\n\\n3.04\\n\\n2.57\\n\\n2.05\\n\\n154\\n\\n1.0 4\\n\\nSpeedup (X times faster)\\n\\n0.54\\n\\n0.0\\n\\nFigure 6: Speedup over standard PyTorch attention at different sequence lengths, on A100, with head dimension 128.\\n\\nA100, Head Dimension 128 Speedup also changes when we increase the head dimension. Each block requires more memory, so we need to use smaller block sizes to fit into SRAM. Figure |6]shows speedup with head dimension 128 on an A100 (batch size 16, 12 heads). We see less speedup overall—but we can still see significant speedup (up to 3x) with a causal mask, where half the blocks are masked out.\\n\\nFlashAttention Speedup, GTX 3090\\n\\n@@—™ Dropout + Masking\\n\\n44 @ Masking Only @mm_ No Masking, No Dropout 3 4 24 14 i¢}\\n\\n1024 2048 oe eequence Length\\n\\nSpeedup (X times faster)\\n\\nFigure 7: Speedup over standard PyTorch attention at different sequence lengths, on RTX 3090.\\n\\nRTX 3090 Figure [7] shows speedup on an RTX 3090 GPU. Here, we use batch size 12 with 12 attention heads. We observe slightly higher speedups on the RTX 3090 (between 2.5-4.5x), since the memory bandwidth on an RTX 3090 is lower than on an A100 (roughly 900 GB/s vs. 1.5 TB/s).\\n\\nT4 Figure [8] shows speedup on a T4 GPU. T4 SRAM is smaller than A100, so we need to make the block sizes smaller in FLASHATTENTION. As a result, we observe less speedup on T4, which matches the IO complexity analysis in Section 3.2] T4 GPUs are commonly used for inference, so we also report speedup on the forward pass only.\\n\\n29\\n\\nFlashAttention Speedup, T4\\n\\n354 l@@—™_ Dropout + Masking g @m_ Masking Only £ 3.04 l@amm_ No Masking, No Dropout G3 2.54 iS 6 2.04 iad e154 3 © 1.04 oO Q 0.54 0.0\\n\\n1024 2048 ees Length\\n\\nFlashAttention Speedup, T4 (Forward Only)\\n\\n@@—™ Dropout + Masking\\n\\n44 @ Masking Only @mm_ No Masking, No Dropout 3 4 24 14 i¢}\\n\\n1024 2048 oe eequence Length\\n\\nSpeedup (X times faster)\\n\\nFigure 8: Speedup over standard PyTorch attention at different sequence lengths, on T4. Top: Combined forward pass + backward pass. Bottom: Forward pass only.\\n\\nE.6 Full Benchmarking Results\\n\\nWe report the full benchmarking results and experimental details on A100.\\n\\nBaselines We compare against reference implementations for exact attention from PyTorch/HuggingFace and Megatron, approximate attention, and sparse attention. For approximate attention, we compare against reference implementations of Reformer [51], Local Attention [68], Linformer Attention [84], Smyrf [19], and LongShortFormer (LSFormer) [94]. For sparse attention, we compare against reference implementations of Block-Sparse Attention form OpenAI [II], Longformer|3], and BigBird Attention [92]. For the approximate and sparse attention, we use a compression ratio of 1/8, or a compressed sequence length of 256, whichever is smaller.\\n\\nSetup We measure runtime and memory usage of the attention computation with 8 heads of dimension 64, and batch size 16 on a machine with one A100 GPU with 40 GB of GPU HBM. We vary sequence length in our experiments. We compute attention on random vectors for Q, K, and V (we do not measure the projection from the hidden layer). For dropout, we use dropout 0.1; for masking, we use a padding mask with uniformly-random mask lengths between the total sequence length and the total sequence length minus 20. To measure runtime, we take the average of 100 measurements of the attention call. We only measure memory footprint once, since it does not vary between runs.\\n\\n30\\n\\nTable 8: Pointers to results tables.\\n\\nDropout Masking Pass Table Yes Yes Forward Table |9 Yes Yes Backwar Table |10 Yes Yes Combined Table [IT\\n\\nfe) Yes Forward Table [12 fe) Yes Backwar Table fe) Yes Combined Table Yes No Forward Table [15 Yes No Backwar Table [16 Yes No Combined Table fe) No Forward Table fe) No Backwar Table oO No Combined Table [20 oO No Memory Usage (Combined) | Table |2T\\n\\nTable 9: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout and masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.36 0.34 0.78 2.54 9.33 36.33 - - - - Megatron 0.40 0.40 1.10 3.65 16.19 - - - - - Reformer 2.03 3.15 5.67 11.02 22.59 46.14 97.38 212.13 - - Local Attention 0.83 0.86 1.01 2.20 7.13 14,32 28.60 57.79 117.67 - Linformer 0.67 0.52 0.69 0.71 1.65 3.18 6.15 12.16 24.17 52.39 Smyrf 2.27 2.34 3.91 7.44 14.71 29.22 58.27 116.41 - - LSformer 1.18 1.27 1.34 3.38 11.40 22.55 44.95 89.76 179.66 - Block Sparse 1.12 1.11 2.13 2.77 6.95 20.91 - - - - Longformer 1.22 1.14 1.08 1.95 5.72 12.98 - - - - BigBird 1.13 1.12 1.12 1.77 6.03 13.68 - - - - FLASHATTENTION 0.04 0.06 0.21, 0.82 2.85 10.41 41.74 167.19 670.76 2682.35 Block-Sparse FLASHATTENTION 0.06 0.06 0.06 0.12 0.44 0.86 1.70 3.29 6.55 13.34\\n\\nWe report timing results on the forward pass, backward pass, and combined forward\\n\\nbackward pass.\\n\\nWe measure each method with and without dropout, masking, or both—except for Block Sparse, Longformer, and BigBird. These methods did not successfully run the backward pass with masking due to a bug in external libraries, so we measured them without masking to be generous. We use FP16 for all measurements, except for Local Attention, whose implementation only supports FP32.\\n\\nFor each baseline, we increase sequence length until it runs out of memory on the GPU, except for the following exceptions: The Megatron implementation does not support sequence lengths longer than 2048. Block-Sparse (OpenAI) does not support sequence lengths longer than 4096. Longformer and BigBird do not', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='support sequence lengths longer than 8092. We measure memory usage on the combined forward + backward pass, without dropout or masking.\\n\\nResults Table\\n\\n31\\n\\nsummarizes all the experimental configurations and contains pointers to the results tables.\\n\\nTable 10: Backward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout and masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.37 0.49 1.66 5.81 22.32 87.67 - - - -\\n\\nMegatron 0.35 0.32 0.77 2.42\\n\\nReformer 2.37 4.59 8.91 17.68\\n\\nLocal Attention 0.55 0.62 1.49 4.03\\n\\nLinformer 0.89 0.80 0.81 0.93\\n\\nSmyrf 1.41 2.83 5.43 10.72\\n\\nLSformer 1.75 1.76 3.01 7.50\\n\\n70.05 140.01 - - 27.61 55.20 110.27 221.40 - 4.75 9.29 18.27 36.53. - 42.31 84.48 168.95 - - 39.08 76.39 150.82 - -\\n\\nBlock Sparse 1.29 1.28 2.18 3.04 21.16 - - - - Longformer 1.27 1.31 . 2.04 10.74 25.95, - - - BigBird 1.33 1.28 1.32 1.81 11.44 27.45, -\\n\\nFLASHATTENTION 0.30 0.26 0.68 2.02 Block-Sparse FLASHATTENTION 0.30 0.27 0.29 0.59\\n\\n26.89 105.70 418.96 1666.89 6660.44 2.94 5.82 11.85 23.98 47.61\\n\\nTable 11: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length, with dropout and masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.84 0.86 2.35 8.29 31.75 124.19 - - - - Megatron 0.87 0.89 1.33 4.21 16.50 - Reformer 4.30 7.76 14.60 28.74 57.79 116.34 237.57 - - Local Attention 1.40 1.60 2.06 6.06 20.94 42.01 84.08 168.48 339.45 - Linformer 1.57 1.49 1.60 4.19 8.04 15.71 30.92 61.47 - Smyrf 3.41 5.08 18.18 36.03 71.68 143.04 285.87 - - LSformer 3.08 3.10 10.90 31.59 61.72 121.51 241.18 - - Block Sparse 2.54 2.52 5.44 13.29 39.19 - - - - Longformer 2.47 2.49 3.10 10.39 22.49 60.44 - - - BigBird 2.51 2.49 3.40 10.97 23.89 63.28 - - - FLASHATTENTION 0.43 0.41 2.55 9.56 37.49 147.75 586.61 2339.11 9341.30 Block-Sparse FLASHATTENTION 0.44 0.44 0.89 1.95 4.12 7.64 16.60 32.73 64.11\\n\\nTable 12: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 PyTorch Attention 0.30 0.30 0.63 1.93 Megatron 0.45 0.41 0.43 1.52 Reformer 1.87 3.00 5.37 10.43\\n\\nLocal Attention 0.70 0.81 1.02 2.09 Linformer 0.63 0.50 0.67 0.65\\n\\nSmyrf 2.38 2.32 3.76 7.16\\n\\nLSformer 1,22 1.29 1.44 3.28\\n\\nBlock Sparse 0.96 1.04 1.66 2.16 Longformer 0.99 0.98 0.99 1.56 BigBird 0.96 1.02 1.02 1.48 FLASHATTENTION 0.03 0.04 0.17 0.68 Block-Sparse FLASHATTENTION 0.05, 0.04 0.05 0.11\\n\\n4096 8192 16384 32768 65536 27.45 112.90 - -\\n\\n43.83 92.80 203.24 - 13.34 26.77 54.02 110.11 - 2.60 5.04 9.92 19.69 43.47 28.09 55.98 111.73 - 21.72 43.29 86.32 172.76 -\\n\\n11.07 32.98 - - - 11.59 34.16 - - 8.40 33.55 134.14 537.50 2150.88 0.68 1.33 2.54 5.34 10.73\\n\\nTable 13: Backward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with masking. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 4096 8192 16384 32768 65536 PyTorch Attention 0.44 0.46 5.33 79.87 - - - - Megatron 0.29 0.31 1.95 - - - - - Reformer 2.31 4.47 17.20 68.09 136.02 - - - Local Attention 0.51 0.62 3.81 26.72 53.41 106.82 214.15 - Linformer 0.76 0.81 0.87 4.25 8.35 16.38 32.67 72.11 Smyrf 1.34 2.77 10.46 41.27 82.41 164.86 - - LSformer 1.66 1.61 7.42 38.35, 74.92 147.86 - - Block Sparse 1.24 1.25 2.91 19.67 - - - - Longformer 1.27 1.23 1.85 10.21 24.89 - - - BigBird 1.43 1.50 1.69 10.86 26.26 - - - FLASHATTENTION 0.21 0.22 0.62 1.84 22.25 86.21 338.91 1343.91 5361.09 Block-Sparse FLASHATTENTION 0.22 0.22 0.26 0.57 3.13 5.98 12.21 23.49 47.85\\n\\nTable 14: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length, with masking. Best in bold, second best underlined.\\n\\nAttention Method | 128 256 512 —-1024_—.2048——-4096 8192 16384-32768 65536 PyTorch Attention | 0.80 0.81 2.08 7.23 27.51 107.58 = = Megatron | 0.81 0.83 1.09 _3.36_—_—:12.39 - - Reformer | 4.16 7.46 14.06 27.68 55.66 112.15 229.37 Local Attention | 1.39 1.68 2.08 5.83 20.04 40.16 80.44 161.35 325.11 - Linformer | 1.51 142 156 167 3.67 13.63 26.77 53.36 117.56 Smyrf | 3.38 4.93 9.07 17.66 34.94 138.72 277.41 - = LSformer | 3.08 3.10 4.26 10.90 _31.59 121.51 241.18 - - Block Sparse | 2.39 240 3.31 5.02 12.25 Longformer | 2.36 2.34 2.38 2.94 9.83 BigBird | 2.35 2.35 2.37 3.25 10.36 FLASHATTENTION | 0.32 0.30 0.83. 237 7.95 Block-Sparse FLASHATTENTION | 0.34 0.34 0.36 0.69 1.85\\n\\n58.12 - - - 60.63 - - - 119.98 473.65 1883.43 7513.01 7.16 14.85 30.46 60.03\\n\\nTable 15: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout. Best in bold, second best underlined.\\n\\nAttention Method | 128 256 512-1024 ~—-2048—— 4096-8192 16384-32768 65536, PyTorch Attention | 0.26. 0.24 0.57 1.80 656 25.34 = = = = Megatron | 0.27 0.27 (0.56 «1.88 6.56 - - - - - Reformer | 1.83 2.96 5.31 10.33 21.19 4342 91.96 201.34 = Local Attention | 0.51 0.60 0.78 2.01 6.23 12.52 25.07 50.50 102.18 - Linformer | 0.47 0.37 0.49 0.52 1.37 2.65 5.12, 10.13 -20.25 44.16 Smyrf | 2.12 2.01 315 5.97 i183 23.36 4648 92.72 - LSformer | 1.28 1.33 1.51 3.39 «11.40 -22.54 44.96 89.85 «179.73 - Block Sparse | 1.03. 1.00. 1.72 2.39 596 17.88 = Longformer | 1.02 1.03 1.03 1.73 5.10 11.63 34.22 - - - BigBird | 0.99 1.03 1.01 1.58 5.36 —-:12.27 35.56 - - FLASHATTENTION | 0.10 0.10 0.22 0.83 2.81 10.38 41.63 167.01 668.74 2678.11 Block-Sparse FLASHATTENTION | 0.54 0.51 0.68 0.61 0.67 1.10 1.89 3.71 7.18 14.41\\n\\nTable 16: Backward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length, with dropout. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.44 0.35 2.94 10.77 41.67 - - - - Megatron 0.28 0.33 2.94 10.80 - - - - - Reformer 2.24 4.34 16.62 33.02 65.77 131.52 - - Local Attention 0.51 0.58 3.71 12.96 25.98 51.94 103.72 207.78 - Linformer 0.84 0.74 0.85 2.28 4.37 8.66 33.78 - Smyrf 1.27 2.56 9.66 19.16 38.13 76.17 LSformer 1.67 1.77 7.52 20.10 39.13 76.35, Block Sparse 1.27 1.36 3.04 7.27 21.18 - Longformer 1.28 1.34 1.98 5.24 10.74 25.95, - - - BigBird 1.48 1.47 1.81 5.57 11.38 27.43 - - FLASHATTENTION 0.15 0.18 1.86 6.50 26.21 104.27 416.10 1661.92 6643.01 Block-Sparse FLASHATTENTION 0.17 0.17 0.40 1.10 2.04 4.43 9.33 18.28 37.31\\n\\nTable 17: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length, with dropout. Best in bold, second best underlined.\\n\\nAttention Method | 128 256 1024 2048 1638432768 65536\\n\\nPyTorch Attention | 0.60 0.67 Z82 17.47 =\\n\\nMegatron | 0.88 _0.90 4.73 17.41 - - -\\n\\nReformer | 4.06 7.28 26.98 54.27 =\\n\\nLocal Attention | 1.09 1.40 5.61 19.23 154.63 311.12 -\\n\\nLinformer | 1.31 1.21 139 3.73 27.69 55.00 -\\n\\nSmyrf | 3.00 4.37 15.66 31.04 245.65 - -\\n\\nLSformer | 3.07 3.17 10.89 31.54 240.94 - -\\n\\nBlock Sparse | 2.54 2.52 5.44 13.29 =\\n\\nLongformer | 2.47 2.49 3.10 10.39 - - -\\n\\nBigBird | 2.51 2.49 3.40 10.97 - - - FLASHATTENTION | 0.35 0.36 252 9.16 583.45 2332.01 Block-Sparse FLASHATTENTION | 0.91 0.83 0.92 1.83 13.56 26.71\\n\\n33\\n\\nTable 18: Forward pass runtime (ms) of various exact /approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.21 0.22 0.43 1.27 4,32 16.47 67.77 - - - Megatron 0.24 0.26 0.42 1.33 4.28 - - - Reformer 1.77 2.82 5.01 9.74 20.03 41.11 87.39 192.40 - - Local Attention 0.48 0.57 0.80 1.90 5.76 11.56 23.13 46.65 94.74 - Linformer 0.46 0.36 0.45 0.50 1.09 2.09 4.01 7.90 15.70 35.40 Smyrf 1.94 1.96 3.01 5.69 11.26 22.23 44,21 88.22 - LSformer 1.21 1.34 1.34 3.31 11.01 21.71 43.27 86.32 172.85 - Block Sparse 0.96 1.04 1.66 2.16 5.41 16.15 - Longformer 0.98 0.99 1.56 4.79 11.07 32.98 - - - BigBird 0.96 1.02 1.02 1.48 5.05 11.59 34.16 - - FLASHATTENTION 0.08 0.09 0.18 0.68 2.40 8.42 33.54 134.03 535.95, 2147.05 Block-Sparse FLASHATTENTION 0.56 0.52 0.63 0.65 0.61 0.96 1.69 3.02 5.69 11.77\\n\\nTable 19: Backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.26 0.29 2.44 8.82 33.87 - - = = Megatron 0.29 0.30 2.59 8.86 - - - -\\n\\n16.12 32.02 63.84 127.60 - - 3.60 12.52 25.08 50.22 100.23 200.66 - 0.80 2.04 3.88 7.67 15.04 30.11 63.15 9.42 18.65 37.12 74.15 148.35 - - 7.40 19.72 38.27 74.89 147.99 - - 2.91 6.78 19.67 - - - - 1.85 4.99 10.21 24.89 - - - 1.69 5.25 10.86 26.26 - - - 1.62 5.45 21.57 84.75, 336.00 1338.56 5343.19 0.38 1.20 2.34 4.69 9.10 18.74 37.04\\n\\nReformer 2.18 4.21\\n\\nLocal Attention 0.51 0.64\\n\\nLinformer 0.69 0.76\\n\\nSmyrf | 1.24 2.49\\n\\nLSformer 1.68 1.61\\n\\nBlock Sparse 1.24 1.25\\n\\nLongformer 1.27 1.23\\n\\nBigBird 1.43 1.50\\n\\nFLASHATTENTION | 0.11 0.16 Block-Sparse FLASHATTENTION | 0.11 0.12\\n\\nTable 20: Forward pass + backward pass runtime (ms) of various exact/approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 0.67 0.70 3.67 13.22 50.44 - - = =\\n\\nMegatron 0.74 0.65 3.80 13.21 - - - - -\\n\\nReformer 3.93 7.01 25.89 52.09 215.13 - - -\\n\\nLocal Attention 1.09 1.27 5.38 18.32 73.67 147.29 296.35 - Linformer 1.31 1.25 1.29 3.20 11.93 23.39 46.72 100.52\\n\\nSmyrf 2.98 4,23 15.12 29.96 118.60 237.02 - -\\n\\nLSformer 3.03 3.05 10.70 30.77 234.94 - -\\n\\nBlock Sparse 2.39 2.40 5.02 12.25 - - - -\\n\\nLongformer 2.36 2.34 2.94 9.83 58.12 - - -\\n\\nBigBird 2.35 2.35 3.25 10.36 60.63 - - - FLASHATTENTION 0.31 0.31 2.29 7.64 118.50 470.51 1876.08 7492.85,\\n\\nBlock-Sparse FLASHATTENTION 0.74 0.77 0.88 1.71 3.21 6.56 12.60 24.93 50.39', metadata={'source': 'documents/flash_attention.pdf'}), Document(page_content='Block-Sparse FLASHATTENTION 0.74 0.77 0.88 1.71 3.21 6.56 12.60 24.93 50.39\\n\\nTable 21: Memory usage (MB) of various exact/approximate/sparse attention mechanisms by sequence length. Best in bold, second best underlined.\\n\\nAttention Method 128 256 512 1024 2048 4096 8192 16384 32768 65536 PyTorch Attention 36 104 336 1184 4416 17024 - - - - Megatron 36 104 336 1184 4416 - - Reformer 377 754 1508 3016 6033) 12067 24134 - - Local Attention 53, 110 232 592 1696 3392 6784 13568 27136 - Linformer 25, 52 114 287 832 1652 3292 6572 13132 26252 Smyrf 217 434 868 1737 3474 6947 13894 27788 - - LSformer 72 152 333 796 2540 5068 10125 20240 - - Block Sparse 33 82 228 408 910 2401 - Longformer 30 61 124 277 681 1370 2748 - - - BigBird 33 66 131 294 708 1431 2872 - - - FLASHATTENTION 22 44 104 209 418 836 1672 3344 6688 13376 Block-Sparse FLASHATTENTION 22 44 104 209 418 836 1672 3344 6690 13384', metadata={'source': 'documents/flash_attention.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "print(output_summary['input_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a35f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The paper introduces FLASHATTENTION, an IO-aware exact attention algorithm that reduces memory reads/writes between GPU memory levels, improving the efficiency of Transformers on long sequences. FLASHATTENTION achieves faster training speeds and higher model quality compared to existing methods, enabling Transformers to handle longer context and achieve better performance on various tasks. The algorithm is shown to be up to 7.6x faster than standard attention implementations and requires less memory access. Additionally, block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k. The paper also discusses the potential of FLASHATTENTION as a primitive for approximate attention algorithms and provides empirical validation of its performance improvements.', 'Introduction:\\nThe paper introduces FLASHATTENTION, an IO-aware exact attention algorithm designed to improve the efficiency of Transformers on long sequences by reducing memory reads/writes between GPU memory levels. This algorithm enables faster training speeds and higher model quality compared to existing methods, allowing Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires less memory access.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- The algorithm has the potential to serve as a primitive for approximate attention algorithms and has been empirically validated for performance improvements.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION presents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory reads/writes and achieve faster training speeds makes it a valuable tool for enhancing the capabilities of Transformer models.', 'Introduction:\\nThe paper introduces FLASHATTENTION, an IO-aware exact attention algorithm designed to improve the efficiency of Transformers on long sequences by reducing memory reads/writes between GPU memory levels. This algorithm enables faster training speeds and higher model quality compared to existing methods, allowing Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- The algorithm has the potential to serve as a primitive for approximate attention algorithms and has been empirically validated for performance improvements.\\n- FLASHATTENTION significantly reduces memory reads/writes and achieves faster training speeds, making it a valuable tool for enhancing Transformer models.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a groundbreaking advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses and achieve faster training speeds makes it a valuable asset for enhancing the capabilities of Transformer models, enabling them to handle longer context and achieve better results on various tasks.', 'Introduction:\\nThe paper introduces FLASHATTENTION, an IO-aware exact attention algorithm designed to improve the efficiency of Transformers on long sequences by reducing memory reads/writes between GPU memory levels. This algorithm enables faster training speeds and higher model quality compared to existing methods, allowing Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, showcasing its ability to handle long context effectively.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a groundbreaking advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks demonstrates its value in enhancing Transformer models for various applications.', 'Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks highlights its value in enhancing Transformer models for various applications.', \"Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks highlights its value in enhancing Transformer models for various applications. The integration of IO-aware runtime optimization and efficient ML models with structured matrices further solidifies FLASHATTENTION's position as a cutting-edge solution in the field of deep learning.\", \"Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks highlights its value in enhancing Transformer models for various applications. The integration of IO-aware runtime optimization, efficient ML models with structured matrices, and butterfly patterns further solidifies FLASHATTENTION's position as a cutting-edge solution in the field of deep learning.\", \"Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks highlights its value in enhancing Transformer models for various applications. The integration of IO-aware runtime optimization, efficient ML models with structured matrices, and butterfly patterns further solidifies FLASHATTENTION's position as a cutting-edge solution in the field of deep learning. The algorithm's innovative approach to the backward pass and its comparison with existing methods demonstrate its superiority in terms of memory efficiency and speed.\", \"Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks highlights its value in enhancing Transformer models for various applications. The integration of IO-aware runtime optimization, efficient ML models with structured matrices, and butterfly patterns further solidifies FLASHATTENTION's position as a cutting-edge solution in the field of deep learning. The algorithm's innovative approach to the backward pass and its comparison with existing methods demonstrate its superiority in terms of memory efficiency and speed. The detailed analysis of IO complexity and potential extensions provide a comprehensive understanding of FLASHATTENTION's capabilities and future directions in deep learning training.\", \"Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION represents a significant advancement in attention algorithms for Transformers, offering improved efficiency and performance on long sequences. Its ability to reduce memory accesses, achieve faster training speeds, and handle challenging tasks highlights its value in enhancing Transformer models for various applications. The integration of IO-aware runtime optimization, efficient ML models with structured matrices, and butterfly patterns further solidifies FLASHATTENTION's position as a cutting-edge solution in the field of deep learning. The algorithm's innovative approach to the backward pass and its comparison with existing methods demonstrate its superiority in terms of memory efficiency and speed. The detailed analysis of IO complexity and potential extensions provide a comprehensive understanding of FLASHATTENTION's capabilities and future directions in deep learning training. FLASHATTENTION's performance on different hardware configurations and its speedup over standard PyTorch attention further emphasize its versatility and efficiency in various settings.\", \"Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\\n\\nIn the experimental results, FLASHATTENTION outperforms other attention mechanisms in terms of runtime for both forward and backward passes across various sequence lengths. It showcases superior performance in handling long sequences and demonstrates its efficiency in memory usage and speed compared to existing methods.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION stands out as a cutting-edge solution in the field of deep learning, offering improved efficiency and performance on long sequences. Its innovative approach to attention mechanisms, structured matrices, and butterfly patterns contribute to its superior performance in handling challenging tasks and long contexts. The algorithm's ability to reduce memory accesses and achieve faster training speeds highlights its value in enhancing Transformer models for various applications. With its impressive results in experimental comparisons, FLASHATTENTION solidifies its position as a significant advancement in attention algorithms for Transformers.\", 'Introduction:\\nRecent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks. Additionally, the Block-Sparse FLASHATTENTION variant further improves efficiency and scalability for longer sequences.\\n\\nKey Points:\\n- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\\n- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\\n- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\\n- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\\n- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\\n\\nConclusion:\\nIn conclusion, FLASHATTENTION and its Block-Sparse variant offer significant advancements in attention algorithms for Transformers, providing improved efficiency, scalability, and performance on long sequences. These algorithms showcase superior speed, memory usage, and effectiveness in handling challenging tasks and long contexts, solidifying their value in enhancing Transformer models for various applications.']\n"
     ]
    }
   ],
   "source": [
    "print(output_summary['intermediate_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16f05db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction:\n",
      "Recent advancements in attention algorithms for Transformers have led to the development of FLASHATTENTION, an IO-aware exact attention algorithm designed to enhance the efficiency of Transformers on long sequences. This algorithm reduces memory reads/writes between GPU memory levels, resulting in faster training speeds and higher model quality compared to existing methods. FLASHATTENTION enables Transformers to handle longer context and achieve better performance on various tasks. Additionally, the Block-Sparse FLASHATTENTION variant further improves efficiency and scalability for longer sequences.\n",
      "\n",
      "Key Points:\n",
      "- FLASHATTENTION is up to 7.6x faster than standard attention implementations and requires fewer memory accesses.\n",
      "- Block-sparse FLASHATTENTION, a sparse attention algorithm, is 2-4x faster and can scale up to sequence lengths of 64k.\n",
      "- FLASHATTENTION improves performance on long document classification tasks such as MIMIC-III and ECtHR datasets, showcasing its effectiveness on lengthy text documents.\n",
      "- The algorithm enables Transformers to achieve non-random performance on challenging benchmarks like Path-X and Path-256, demonstrating its ability to handle long context effectively.\n",
      "- FLASHATTENTION utilizes structured matrices and butterfly patterns to optimize runtime and memory efficiency.\n",
      "\n",
      "Conclusion:\n",
      "In conclusion, FLASHATTENTION and its Block-Sparse variant offer significant advancements in attention algorithms for Transformers, providing improved efficiency, scalability, and performance on long sequences. These algorithms showcase superior speed, memory usage, and effectiveness in handling challenging tasks and long contexts, solidifying their value in enhancing Transformer models for various applications.\n"
     ]
    }
   ],
   "source": [
    "print(output_summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f7f57",
   "metadata": {},
   "source": [
    "### Summarizing using LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad663a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6369e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')\n",
    "wikipedia = WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1eb13e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name='Wikipedia',\n",
    "        func=wikipedia.run,\n",
    "        description='Useful for when you need to get information from wikipedia on a topic'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56c8670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent_executor = initialize_agent(tools, llm, agent='zero-shot-react-description', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15e55569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakesh.panigrahy/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Wikipedia to find information on Gopabandhu Das\n",
      "Action: Wikipedia\n",
      "Action Input: Gopabandhu Das\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Gopabandhu Das\n",
      "Summary: Gopabandhu Das (1877–1928), popularly known as Utkalamani Gopabandhu Das (Jewel of Utkal or Odisha), was a social worker, reformer, political activist, journalist, poet and essayist.\n",
      "\n",
      "Page: Nilakantha Das\n",
      "Summary: Pandit Nilakantha Das (1884-1967) was one of the most illustrious sons of Odisha, who appeared both in its political and literary arena at the most crucial period of its history, when Odisha had no political identity in the map of India, and Odia as a language was about to be extinct. He worked relentlessly for Odisha's recognition both politically and linguistically, and helped bring to fruition the dreams of Utkala Gaurab Madhusudan Das, Utkalamani Gopabandhu Das and all other Odia loving people.\n",
      "As a colleague of Mahatma Gandhi, Motilal Nehru and Dr. Rajendra Prasad, among others, Nilakantha played a key role in the Indian Independence movement. He was a polymath who was an eminent teacher, exceptional leader, erudite scholar, renowned writer, great orator, and a powerful legislator. Pandit Nilakantha was renowned as the headmaster of Satyabadi Bana Bidyalaya, the brainchild of Utkalamani Gopabandhu. He was a prime architect in creating the independent Odisha Province in 1936, who worked untiringly as the right-hand man of Madhusudan Das to achieve this goal. Because of his legislative efforts in Delhi Central Assembly, Odisha became the first Province in India to be formed on a linguistic basis.\n",
      "His in-depth research on the evolution of Odia language revealed a number of facts that helped establish Odia as the sixth Indian classical language. Odia is also the only language from the Indo-Aryan group of languages aside from Sanskrit to have the classical tag as of 2024.\n",
      "Because of his unfathomable knowledge in many important fields, Nilakantha Das is also revered as Utkala Guru.\n",
      "\n",
      "Page: Das (surname)\n",
      "Summary: Das (translation: \"devotee of God\") is a common last name in South Asia, among adherents of Hinduism and Sikhism, as well as those who converted to Islam or Christianity. It is a derived from the Sanskrit word Dasa (Sanskrit: दास) meaning servant, devotee, or votary. \"Das\" may be inferred to be one who has surrendered to God. The surname is often used by those in the Vaishnav community.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should continue searching for information on Gopabandhu Das\n",
      "Action: Wikipedia\n",
      "Action Input: Gopabandhu Das\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Gopabandhu Das\n",
      "Summary: Gopabandhu Das (1877–1928), popularly known as Utkalamani Gopabandhu Das (Jewel of Utkal or Odisha), was a social worker, reformer, political activist, journalist, poet and essayist.\n",
      "\n",
      "Page: Nilakantha Das\n",
      "Summary: Pandit Nilakantha Das (1884-1967) was one of the most illustrious sons of Odisha, who appeared both in its political and literary arena at the most crucial period of its history, when Odisha had no political identity in the map of India, and Odia as a language was about to be extinct. He worked relentlessly for Odisha's recognition both politically and linguistically, and helped bring to fruition the dreams of Utkala Gaurab Madhusudan Das, Utkalamani Gopabandhu Das and all other Odia loving people.\n",
      "As a colleague of Mahatma Gandhi, Motilal Nehru and Dr. Rajendra Prasad, among others, Nilakantha played a key role in the Indian Independence movement. He was a polymath who was an eminent teacher, exceptional leader, erudite scholar, renowned writer, great orator, and a powerful legislator. Pandit Nilakantha was renowned as the headmaster of Satyabadi Bana Bidyalaya, the brainchild of Utkalamani Gopabandhu. He was a prime architect in creating the independent Odisha Province in 1936, who worked untiringly as the right-hand man of Madhusudan Das to achieve this goal. Because of his legislative efforts in Delhi Central Assembly, Odisha became the first Province in India to be formed on a linguistic basis.\n",
      "His in-depth research on the evolution of Odia language revealed a number of facts that helped establish Odia as the sixth Indian classical language. Odia is also the only language from the Indo-Aryan group of languages aside from Sanskrit to have the classical tag as of 2024.\n",
      "Because of his unfathomable knowledge in many important fields, Nilakantha Das is also revered as Utkala Guru.\n",
      "\n",
      "Page: Das (surname)\n",
      "Summary: Das (translation: \"devotee of God\") is a common last name in South Asia, among adherents of Hinduism and Sikhism, as well as those who converted to Islam or Christianity. It is a derived from the Sanskrit word Dasa (Sanskrit: दास) meaning servant, devotee, or votary. \"Das\" may be inferred to be one who has surrendered to God. The surname is often used by those in the Vaishnav community.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Gopabandhu Das (1877–1928), popularly known as Utkalamani Gopabandhu Das, was a social worker, reformer, political activist, journalist, poet, and essayist.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = agent_executor.run('Can you please provide a short summary of Gopabandhu Das')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04c32e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gopabandhu Das (1877–1928), popularly known as Utkalamani Gopabandhu Das, was a social worker, reformer, political activist, journalist, poet, and essayist.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0145836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
